{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ER Evaluation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1452"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv('/data/home/wangys/MoE-Example/DI/restaurant/restaurant_all.csv')\n",
    "train = pd.read_json('/data/home/wangys/ExtractGPT-main/data/processed_datasets/oa-mine/train_1.0.jsonl',lines=True)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>category</th>\n",
       "      <th>target_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vertvie Women Running Shorts Trunks Phone Pock...</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>{'Sport Type': {'Running': 1}, 'Gender': {'Wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Running Sport Mens Basketball Tight Compre...</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>{'Sport Type': {'Running': 1}, 'Gender': {'Men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Space Jam Tune Squad Men&amp;#39;s Basketball Shor...</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>{'Sport Type': {'Basketball': 1}, 'Gender': {'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEAK Women Running Shorts Yoga Drawstring Shor...</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>{'Brand Name': {'PEAK': 1}, 'Gender': {'Women'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENERAN 2018 Sport Shorts Women Yoga Fitness S...</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>{'Gender': {'Women': 1}, 'Brand Name': {'PENER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>FreeBee Windproof Unisex Cycling Goggles Sport...</td>\n",
       "      <td>Eyewear</td>\n",
       "      <td>{'Gender': {'Unisex': 1}, 'Sport Type': {'Cycl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>100 speedcraft Base Outdoor Sports Bicycle Sun...</td>\n",
       "      <td>Eyewear</td>\n",
       "      <td>{'Lenses Material': {'n/a': 1}, 'Sport Type': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Professional Ski Goggles UV400 Lens Anti-fog S...</td>\n",
       "      <td>Eyewear</td>\n",
       "      <td>{'Lenses Optical Attribute': {'n/a': 1}, 'Gend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Cycling Eyewear Unisex Outdoor Sunglass UV400 ...</td>\n",
       "      <td>Eyewear</td>\n",
       "      <td>{'Lenses Optical Attribute': {'Polarized': 1},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>POLISI Professional Ski Goggles Double Layer L...</td>\n",
       "      <td>Eyewear</td>\n",
       "      <td>{'Sport Type': {'Skiing': 1}, 'Frame Material'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input category  \\\n",
       "0    Vertvie Women Running Shorts Trunks Phone Pock...   Shorts   \n",
       "1    New Running Sport Mens Basketball Tight Compre...   Shorts   \n",
       "2    Space Jam Tune Squad Men&#39;s Basketball Shor...   Shorts   \n",
       "3    PEAK Women Running Shorts Yoga Drawstring Shor...   Shorts   \n",
       "4    PENERAN 2018 Sport Shorts Women Yoga Fitness S...   Shorts   \n",
       "..                                                 ...      ...   \n",
       "306  FreeBee Windproof Unisex Cycling Goggles Sport...  Eyewear   \n",
       "307  100 speedcraft Base Outdoor Sports Bicycle Sun...  Eyewear   \n",
       "308  Professional Ski Goggles UV400 Lens Anti-fog S...  Eyewear   \n",
       "309  Cycling Eyewear Unisex Outdoor Sunglass UV400 ...  Eyewear   \n",
       "310  POLISI Professional Ski Goggles Double Layer L...  Eyewear   \n",
       "\n",
       "                                         target_scores  \n",
       "0    {'Sport Type': {'Running': 1}, 'Gender': {'Wom...  \n",
       "1    {'Sport Type': {'Running': 1}, 'Gender': {'Men...  \n",
       "2    {'Sport Type': {'Basketball': 1}, 'Gender': {'...  \n",
       "3    {'Brand Name': {'PEAK': 1}, 'Gender': {'Women'...  \n",
       "4    {'Gender': {'Women': 1}, 'Brand Name': {'PENER...  \n",
       "..                                                 ...  \n",
       "306  {'Gender': {'Unisex': 1}, 'Sport Type': {'Cycl...  \n",
       "307  {'Lenses Material': {'n/a': 1}, 'Sport Type': ...  \n",
       "308  {'Lenses Optical Attribute': {'n/a': 1}, 'Gend...  \n",
       "309  {'Lenses Optical Attribute': {'Polarized': 1},...  \n",
       "310  {'Sport Type': {'Skiing': 1}, 'Frame Material'...  \n",
       "\n",
       "[311 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4809, 4809),\n",
       " (2500, 2500),\n",
       " (3917, 3917),\n",
       " (4928, 4928),\n",
       " (2700, 2700),\n",
       " (5307, 5307),\n",
       " (556, 556),\n",
       " (4660, 4660),\n",
       " (3653, 3653),\n",
       " (2910, 2910),\n",
       " (108, 108),\n",
       " (3994, 3994),\n",
       " (2868, 2868),\n",
       " (4221, 4221),\n",
       " (5076, 5076),\n",
       " (4799, 4799),\n",
       " (5235, 5235),\n",
       " (351, 351),\n",
       " (2463, 2463),\n",
       " (366, 366),\n",
       " (3408, 3408),\n",
       " (2675, 2675),\n",
       " (3756, 3756),\n",
       " (622, 622),\n",
       " (3864, 3864),\n",
       " (2467, 2467),\n",
       " (4089, 4089),\n",
       " (1550, 1550),\n",
       " (127, 127),\n",
       " (478, 478),\n",
       " (2118, 2118),\n",
       " (4464, 4464),\n",
       " (3896, 3896),\n",
       " (652, 652),\n",
       " (1058, 1058),\n",
       " (985, 985),\n",
       " (5185, 5185),\n",
       " (3606, 3606),\n",
       " (4191, 4191),\n",
       " (2565, 2565),\n",
       " (291, 291),\n",
       " (4977, 4977),\n",
       " (2992, 2992),\n",
       " (4047, 4047),\n",
       " (2383, 2383),\n",
       " (33, 33),\n",
       " (4001, 4001),\n",
       " (1236, 1236),\n",
       " (257, 257),\n",
       " (244, 244),\n",
       " (3905, 3905),\n",
       " (2989, 2989),\n",
       " (4987, 4987),\n",
       " (3914, 3914),\n",
       " (2621, 2621),\n",
       " (863, 863),\n",
       " (987, 987),\n",
       " (5316, 5316),\n",
       " (1691, 1691),\n",
       " (936, 936),\n",
       " (3831, 3831),\n",
       " (3705, 3705),\n",
       " (4145, 4145),\n",
       " (5208, 5208),\n",
       " (1179, 1179),\n",
       " (2509, 2509),\n",
       " (4026, 4026),\n",
       " (1475, 1475),\n",
       " (966, 966),\n",
       " (1796, 1796),\n",
       " (1212, 1212),\n",
       " (666, 666),\n",
       " (4313, 4313),\n",
       " (1178, 1178),\n",
       " (3710, 3710),\n",
       " (923, 923),\n",
       " (1526, 1526),\n",
       " (5013, 5013),\n",
       " (564, 564),\n",
       " (4015, 4015)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.load('/data/home/wangys/LLM_ER/process_data/semi-text-w/semi-text-w.npy',allow_pickle=True)[0]\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    List all files in the given folder and its subfolders, and return their paths.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path of the folder to traverse.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of file paths\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "    \n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03225806451612903 0.004273504273504274 0.007547169811320755\n"
     ]
    }
   ],
   "source": [
    "# result_merge = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/Mistral|synthea_train-MoE-Add/mistral-7b-synthea_test_few_output.csv',index_col=0).fillna('')\n",
    "result_merge = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_MELD/Vicuna-33B|amazon-google-train-MoE/vicuna-33b-MoE_ER_amazon-google-test.csv',index_col=0).fillna('')\n",
    "def Transfer(row):\n",
    "    if(row['output'].__contains__('dismatch')):\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    if(row['predict'].__contains__('dismatch')):\n",
    "        predict = 0\n",
    "    else:\n",
    "        predict = 1\n",
    "    return label,predict\n",
    "result_output = result_merge.apply(Transfer,axis=1,result_type='expand')\n",
    "from sklearn.metrics import f1_score\n",
    "print(precision_score(y_true=result_output[0],y_pred=result_output[1]),recall_score(y_true=result_output[0],y_pred=result_output[1]),f1_score(y_true=result_output[0],y_pred=result_output[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Output': 'match'}       16\n",
       "{'Output': 'dismatch'}    15\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_merge[result_merge['predict'].str.strip()!=result_merge['output']]['output'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon-Google\n",
    "Mistral: 0.8337\n",
    "LLaMa2-13b: 0.8086956521739128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ant_buy_add\n",
    "0.5714285714285714 amazon-google-test-DPO-AllPrompt.csv\n",
    "0.8925233644859812 ant-buy-test-sft-align.csv\n",
    "0.8750000000000001 beer-prompt-init-test.csv\n",
    "0.0 dblp-acm-PromptOpt-test.csv\n",
    "0.0 dblp-google-PromptOpt-test.csv\n",
    "0.8055555555555556 semi-text-c-prompt-init-test.csv\n",
    "0.7014492753623189 semi-text-w-prompt-init-test-all.csv\n",
    "0.8169642857142858 walmart-amazon-PromptOpt-test-align.csv\n",
    "0.8883534136546185 wdc-all-PromptOpt-test.csv\n",
    "## semi_text_c\n",
    "0.4602683178534572 amazon-google-test-DPO-AllPrompt.csv\n",
    "0.8189655172413793 ant-buy-test-sft-align.csv\n",
    "0.8235294117647058 beer-prompt-init-test.csv\n",
    "0.030973451327433624 dblp-acm-PromptOpt-test.csv\n",
    "0.00558659217877095 dblp-google-PromptOpt-test.csv\n",
    "0.8124392614188533 semi-text-c-prompt-init-test.csv\n",
    "0.7268170426065163 semi-text-w-prompt-init-test-all.csv\n",
    "0.6123778501628665 walmart-amazon-PromptOpt-test-align.csv\n",
    "0.857037037037037 wdc-all-PromptOpt-test.csv\n",
    "## walmart_amazon_add\n",
    "0.4689092762487258 amazon-google-test-DPO-AllPrompt.csv\n",
    "0.8016194331983806 ant-buy-test-sft-align.csv\n",
    "0.8750000000000001 beer-prompt-init-test.csv\n",
    "0.0 dblp-acm-PromptOpt-test.csv\n",
    "0.32088768930874195 dblp-google-PromptOpt-test.csv\n",
    "0.8588235294117647 semi-text-c-prompt-init-test.csv\n",
    "0.7438752783964365 semi-text-w-prompt-init-test-all.csv\n",
    "0.6904315196998123 walmart-amazon-PromptOpt-test-align.csv\n",
    "0.8662232076866222 wdc-all-PromptOpt-test.csv\n",
    "## wdc_all_add_llama2_13b\n",
    "0.5638297872340425 amazon-google-test-DPO-AllPrompt.csv\n",
    "0.86784140969163 ant-buy-test-sft-align.csv\n",
    "0.8750000000000001 beer-prompt-init-test.csv\n",
    "0.0 dblp-acm-PromptOpt-test.csv\n",
    "0.0 dblp-google-PromptOpt-test.csv\n",
    "0.8140900195694716 semi-text-c-prompt-init-test.csv\n",
    "0.7298050139275765 semi-text-w-prompt-init-test-all.csv\n",
    "0.7540983606557377 walmart-amazon-PromptOpt-test-align.csv\n",
    "0.8932190179267342 wdc-all-PromptOpt-test.csv\n",
    "## Mixtral_8*7b ant_buy\n",
    "0.6156716417910447 amazon-google-test-DPO-AllPrompt.csv\n",
    "0.852607709750567 ant-buy-test-sft-align.csv\n",
    "0.9032258064516129 beer-prompt-init-test.csv\n",
    "0.6023113528212102 dblp-acm-PromptOpt-test.csv\n",
    "0.8178311187312474 dblp-google-PromptOpt-test.csv\n",
    "0.8198019801980199 semi-text-c-prompt-init-test.csv\n",
    "0.7542857142857142 semi-text-w-prompt-init-test-all.csv\n",
    "0.8017817371937639 walmart-amazon-PromptOpt-test-align.csv\n",
    "0.8900116595413914 wdc-all-PromptOpt-test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6331168831168832 amazon-google-test.csv\n",
      "0.8306878306878307 ant_buy_test_output.csv\n",
      "0.8241010689990281 semi-text-c-test-MoE.csv\n",
      "0.7643979057591623 semi-text-w-test-MoE.csv\n",
      "0.8298368298368298 walmart_amazon_test_output.csv\n",
      "0.9038219235615288 wdc_all_test_output.csv\n",
      "1.0 RE-test_t=4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_list = list_files_in_folder('/data/home/wangys/LLaMA-Factory-main/inference/Mistral|wdc_all-MoE-Add')\n",
    "for f in file_list:\n",
    "    result_merge = pd.read_csv(f,index_col=0).fillna('')\n",
    "    def Transfer(row):\n",
    "        if(row['output'].__contains__('dismatch')):\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        if(row['predict'].__contains__('dismatch')):\n",
    "            predict = 0\n",
    "        else:\n",
    "            predict = 1\n",
    "        return label,predict\n",
    "    result_output = result_merge.apply(Transfer,axis=1,result_type='expand')\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(f1_score(y_true=result_output[0],y_pred=result_output[1]),f.split('/')[-1].replace('mistral-7b-',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_google\n",
    "0.8341013824884792 amazon-google-test.csv\n",
    "0.7537091988130563 ant_buy_test_output.csv\n",
    "0.7467467467467468 semi-text-c-test-MoE.csv\n",
    "0.6578947368421052 semi-text-w-test-MoE.csv\n",
    "0.6635071090047393 walmart_amazon_test_output.csv\n",
    "0.8806278397356464 wdc_all_test_output.csv\n",
    "1.0 RE-test_t=4.csv\n",
    "ant_buy\n",
    "0.6884681583476764 amazon-google-test.csv\n",
    "0.9112709832134294 ant_buy_test_output.csv\n",
    "0.8744512730465319 semi-text-c-test-MoE.csv\n",
    "0.7828282828282829 semi-text-w-test-MoE.csv\n",
    "0.8367816091954023 walmart_amazon_test_output.csv\n",
    "0.9197816043679127 wdc_all_test_output.csv\n",
    "semi_text_c\n",
    "0.5965909090909091 amazon-google-test.csv\n",
    "0.8258426966292136 ant_buy_test_output.csv\n",
    "0.7942973523421588 semi-text-c-test-MoE.csv\n",
    "0.7272727272727272 semi-text-w-test-MoE.csv\n",
    "0.8555240793201133 walmart_amazon_test_output.csv\n",
    "0.8821670428893904 wdc_all_test_output.csv\n",
    "semi_text_w\n",
    "0.731404958677686 amazon-google-test.csv\n",
    "0.8888888888888888 ant_buy_test_output.csv\n",
    "0.8646125116713352 semi-text-c-test-MoE.csv\n",
    "0.7616580310880829 semi-text-w-test-MoE.csv\n",
    "0.8542713567839197 walmart_amazon_test_output.csv\n",
    "0.901169826542961 wdc_all_test_output.csv\n",
    "walmart_amazon\n",
    "0.6715063520871144 amazon-google-test.csv\n",
    "0.918781725888325 ant_buy_test_output.csv\n",
    "0.8421052631578948 semi-text-c-test-MoE.csv\n",
    "0.7688172043010753 semi-text-w-test-MoE.csv\n",
    "0.9142857142857143 walmart_amazon_test_output.csv\n",
    "0.8979947689625108 wdc_all_test_output.csv\n",
    "wdc_all\n",
    "0.6331168831168832 amazon-google-test.csv\n",
    "0.8306878306878307 ant_buy_test_output.csv\n",
    "0.8241010689990281 semi-text-c-test-MoE.csv\n",
    "0.7643979057591623 semi-text-w-test-MoE.csv\n",
    "0.8298368298368298 walmart_amazon_test_output.csv\n",
    "0.9038219235615288 wdc_all_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation on AVE, whether it can be done or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_train = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/llama-2-13b-lora_weight|oa_mine|oa_mine_train_small-oa_mine_test_small.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def AST(row):\n",
    "    output = row['output'].strip()\n",
    "    predict = row['predict'].strip()\n",
    "    output_item = list(ast.literal_eval(output).values())[0]\n",
    "    predict_item = list(ast.literal_eval(predict).values())[0]\n",
    "    row['output_item'] = output_item.lower()\n",
    "    row['predict_item'] = predict_item.lower()\n",
    "    return row\n",
    "ave_train = ave_train.apply(AST,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462260301917585"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - len(ave_train[ave_train['output_item']!=ave_train['predict_item']]) / len(ave_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>predict</th>\n",
       "      <th>output_item</th>\n",
       "      <th>predict_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Brand\": \"Glamorous Wash\"}</td>\n",
       "      <td>{\"Brand\": \"Tyler Candle Co\"}</td>\n",
       "      <td>glamorous wash</td>\n",
       "      <td>tyler candle co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Specific uses\": \"Laundry Scent Booster\"}</td>\n",
       "      <td>{\"Specific uses\": \"Cruelty Free Formula\"}</td>\n",
       "      <td>laundry scent booster</td>\n",
       "      <td>cruelty free formula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Brand\": \"Arm &amp; Hammer\"}</td>\n",
       "      <td>{\"Brand\": \"Arm &amp; Hammer Clean &amp; Simple\"}</td>\n",
       "      <td>arm &amp; hammer</td>\n",
       "      <td>arm &amp; hammer clean &amp; simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Specialty\": \"Enzyme-Based\"}</td>\n",
       "      <td>{\"Specialty\": \"Free &amp; Clear\"}</td>\n",
       "      <td>enzyme-based</td>\n",
       "      <td>free &amp; clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Specialty\": \"Signature\"}</td>\n",
       "      <td>{\"Specialty\": \"Classic\"}</td>\n",
       "      <td>signature</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Item form\": \"Tablets\"}</td>\n",
       "      <td>{\"Item form\": \"Tablets w. Folic Acid\"}</td>\n",
       "      <td>tablets</td>\n",
       "      <td>tablets w. folic acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Health benefit\": \"Superior Strength Hair/Ski...</td>\n",
       "      <td>{\"Health benefit\": \"Hair/Skin/Nails with Arga...</td>\n",
       "      <td>superior strength hair/skin/nails</td>\n",
       "      <td>hair/skin/nails with argan/coconut oil/collagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Supplement type\": \"Pure Quercetin Dihydrate\"}</td>\n",
       "      <td>{\"Supplement type\": \"Quercetin Dihydrate\"}</td>\n",
       "      <td>pure quercetin dihydrate</td>\n",
       "      <td>quercetin dihydrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Administration type\": \"Sublingual Vitamins\"}</td>\n",
       "      <td>{\"Administration type\": \"Sublingual\"}</td>\n",
       "      <td>sublingual vitamins</td>\n",
       "      <td>sublingual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>You are a world-class expert for extracting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Supplement type\": \" Brewers Yeast 7-1/2 Grai...</td>\n",
       "      <td>{\"Supplement type\": \"Brewers Yeast 7-1/2 Grai...</td>\n",
       "      <td>brewers yeast 7-1/2 grains with vitamin b1, v...</td>\n",
       "      <td>brewers yeast 7-1/2 grains with vitamin b1, vi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instruction  input  \\\n",
       "5     You are a world-class expert for extracting in...    NaN   \n",
       "8     You are a world-class expert for extracting in...    NaN   \n",
       "12    You are a world-class expert for extracting in...    NaN   \n",
       "18    You are a world-class expert for extracting in...    NaN   \n",
       "24    You are a world-class expert for extracting in...    NaN   \n",
       "...                                                 ...    ...   \n",
       "2421  You are a world-class expert for extracting in...    NaN   \n",
       "2423  You are a world-class expert for extracting in...    NaN   \n",
       "2432  You are a world-class expert for extracting in...    NaN   \n",
       "2440  You are a world-class expert for extracting in...    NaN   \n",
       "2447  You are a world-class expert for extracting in...    NaN   \n",
       "\n",
       "                                                 output  \\\n",
       "5                           {\"Brand\": \"Glamorous Wash\"}   \n",
       "8            {\"Specific uses\": \"Laundry Scent Booster\"}   \n",
       "12                            {\"Brand\": \"Arm & Hammer\"}   \n",
       "18                        {\"Specialty\": \"Enzyme-Based\"}   \n",
       "24                           {\"Specialty\": \"Signature\"}   \n",
       "...                                                 ...   \n",
       "2421                           {\"Item form\": \"Tablets\"}   \n",
       "2423  {\"Health benefit\": \"Superior Strength Hair/Ski...   \n",
       "2432    {\"Supplement type\": \"Pure Quercetin Dihydrate\"}   \n",
       "2440     {\"Administration type\": \"Sublingual Vitamins\"}   \n",
       "2447  {\"Supplement type\": \" Brewers Yeast 7-1/2 Grai...   \n",
       "\n",
       "                                                predict  \\\n",
       "5                          {\"Brand\": \"Tyler Candle Co\"}   \n",
       "8             {\"Specific uses\": \"Cruelty Free Formula\"}   \n",
       "12             {\"Brand\": \"Arm & Hammer Clean & Simple\"}   \n",
       "18                        {\"Specialty\": \"Free & Clear\"}   \n",
       "24                             {\"Specialty\": \"Classic\"}   \n",
       "...                                                 ...   \n",
       "2421             {\"Item form\": \"Tablets w. Folic Acid\"}   \n",
       "2423   {\"Health benefit\": \"Hair/Skin/Nails with Arga...   \n",
       "2432         {\"Supplement type\": \"Quercetin Dihydrate\"}   \n",
       "2440              {\"Administration type\": \"Sublingual\"}   \n",
       "2447   {\"Supplement type\": \"Brewers Yeast 7-1/2 Grai...   \n",
       "\n",
       "                                            output_item  \\\n",
       "5                                        glamorous wash   \n",
       "8                                 laundry scent booster   \n",
       "12                                         arm & hammer   \n",
       "18                                         enzyme-based   \n",
       "24                                            signature   \n",
       "...                                                 ...   \n",
       "2421                                            tablets   \n",
       "2423                  superior strength hair/skin/nails   \n",
       "2432                           pure quercetin dihydrate   \n",
       "2440                                sublingual vitamins   \n",
       "2447   brewers yeast 7-1/2 grains with vitamin b1, v...   \n",
       "\n",
       "                                           predict_item  \n",
       "5                                       tyler candle co  \n",
       "8                                  cruelty free formula  \n",
       "12                          arm & hammer clean & simple  \n",
       "18                                         free & clear  \n",
       "24                                              classic  \n",
       "...                                                 ...  \n",
       "2421                              tablets w. folic acid  \n",
       "2423    hair/skin/nails with argan/coconut oil/collagen  \n",
       "2432                                quercetin dihydrate  \n",
       "2440                                         sublingual  \n",
       "2447  brewers yeast 7-1/2 grains with vitamin b1, vi...  \n",
       "\n",
       "[622 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_train[ave_train['output_item']!=ave_train['predict_item']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8049932523616734 ave_test_large\n",
    "0.7442645074224021 ave_test_small\n",
    "0.8049775601795186 oa_mine_large\n",
    "0.7462260301917585 oa_mine_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on DI\n",
    "### Walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/Mistral|DI-amazon-train-all/mistral-7b-amazon_test_output_wide.csv',index_col=0)\n",
    "# walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|jellyfish-sft/llama2-13b-walmart_test.csv',index_col=0)\n",
    "# walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|jellyfish-sft/llama2-13b-amazon_test.csv',index_col=0)\n",
    "# walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|Mixtral-sft/Mixtral-walmart_test.csv',index_col=0)\n",
    "# walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|Mixtral-sft/Mixtral-amazon_test.csv',index_col=0)\n",
    "# walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|Mixtral-sft/Mixtral-restaurant_test.csv',index_col=0)\n",
    "walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/Mistral|DI-amazon-train-all/mistral-7b-amazon_test_output_wide.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_DI_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/Mistral|DI-amazon-train-all/mistral-7b-amazon_test_output_wide.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walmart_DI_result[walmart_DI_result['output']!=walmart_DI_result['predict']]\n",
    "import ast\n",
    "def AST(row):\n",
    "    output = list(ast.literal_eval(row['output']).values())[0]\n",
    "    try:\n",
    "        predict = list(ast.literal_eval(row['predict'].strip()).values())[0]\n",
    "    except:\n",
    "        print(row['predict'])\n",
    "        predict  = ''\n",
    "    return output,predict\n",
    "walmart_DI_ast = walmart_DI_result.apply(AST,axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7512254901960784"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - len(walmart_DI_ast[walmart_DI_ast[0]!=walmart_DI_ast[1]]) / len(walmart_DI_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2451, 555)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(walmart_DI_ast),len(walmart_DI_ast[walmart_DI_ast[0]!=walmart_DI_ast[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310344827586207"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 2/29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/Mistral|restaurant_train-MoE-Add/mistral-7b-restaurant_test_output_wide.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walmart_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/CTA|CTA_SimTab_train_init/mistral-7b-SimTab_test_few.csv',index_col=0)\n",
    "walmart_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|jellyfish-sft/llama2-13b-restaurant_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walmart_DI_result[walmart_DI_result['output']!=walmart_DI_result['predict']]\n",
    "import ast\n",
    "def AST(row):\n",
    "    output = list(ast.literal_eval(row['output']).values())[0]\n",
    "    try:\n",
    "        predict = list(ast.literal_eval(row['predict'].strip()).values())[0]\n",
    "    except:\n",
    "        print(row['predict'])\n",
    "        predict  = ''\n",
    "    return output,predict\n",
    "walmart_DI_ast = walmart_test.apply(AST,axis=1,result_type='expand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>` san francisco '</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>` new york city '</td>\n",
       "      <td>` new york '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>` atlanta '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>` atlanta '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>` new york city '</td>\n",
       "      <td>` new york '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pasadena</td>\n",
       "      <td>` pasadena '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>` atlanta '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>` atlanta '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>` new york city '</td>\n",
       "      <td>` new york '</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0              1\n",
       "0   ` san francisco '  san francisco\n",
       "1   ` new york city '   ` new york '\n",
       "9             atlanta    ` atlanta '\n",
       "10            atlanta    ` atlanta '\n",
       "12  ` new york city '   ` new york '\n",
       "19           pasadena   ` pasadena '\n",
       "22            atlanta    ` atlanta '\n",
       "25            atlanta    ` atlanta '\n",
       "26  ` new york city '   ` new york '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_DI_ast[walmart_DI_ast[0]!=walmart_DI_ast[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Over CTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/CTA|CTA_SimTab_train_init/mistral-7b-SimTab_test_few.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference/CTA|CTA_WebTable_train_init/mistral-7b-WebTable_Test_few.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_GEIL/Mistral|RE-MoE-Add/mistral-7b-data_RE_RE-test_t=4.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_MELD/Vicuna-33B|RE-MoE-Add/vicuna-33b-data_RE_RE-test_t=4.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|Mixtral-sft/Mixtral-SimTab_test.csv',index_col=0)\n",
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|Mixtral-sft/Mixtral-webtable_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_MELD/Vicuna-33B|SimTab_train_init-MoE-Add/vicuna-33b-data_CTA_SimTab_test_few.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_GEIL/Mistral|SimTab-MoE-CT/mistral-7b-data_CTA_SimTab_test_few.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|Mixtral-sft/Mixtral-RE-test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|table-llama/table-llama-SimTab_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|jellyfish-sft/table-llama-webtable_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|table-llama/table-llama-RE-test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('inference_Transfer_ER/SimTab-P1--SimTab_test_few.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('inference_Transfer_ER/--SimTab_test_few.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test = pd.read_csv('inference_Transfer_ER/--WebTable_Test_few.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimTab_test['index'] = SimTab_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimTab_test\n",
    "import ast\n",
    "def Ast(row):\n",
    "    truth = list(eval(row['output']).values())[0]\n",
    "    try:\n",
    "        pred = list(eval(row['predict']).values())[0]\n",
    "    except:\n",
    "        pred = ''\n",
    "    index = row['index']\n",
    "    return truth, pred, index\n",
    "SimTab_test_Transform = SimTab_test.apply(Ast,axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation = list(SimTab_test_Transform[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation = np.load('/data/home/wangys/LLaMA-Factory-main/data/CTA/sim_all_relation.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation = np.load('/data/home/wangys/LLaMA-Factory-main/data/CTA/webtable_all_relation.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation = np.load('/data/home/wangys/LLaMA-Factory-main/data/RE/all_relation.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9046519524617996"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimTab_test_Transform.columns = ['truth','pred','index']\n",
    "count = 0\n",
    "truth_list = []\n",
    "pred_list = []\n",
    "for i in range(len(SimTab_test_Transform['index'].unique())):\n",
    "    select_df = SimTab_test_Transform[SimTab_test_Transform['index'] == i]\n",
    "    truth = select_df.iloc[0,0]\n",
    "    select_df_filter = select_df[select_df['pred'].isin(all_relation)]\n",
    "    try:\n",
    "        pred = select_df_filter['pred'].value_counts().idxmax()\n",
    "    except:\n",
    "        pred = select_df['pred'].value_counts().idxmax()\n",
    "    truth_list.append(truth)\n",
    "    pred_list.append(pred)\n",
    "    if truth==pred:\n",
    "        count += 1\n",
    "    # else:\n",
    "    #     print(truth,select_df['pred'].value_counts().idxmax())\n",
    "count / len(SimTab_test_Transform['index'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {}\n",
    "# all_relation = list(SimTab_test_Transform['truth'].unique())\n",
    "# all_relation = np.load('data/CTA/sim_all_relation.npy')\n",
    "# all_relation.extend(list(SimTab_test_Transform['pred'].unique()))\n",
    "for i in range(len(all_relation)):\n",
    "    relation_dict[all_relation[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9046519524617996, 0.7002269601639742)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimTab_F1 = pd.DataFrame()\n",
    "SimTab_F1['pred_output'] = pred_list\n",
    "SimTab_F1['truth_output'] = truth_list\n",
    "from sklearn.metrics import f1_score\n",
    "pred = SimTab_F1['pred_output'].map(relation_dict).fillna(0).to_list()\n",
    "truth = SimTab_F1['truth_output'].map(relation_dict).to_list()\n",
    "f1_score(y_pred=pred,y_true=truth,average='micro'),f1_score(y_pred=pred,y_true=truth,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.8909329829172142, 0.771330102155335) Mistral\n",
    "(0.7818659658344284, 0.5989916556768511) Qwen\n",
    "(0.859395532194481, 0.731767797493626) Qwen\n",
    "(0.8528252299605782, 0.780033122507523) Select-Mistral-2K sample\n",
    "(0.8462549277266754, 0.7313185684839995) \n",
    "Select-Mistral-1K sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pred = SimTab_F1['pred_output'].map(relation_dict).fillna(0).to_list()\n",
    "truth = SimTab_F1['truth_output'].map(relation_dict).to_list()\n",
    "f1_score(y_pred=pred,y_true=truth,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.8625492772667542, 0.6750286265992705) Mistral-Macro\n",
    "(0.961488508667909, 0.7905716732210353) Mistral-Macro\n",
    "(0.8222076215505915, 0.5598983999723887) TableLLAMA-SimTab_F1\n",
    "(0.9459596815178722, 0.8095254469231098) TableLLAMA\n",
    "(0.832046332046332, 0.6213512764551432) RE-test Mistral-7B\n",
    "(0.6587837837837838, 0.4239049298280863) TableLLAMA-RE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WebTable\n",
    "(0.8783701188455009, 0.678877623513516) DataSelection 1500\n",
    "(0.9046519524617996, 0.7002269601639742) 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pred = SimTab_test_Transform['pred'].map(relation_dict).to_list()\n",
    "truth = SimTab_test_Transform['truth'].map(relation_dict).to_list()\n",
    "f1_score(y_pred=pred,y_true=truth,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8935611038107752\n",
    "# 0.8625492772667542 Micro-F1\n",
    "# 0.7891529869661876/0.6750286265992705 Macro-F1\n",
    "0.8935 Micro/ 0.7616 Macro\n",
    "0.9641 Micro/ 0.7876 Macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Imputation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/1/71\"}</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/13/00\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jvolumn\": \"-1\"}</td>\n",
       "      <td>{\"article_jvolumn\": \"-1\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jissue\": \"-1\"}</td>\n",
       "      <td>{\"article_jissue\": \"-1\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jcreated_at\": \"2/15/04\"}</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/13/04\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/6/12\"}</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/13/04\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jvolumn\": \"-1\"}</td>\n",
       "      <td>{\"article_jvolumn\": \"-1\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jissue\": \"-1\"}</td>\n",
       "      <td>{\"article_jissue\": \"-1\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jcreated_at\": \"10/27/14\"}</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/13/12\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/11/01\"}</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/13/12\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>You are an expert in Cleaning Rayyan Dataset. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/12/01\"}</td>\n",
       "      <td>{\"article_jcreated_at\": \"1/12/01\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1117 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instruction  input  \\\n",
       "0     You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "1     You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "2     You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "3     You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "4     You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "...                                                 ...    ...   \n",
       "1112  You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "1113  You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "1114  You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "1115  You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "1116  You are an expert in Cleaning Rayyan Dataset. ...    NaN   \n",
       "\n",
       "                                   output                              predict  \n",
       "0       {\"article_jcreated_at\": \"1/1/71\"}   {\"article_jcreated_at\": \"1/13/00\"}  \n",
       "1               {\"article_jvolumn\": \"-1\"}            {\"article_jvolumn\": \"-1\"}  \n",
       "2                {\"article_jissue\": \"-1\"}             {\"article_jissue\": \"-1\"}  \n",
       "3      {\"article_jcreated_at\": \"2/15/04\"}   {\"article_jcreated_at\": \"1/13/04\"}  \n",
       "4       {\"article_jcreated_at\": \"1/6/12\"}   {\"article_jcreated_at\": \"1/13/04\"}  \n",
       "...                                   ...                                  ...  \n",
       "1112            {\"article_jvolumn\": \"-1\"}            {\"article_jvolumn\": \"-1\"}  \n",
       "1113             {\"article_jissue\": \"-1\"}             {\"article_jissue\": \"-1\"}  \n",
       "1114  {\"article_jcreated_at\": \"10/27/14\"}   {\"article_jcreated_at\": \"1/13/12\"}  \n",
       "1115   {\"article_jcreated_at\": \"1/11/01\"}   {\"article_jcreated_at\": \"1/13/12\"}  \n",
       "1116   {\"article_jcreated_at\": \"1/12/01\"}   {\"article_jcreated_at\": \"1/12/01\"}  \n",
       "\n",
       "[1117 rows x 4 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012123584747314453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1117,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db94f707307f4a2eaacbd35faa3e20b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01129150390625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bd43bcf81e4070b09be605b39fe011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.7534372135655362, 0.8670886075949367, 0.8062775870524767)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Try to test recall on Rayyan Dataset\n",
    "import json\n",
    "# result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_multi_experts/merge_experts_hospital|Expert-7/mistral-7b-rayyan-test-20.csv',index_col=0)\n",
    "result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_MELD/Vicuna-33B|rayyan-train-MoE/vicuna-33b-data_rayyan_rayyan-test-20.csv',index_col=0)\n",
    "rayyan_detector = np.load('/data/home/wangys/MoE-Example/DC/GEIL_Data/rayyan/detector/detector.npy')\n",
    "rayyan_clean = pd.read_csv('/data/home/wangys/MoE-Example/DC/GEIL_Data/rayyan/original/clean.csv').fillna('')\n",
    "rayyan_dirty = pd.read_csv('/data/home/wangys/MoE-Example/DC/GEIL_Data/rayyan/original/dirty.csv').fillna('')\n",
    "def Str2Int(row):\n",
    "    for index in range(11):\n",
    "        temp = row[index]\n",
    "        try:\n",
    "            row[index] = str(int(temp))\n",
    "        except:\n",
    "            continue\n",
    "    return row\n",
    "rayyan_clean = rayyan_clean.apply(Str2Int,axis=1)\n",
    "rayyan_dirty = rayyan_dirty.apply(Str2Int,axis=1)\n",
    "count = 0\n",
    "valid_count = 0\n",
    "rayyan_correction = rayyan_dirty.copy()\n",
    "import ast\n",
    "for d in tqdm(np.argwhere(rayyan_detector==1)):\n",
    "    i = d[0]\n",
    "    j = d[1] + 1 ## Ignore Index\n",
    "    try:\n",
    "        predict = list(eval(result.iloc[count,-1]).values())[0]\n",
    "        rayyan_correction.iloc[i,j] = predict\n",
    "        valid_count += 1\n",
    "    except:\n",
    "        # print(result.iloc[count,-1])\n",
    "        predict = result.iloc[count,-1]\n",
    "        rayyan_correction.iloc[i,j] = predict\n",
    "    count += 1\n",
    "All_Data_Error = 0\n",
    "All_Fixed_Error = 0\n",
    "Correct_Fixed_Error = 0\n",
    "clean = rayyan_clean.copy()\n",
    "dirty = rayyan_dirty.copy()\n",
    "correction = rayyan_correction.copy()\n",
    "for i in tqdm(range(len(clean))):\n",
    "# for i in tqdm(tax_error):\n",
    "    for j in range(clean.shape[1]):\n",
    "        dirty_cell = dirty.iloc[i,j]\n",
    "        clean_cell = clean.iloc[i,j]\n",
    "        correct_cell = correction.iloc[i,j]\n",
    "        if(correct_cell!=dirty_cell):\n",
    "            All_Fixed_Error += 1\n",
    "        if(clean_cell!=dirty_cell):\n",
    "            All_Data_Error += 1\n",
    "            if(correct_cell==clean_cell or correct_cell in clean_cell):\n",
    "                Correct_Fixed_Error += 1\n",
    "Precision_hospital = Correct_Fixed_Error / All_Fixed_Error\n",
    "Recall_hospital = Correct_Fixed_Error / All_Data_Error\n",
    "F1_hospital = (2 * Precision_hospital * Recall_hospital) / (Precision_hospital + Recall_hospital)\n",
    "Precision_hospital,Recall_hospital,F1_hospital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "77.80\n",
    "80.21\n",
    "82.55\n",
    "81.64\n",
    "79.58\n",
    "77.79\n",
    "77.16\n",
    "80.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bdbfeb6d314b8f825e54291af7258b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.06177260519247986, 0.07278481012658228, 0.06682808716707023)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data_Error = 0\n",
    "All_Fixed_Error = 0\n",
    "Correct_Fixed_Error = 0\n",
    "clean = rayyan_clean.copy()\n",
    "dirty = rayyan_dirty.copy()\n",
    "correction = rayyan_correction.copy()\n",
    "for i in tqdm(range(len(clean))):\n",
    "# for i in tqdm(tax_error):\n",
    "    for j in range(clean.shape[1]):\n",
    "        dirty_cell = dirty.iloc[i,j]\n",
    "        clean_cell = clean.iloc[i,j]\n",
    "        correct_cell = correction.iloc[i,j]\n",
    "        if(correct_cell!=dirty_cell):\n",
    "            All_Fixed_Error += 1\n",
    "        if(clean_cell!=dirty_cell):\n",
    "            All_Data_Error += 1\n",
    "            if(correct_cell==clean_cell):\n",
    "                Correct_Fixed_Error += 1\n",
    "Precision_hospital = Correct_Fixed_Error / All_Fixed_Error\n",
    "Recall_hospital = Correct_Fixed_Error / All_Data_Error\n",
    "F1_hospital = (2 * Precision_hospital * Recall_hospital) / (Precision_hospital + Recall_hospital)\n",
    "Precision_hospital,Recall_hospital,F1_hospital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3364 3364 3364\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "beer_clean = pd.read_csv('/data/home/wangys/MoE-Example/DC/GEIL_Data/beers/original/clean.csv').fillna('')\n",
    "beer_dirty = pd.read_csv('/data/home/wangys/MoE-Example/DC/GEIL_Data/beers/original/dirty.csv').fillna('')\n",
    "detector_beer = np.load('/data/home/wangys/MoE-Example/DC/GEIL_Data/beers/detector/detector.npy')\n",
    "beer_dirty.columns = beer_clean.columns\n",
    "def try_convert_to_int(row):\n",
    "    for x,y in row.items():\n",
    "        if(x in ['ounces','ibu']):\n",
    "            try:\n",
    "                row[x] = int(y)\n",
    "            except:\n",
    "                row[x] = y\n",
    "    return row\n",
    "beer_clean = beer_clean.apply(try_convert_to_int,axis=1).astype(str)\n",
    "beer_dirty = beer_dirty.apply(try_convert_to_int,axis=1).astype(str)\n",
    "beer_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_baseline/models|Mixtral-sft/Mixtral-beer-test-ablation.csv',index_col=0) ## generation-ablation\n",
    "beer_correction = beer_dirty.copy()\n",
    "for d in np.argwhere(detector_beer==1):\n",
    "    i = d[0] \n",
    "    j = d[1] + 2\n",
    "    \n",
    "    try:\n",
    "        predict = list(eval(beer_result.iloc[count,-1]).values())[0]\n",
    "        beer_correction.iloc[i,j] = predict\n",
    "        count += 1\n",
    "    except:\n",
    "        print(count)\n",
    "        count += 1\n",
    "print(count,len(np.argwhere(detector_beer==1)),len(beer_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.562128418549346, 0.5633005659815311, 0.562713881862818)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data_Error = 0\n",
    "All_Fixed_Error = 0\n",
    "Correct_Fixed_Error = 0\n",
    "for i in range(len(beer_clean)):\n",
    "    for j in range(11):\n",
    "        dirty_cell = beer_dirty.iloc[i,j]\n",
    "        clean_cell = beer_clean.iloc[i,j]\n",
    "        correct_cell = beer_correction.iloc[i,j]\n",
    "        if(correct_cell!=dirty_cell):\n",
    "            All_Fixed_Error += 1\n",
    "        if(clean_cell!=dirty_cell):\n",
    "            All_Data_Error += 1\n",
    "            if(correct_cell==clean_cell):\n",
    "                Correct_Fixed_Error += 1\n",
    "Precision_hospital = Correct_Fixed_Error / All_Fixed_Error\n",
    "Recall_hospital = Correct_Fixed_Error / All_Data_Error\n",
    "F1_hospital = (2 * Precision_hospital * Recall_hospital) / (Precision_hospital + Recall_hospital)\n",
    "Precision_hospital,Recall_hospital,F1_hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3357, 3364, 1724)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data_Error,All_Fixed_Error,Correct_Fixed_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508 508\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011737823486328125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24073e752d7c415c9fa9d0d561596ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.9486166007905138, 0.9430255402750491, 0.9458128078817735)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_result = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_multi_experts/merge_experts_hospital|Expert-8/mistral-7b-hospital-test.csv',index_col=0) ## \n",
    "count = 0\n",
    "hospital_clean = pd.read_csv('/data/home/wangys/MoE-Example/DC/GEIL_Data/hospital/original/clean.csv').astype(str)\n",
    "hospital_dirty = pd.read_csv('/data/home/wangys/MoE-Example/DC/GEIL_Data/hospital/original/dirty.csv').astype(str)\n",
    "hospital_dirty.columns = hospital_clean.columns\n",
    "hospital_correction = hospital_dirty.copy()\n",
    "hospital_detector = np.load('/data/home/wangys/MoE-Example/DC/GEIL_Data/hospital/detector/detector.npy').reshape((-1,20))\n",
    "import ast\n",
    "for d in np.argwhere(hospital_detector==1):\n",
    "    i = d[0]\n",
    "    j = d[1]\n",
    "    try:\n",
    "        predict = list(eval(hospital_result.iloc[count,-1]).values())[0]\n",
    "        hospital_correction.iloc[i,j] = predict\n",
    "        count += 1\n",
    "    except:\n",
    "        predict = hospital_result.iloc[count,-1]\n",
    "        hospital_correction.iloc[i,j] = predict\n",
    "        count += 1\n",
    "print(count,len(hospital_result))\n",
    "All_Data_Error = 0\n",
    "All_Fixed_Error = 0\n",
    "Correct_Fixed_Error = 0\n",
    "clean = hospital_clean.copy()\n",
    "dirty = hospital_dirty.copy()\n",
    "correction = hospital_correction.copy()\n",
    "for i in tqdm(range(len(clean))):\n",
    "# for i in tqdm(tax_error):\n",
    "    for j in range(clean.shape[1]):\n",
    "        dirty_cell = dirty.iloc[i,j]\n",
    "        clean_cell = clean.iloc[i,j]\n",
    "        correct_cell = correction.iloc[i,j]\n",
    "        if(correct_cell!=dirty_cell):\n",
    "            All_Fixed_Error += 1\n",
    "        if(clean_cell!=dirty_cell):\n",
    "            All_Data_Error += 1\n",
    "            if(correct_cell==clean_cell or correct_cell in clean_cell):\n",
    "                Correct_Fixed_Error += 1\n",
    "Precision_hospital = Correct_Fixed_Error / All_Fixed_Error\n",
    "Recall_hospital = Correct_Fixed_Error / All_Data_Error\n",
    "F1_hospital = (2 * Precision_hospital * Recall_hospital) / (Precision_hospital + Recall_hospital)\n",
    "Precision_hospital,Recall_hospital,F1_hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021889925003051758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fa2b2eb89b44cabec038cc16ef7e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.914, 0.8978388998035364, 0.9058473736372646)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data_Error = 0\n",
    "All_Fixed_Error = 0\n",
    "Correct_Fixed_Error = 0\n",
    "clean = hospital_clean.copy()\n",
    "dirty = hospital_dirty.copy()\n",
    "correction = hospital_correction.copy()\n",
    "for i in tqdm(range(len(clean))):\n",
    "# for i in tqdm(tax_error):\n",
    "    for j in range(clean.shape[1]):\n",
    "        dirty_cell = dirty.iloc[i,j]\n",
    "        clean_cell = clean.iloc[i,j]\n",
    "        correct_cell = correction.iloc[i,j]\n",
    "        if(correct_cell!=dirty_cell):\n",
    "            All_Fixed_Error += 1\n",
    "        if(clean_cell!=dirty_cell):\n",
    "            All_Data_Error += 1\n",
    "            if(correct_cell==clean_cell or correct_cell in clean_cell):\n",
    "                Correct_Fixed_Error += 1\n",
    "Precision_hospital = Correct_Fixed_Error / All_Fixed_Error\n",
    "Recall_hospital = Correct_Fixed_Error / All_Data_Error\n",
    "F1_hospital = (2 * Precision_hospital * Recall_hospital) / (Precision_hospital + Recall_hospital)\n",
    "Precision_hospital,Recall_hospital,F1_hospital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Task and Cross-Domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/data/home/wangys/LLaMA-Factory-main/data/MoE/ER/amazon-google-test.json\n",
    "/data/home/wangys/LLaMA-Factory-main/data/MoE/ER/semi-text-w-test-MoE.json\n",
    "/data/home/wangys/LLaMA-Factory-main/data/MoE/DI/walmart_test_output_wide.json\n",
    "/data/home/wangys/LLaMA-Factory-main/data/MoE/DI/restaurant_test_output_wide.json\n",
    "/data/home/wangys/LLaMA-Factory-main/data/CTA/WebTable_Test_few.json\n",
    "/data/home/wangys/LLaMA-Factory-main/data/CTA/SimTab_test_few.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mistral|amazon_google-MoE-CT',\n",
       " 'Mistral|semi_text_w-MoE-CT',\n",
       " 'Mistral|walmart-MoE-CT',\n",
       " 'Mistral|restaurant-MoE-CT',\n",
       " 'Mistral|webtable-MoE-CT',\n",
       " 'Mistral|SimTab-MoE-CT']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(MoE_list_update_top_2['domain'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoE_list_update_top_2 = pd.read_csv('../MoE-Example/Router/MoE_list_update_top_2_cross_dataset.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoE_list_update_top_2 = pd.read_csv('../MoE-Example/Router/MoE_list_update_top_2_cross_task.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon_Google_CD = MoE_list_update_top_2[MoE_list_update_top_2['domain']=='Mistral|amazon_google-MoE-CT']\n",
    "# amazon_google_gt = pd.read_json('/data/home/wangys/LLaMA-Factory-main/data/MoE/ER/amazon-google-test.json')\n",
    "\n",
    "# Amazon_Google_CD = MoE_list_update_top_2[MoE_list_update_top_2['domain']=='Mistral|semi_text_w-MoE-CT']\n",
    "# amazon_google_gt = pd.read_json('/data/home/wangys/LLaMA-Factory-main/data/MoE/ER/semi-text-w-test-MoE.json')\n",
    "\n",
    "# Amazon_Google_CD = MoE_list_update_top_2[MoE_list_update_top_2['domain']=='Mistral|SimTab-MoE-CT']\n",
    "# amazon_google_gt = pd.read_json('/data/home/wangys/LLaMA-Factory-main/data/CTA/SimTab_test_few.json')\n",
    "\n",
    "# Amazon_Google_CD = MoE_list_update_top_2[MoE_list_update_top_2['domain']=='Mistral|webtable-MoE-CT']\n",
    "# amazon_google_gt = pd.read_json('/data/home/wangys/LLaMA-Factory-main/data/CTA/WebTable_Test_few.json')\n",
    "\n",
    "# Amazon_Google_CD = MoE_list_update_top_2[MoE_list_update_top_2['domain']=='Mistral|walmart-MoE-CT']\n",
    "# amazon_google_gt = pd.read_json('/data/home/wangys/LLaMA-Factory-main/data/MoE/DI/walmart_test_output_wide.json')\n",
    "\n",
    "Amazon_Google_CD = MoE_list_update_top_2[MoE_list_update_top_2['domain']=='Mistral|restaurant-MoE-CT']\n",
    "amazon_google_gt = pd.read_json('/data/home/wangys/LLaMA-Factory-main/data/MoE/DI/restaurant_test_output_wide.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1389237/3355500504.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Amazon_Google_CD['output'] = Amazon_Google_CD['query'].map(amazon_google_gt_dict)\n"
     ]
    }
   ],
   "source": [
    "amazon_google_gt_dict = dict(zip(amazon_google_gt['instruction'],amazon_google_gt['output']))\n",
    "Amazon_Google_CD['output'] = Amazon_Google_CD['query'].map(amazon_google_gt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38860103626943004 0.35545023696682465 0.3712871287128713\n"
     ]
    }
   ],
   "source": [
    "# result_merge = Amazon_Google_CD\n",
    "result_merge = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_MoE/Mixtral-CT|CD-no-semi-text-w/Mixtral-7x8b-semi-text-w-test-MoE.csv',index_col=0)\n",
    "def Transfer(row):\n",
    "    if(row['output'].lower().__contains__('dismatch')):\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    if(row['predict'].lower().__contains__('dismatch')):\n",
    "        predict = 0\n",
    "    else:\n",
    "        predict = 1\n",
    "    return label,predict\n",
    "result_output = result_merge.apply(Transfer,axis=1,result_type='expand')\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "print(precision_score(y_true=result_output[0],y_pred=result_output[1]),recall_score(y_true=result_output[0],y_pred=result_output[1]),f1_score(y_true=result_output[0],y_pred=result_output[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3892371110734655"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon_Google_CD = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_MoE/Table-llama-CT|CD-no-webtable/table-llama-WebTable_Test_few.csv',index_col=0).fillna('')\n",
    "count = 0\n",
    "for index,row in Amazon_Google_CD.iterrows():\n",
    "    try:\n",
    "        truth = list(eval(row['output']).values())[0].lower().strip()\n",
    "    except:\n",
    "        truth = (row['output'])\n",
    "    if(row['predict'].lower().strip().__contains__(truth)):\n",
    "        count += 1\n",
    "count / len(Amazon_Google_CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset - Expert\n",
    "Walmart - Restaurant: Cross-Dataset with Top-1 expert 0.8461538461538461\n",
    "Walmart - SimTable: 0.8076923076923077/0.8275862068965517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7586206896551724"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amazon_Google_CD\n",
    "count = 0\n",
    "for index,row in Amazon_Google_CD.iterrows():\n",
    "    truth = list(eval(row['output']).values())[0].lower().strip()\n",
    "    if(row['prediction'].lower().strip().__contains__(truth)):\n",
    "        count += 1\n",
    "count / len(Amazon_Google_CD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation over one single data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('/data/home/wangys/LLaMA-Factory-main/inference_noMeta/MoE-no-Meta|ant_buy_train-MoE-noMeta/mistral-7b-all_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4726477024070022 0.9230769230769231 0.6251808972503619 amazon_google_test\n",
      "0.28180039138943247 0.6824644549763034 0.39889196675900274 semi_text_w_test\n",
      "0.5087538619979403 0.853195164075993 0.6374193548387096 semi_text_c_test\n",
      "0.6964980544747081 0.927461139896373 0.7955555555555555 walmart_amazon_test\n",
      "0.9267461669505963 0.9081803005008348 0.9173693086003373 wdc_all_test\n",
      "0.8947368421052632 0.9077669902912622 0.9012048192771085 ant_buy_test\n"
     ]
    }
   ],
   "source": [
    "domain = file['domain'].unique()\n",
    "for d in domain:\n",
    "    select_df = file[file['domain']==d]\n",
    "    result_merge = select_df\n",
    "    def Transfer(row):\n",
    "        if(row['output'].lower().__contains__('dismatch')):\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        if(row['predict'].lower().__contains__('dismatch')):\n",
    "            predict = 0\n",
    "        else:\n",
    "            predict = 1\n",
    "        return label,predict\n",
    "    result_output = result_merge.apply(Transfer,axis=1,result_type='expand')\n",
    "    from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "    print(precision_score(y_true=result_output[0],y_pred=result_output[1]),recall_score(y_true=result_output[0],y_pred=result_output[1]),f1_score(y_true=result_output[0],y_pred=result_output[1]),d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'python vllm_inference_api_table_llama.py -checkpoint_dir lora_weight/Table-llama-CT/CD-no-SimTab -test_file /data/home/wangys/LLaMA-Factory-main/data/CTA/SimTab_test_few.json --count 0 --json',\n",
    "'python vllm_inference_api_table_llama.py -checkpoint_dir lora_weight/Table-llama-CT/CD-no-webtable -test_file /data/home/wangys/LLaMA-Factory-main/data/CTA/WebTable_Test_few.json --count 0 --json',"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
