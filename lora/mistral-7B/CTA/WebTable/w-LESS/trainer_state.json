{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 657,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.045662100456621,
      "grad_norm": 51.74197769165039,
      "learning_rate": 1.5151515151515153e-05,
      "loss": 4.0274,
      "step": 10
    },
    {
      "epoch": 0.091324200913242,
      "grad_norm": 13.690367698669434,
      "learning_rate": 3.0303030303030306e-05,
      "loss": 1.1704,
      "step": 20
    },
    {
      "epoch": 0.136986301369863,
      "grad_norm": 6.750229835510254,
      "learning_rate": 4.545454545454546e-05,
      "loss": 0.2539,
      "step": 30
    },
    {
      "epoch": 0.182648401826484,
      "grad_norm": 5.088875770568848,
      "learning_rate": 6.060606060606061e-05,
      "loss": 0.0967,
      "step": 40
    },
    {
      "epoch": 0.228310502283105,
      "grad_norm": 1.926086664199829,
      "learning_rate": 7.575757575757576e-05,
      "loss": 0.0271,
      "step": 50
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 2.4072563648223877,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.0237,
      "step": 60
    },
    {
      "epoch": 0.319634703196347,
      "grad_norm": 1.9739304780960083,
      "learning_rate": 9.998869765883566e-05,
      "loss": 0.0391,
      "step": 70
    },
    {
      "epoch": 0.365296803652968,
      "grad_norm": 2.0983922481536865,
      "learning_rate": 9.986160499534318e-05,
      "loss": 0.0217,
      "step": 80
    },
    {
      "epoch": 0.410958904109589,
      "grad_norm": 0.9420461654663086,
      "learning_rate": 9.959365197965824e-05,
      "loss": 0.0264,
      "step": 90
    },
    {
      "epoch": 0.45662100456621,
      "grad_norm": 3.5005390644073486,
      "learning_rate": 9.918559558613344e-05,
      "loss": 0.0273,
      "step": 100
    },
    {
      "epoch": 0.502283105022831,
      "grad_norm": 1.1649198532104492,
      "learning_rate": 9.863858858486735e-05,
      "loss": 0.0137,
      "step": 110
    },
    {
      "epoch": 0.547945205479452,
      "grad_norm": 0.12162160128355026,
      "learning_rate": 9.795417628509857e-05,
      "loss": 0.0072,
      "step": 120
    },
    {
      "epoch": 0.593607305936073,
      "grad_norm": 3.603360176086426,
      "learning_rate": 9.713429216966624e-05,
      "loss": 0.0057,
      "step": 130
    },
    {
      "epoch": 0.639269406392694,
      "grad_norm": 7.68501091003418,
      "learning_rate": 9.618125243286989e-05,
      "loss": 0.0145,
      "step": 140
    },
    {
      "epoch": 0.684931506849315,
      "grad_norm": 1.8330397605895996,
      "learning_rate": 9.509774943715939e-05,
      "loss": 0.0206,
      "step": 150
    },
    {
      "epoch": 0.730593607305936,
      "grad_norm": 0.9337185025215149,
      "learning_rate": 9.388684410713977e-05,
      "loss": 0.0068,
      "step": 160
    },
    {
      "epoch": 0.776255707762557,
      "grad_norm": 2.660557985305786,
      "learning_rate": 9.255195728237838e-05,
      "loss": 0.0224,
      "step": 170
    },
    {
      "epoch": 0.821917808219178,
      "grad_norm": 0.3143342435359955,
      "learning_rate": 9.109686005344258e-05,
      "loss": 0.0162,
      "step": 180
    },
    {
      "epoch": 0.867579908675799,
      "grad_norm": 1.4943907260894775,
      "learning_rate": 8.95256631084693e-05,
      "loss": 0.0301,
      "step": 190
    },
    {
      "epoch": 0.91324200913242,
      "grad_norm": 0.9724547266960144,
      "learning_rate": 8.784280512036235e-05,
      "loss": 0.0063,
      "step": 200
    },
    {
      "epoch": 0.958904109589041,
      "grad_norm": 3.37819242477417,
      "learning_rate": 8.60530402074241e-05,
      "loss": 0.0057,
      "step": 210
    },
    {
      "epoch": 1.004566210045662,
      "grad_norm": 0.7806942462921143,
      "learning_rate": 8.416142450284565e-05,
      "loss": 0.007,
      "step": 220
    },
    {
      "epoch": 1.0502283105022832,
      "grad_norm": 1.2574446201324463,
      "learning_rate": 8.217330187099688e-05,
      "loss": 0.0066,
      "step": 230
    },
    {
      "epoch": 1.095890410958904,
      "grad_norm": 0.028967952355742455,
      "learning_rate": 8.009428881086835e-05,
      "loss": 0.0063,
      "step": 240
    },
    {
      "epoch": 1.1415525114155252,
      "grad_norm": 0.5522549152374268,
      "learning_rate": 7.793025858931318e-05,
      "loss": 0.0021,
      "step": 250
    },
    {
      "epoch": 1.187214611872146,
      "grad_norm": 0.014899021945893764,
      "learning_rate": 7.568732464891293e-05,
      "loss": 0.0098,
      "step": 260
    },
    {
      "epoch": 1.2328767123287672,
      "grad_norm": 1.2219462394714355,
      "learning_rate": 7.33718233373407e-05,
      "loss": 0.0029,
      "step": 270
    },
    {
      "epoch": 1.278538812785388,
      "grad_norm": 0.7070730328559875,
      "learning_rate": 7.099029600701143e-05,
      "loss": 0.0028,
      "step": 280
    },
    {
      "epoch": 1.3242009132420092,
      "grad_norm": 0.005339215509593487,
      "learning_rate": 6.854947053558849e-05,
      "loss": 0.0021,
      "step": 290
    },
    {
      "epoch": 1.36986301369863,
      "grad_norm": 0.0038704967591911554,
      "learning_rate": 6.605624231955131e-05,
      "loss": 0.0024,
      "step": 300
    },
    {
      "epoch": 1.4155251141552512,
      "grad_norm": 0.1288050264120102,
      "learning_rate": 6.351765479451815e-05,
      "loss": 0.009,
      "step": 310
    },
    {
      "epoch": 1.461187214611872,
      "grad_norm": 0.003236551070585847,
      "learning_rate": 6.094087953735423e-05,
      "loss": 0.0052,
      "step": 320
    },
    {
      "epoch": 1.5068493150684932,
      "grad_norm": 0.034867700189352036,
      "learning_rate": 5.833319600627753e-05,
      "loss": 0.0078,
      "step": 330
    },
    {
      "epoch": 1.5525114155251143,
      "grad_norm": 3.58373761177063,
      "learning_rate": 5.570197097619688e-05,
      "loss": 0.0083,
      "step": 340
    },
    {
      "epoch": 1.5981735159817352,
      "grad_norm": 0.47439834475517273,
      "learning_rate": 5.305463772737812e-05,
      "loss": 0.004,
      "step": 350
    },
    {
      "epoch": 1.643835616438356,
      "grad_norm": 0.07610837370157242,
      "learning_rate": 5.0398675046230835e-05,
      "loss": 0.0055,
      "step": 360
    },
    {
      "epoch": 1.6894977168949772,
      "grad_norm": 0.36772096157073975,
      "learning_rate": 4.7741586097539075e-05,
      "loss": 0.0113,
      "step": 370
    },
    {
      "epoch": 1.7351598173515983,
      "grad_norm": 0.9376148581504822,
      "learning_rate": 4.509087722782242e-05,
      "loss": 0.0019,
      "step": 380
    },
    {
      "epoch": 1.7808219178082192,
      "grad_norm": 0.03664730489253998,
      "learning_rate": 4.2454036759708765e-05,
      "loss": 0.0012,
      "step": 390
    },
    {
      "epoch": 1.82648401826484,
      "grad_norm": 0.11466465145349503,
      "learning_rate": 3.983851383722482e-05,
      "loss": 0.0041,
      "step": 400
    },
    {
      "epoch": 1.8721461187214612,
      "grad_norm": 0.39853817224502563,
      "learning_rate": 3.725169738176737e-05,
      "loss": 0.005,
      "step": 410
    },
    {
      "epoch": 1.9178082191780823,
      "grad_norm": 0.23475046455860138,
      "learning_rate": 3.470089521820502e-05,
      "loss": 0.0011,
      "step": 420
    },
    {
      "epoch": 1.9634703196347032,
      "grad_norm": 0.0034923828206956387,
      "learning_rate": 3.219331343007974e-05,
      "loss": 0.0002,
      "step": 430
    },
    {
      "epoch": 2.009132420091324,
      "grad_norm": 0.005950808059424162,
      "learning_rate": 2.9736036002230332e-05,
      "loss": 0.001,
      "step": 440
    },
    {
      "epoch": 2.0547945205479454,
      "grad_norm": 0.0011704614153131843,
      "learning_rate": 2.7336004808348093e-05,
      "loss": 0.0059,
      "step": 450
    },
    {
      "epoch": 2.1004566210045663,
      "grad_norm": 0.008990103378891945,
      "learning_rate": 2.500000000000001e-05,
      "loss": 0.0002,
      "step": 460
    },
    {
      "epoch": 2.146118721461187,
      "grad_norm": 0.0003893689427059144,
      "learning_rate": 2.273462085252146e-05,
      "loss": 0.0002,
      "step": 470
    },
    {
      "epoch": 2.191780821917808,
      "grad_norm": 0.004631975665688515,
      "learning_rate": 2.054626712188886e-05,
      "loss": 0.0022,
      "step": 480
    },
    {
      "epoch": 2.237442922374429,
      "grad_norm": 0.05920121446251869,
      "learning_rate": 1.8441120965239912e-05,
      "loss": 0.0007,
      "step": 490
    },
    {
      "epoch": 2.2831050228310503,
      "grad_norm": 0.0017018805956467986,
      "learning_rate": 1.642512947611622e-05,
      "loss": 0.0014,
      "step": 500
    },
    {
      "epoch": 2.328767123287671,
      "grad_norm": 0.005027814768254757,
      "learning_rate": 1.4503987883766857e-05,
      "loss": 0.0018,
      "step": 510
    },
    {
      "epoch": 2.374429223744292,
      "grad_norm": 0.4031725227832794,
      "learning_rate": 1.2683123463975143e-05,
      "loss": 0.0006,
      "step": 520
    },
    {
      "epoch": 2.4200913242009134,
      "grad_norm": 2.3317384719848633,
      "learning_rate": 1.0967680206861197e-05,
      "loss": 0.0012,
      "step": 530
    },
    {
      "epoch": 2.4657534246575343,
      "grad_norm": 0.013743817806243896,
      "learning_rate": 9.362504284973683e-06,
      "loss": 0.0012,
      "step": 540
    },
    {
      "epoch": 2.5114155251141552,
      "grad_norm": 0.007352674379944801,
      "learning_rate": 7.872130362724422e-06,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 2.557077625570776,
      "grad_norm": 0.00464088749140501,
      "learning_rate": 6.500768785841483e-06,
      "loss": 0.0001,
      "step": 560
    },
    {
      "epoch": 2.602739726027397,
      "grad_norm": 0.0012061174493283033,
      "learning_rate": 5.2522936870311955e-06,
      "loss": 0.0,
      "step": 570
    },
    {
      "epoch": 2.6484018264840183,
      "grad_norm": 0.0009686960838735104,
      "learning_rate": 4.130232041450866e-06,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 2.6940639269406392,
      "grad_norm": 0.003948208875954151,
      "learning_rate": 3.1377537029107174e-06,
      "loss": 0.0007,
      "step": 590
    },
    {
      "epoch": 2.73972602739726,
      "grad_norm": 0.014138332568109035,
      "learning_rate": 2.277662448953066e-06,
      "loss": 0.0009,
      "step": 600
    },
    {
      "epoch": 2.7853881278538815,
      "grad_norm": 0.04503648355603218,
      "learning_rate": 1.5523880601066798e-06,
      "loss": 0.0001,
      "step": 610
    },
    {
      "epoch": 2.8310502283105023,
      "grad_norm": 0.002827584743499756,
      "learning_rate": 9.639794556925042e-07,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 2.8767123287671232,
      "grad_norm": 0.007753210142254829,
      "learning_rate": 5.140989055724687e-07,
      "loss": 0.0002,
      "step": 630
    },
    {
      "epoch": 2.922374429223744,
      "grad_norm": 0.04592680186033249,
      "learning_rate": 2.0401733419315727e-07,
      "loss": 0.0001,
      "step": 640
    },
    {
      "epoch": 2.968036529680365,
      "grad_norm": 0.014635635539889336,
      "learning_rate": 3.461073019064842e-08,
      "loss": 0.0017,
      "step": 650
    },
    {
      "epoch": 3.0,
      "step": 657,
      "total_flos": 4.6556510152137114e+17,
      "train_loss": 0.09116981649481447,
      "train_runtime": 1454.0827,
      "train_samples_per_second": 7.229,
      "train_steps_per_second": 0.452
    }
  ],
  "logging_steps": 10,
  "max_steps": 657,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.6556510152137114e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
