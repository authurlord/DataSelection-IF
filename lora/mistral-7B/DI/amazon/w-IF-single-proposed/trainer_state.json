{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 552,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05434782608695652,
      "grad_norm": 47.8241081237793,
      "learning_rate": 1.785714285714286e-05,
      "loss": 5.581,
      "step": 10
    },
    {
      "epoch": 0.10869565217391304,
      "grad_norm": 8.843596458435059,
      "learning_rate": 3.571428571428572e-05,
      "loss": 1.0147,
      "step": 20
    },
    {
      "epoch": 0.16304347826086957,
      "grad_norm": 2.958380699157715,
      "learning_rate": 5.3571428571428575e-05,
      "loss": 0.1519,
      "step": 30
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 2.2221977710723877,
      "learning_rate": 7.142857142857143e-05,
      "loss": 0.1044,
      "step": 40
    },
    {
      "epoch": 0.2717391304347826,
      "grad_norm": 2.0529122352600098,
      "learning_rate": 8.92857142857143e-05,
      "loss": 0.1016,
      "step": 50
    },
    {
      "epoch": 0.32608695652173914,
      "grad_norm": 1.384753942489624,
      "learning_rate": 9.998395376482152e-05,
      "loss": 0.1071,
      "step": 60
    },
    {
      "epoch": 0.3804347826086957,
      "grad_norm": 1.682694435119629,
      "learning_rate": 9.980355187882605e-05,
      "loss": 0.1078,
      "step": 70
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 1.2228938341140747,
      "learning_rate": 9.942341621640558e-05,
      "loss": 0.0985,
      "step": 80
    },
    {
      "epoch": 0.4891304347826087,
      "grad_norm": 0.8049055337905884,
      "learning_rate": 9.884507128592435e-05,
      "loss": 0.0911,
      "step": 90
    },
    {
      "epoch": 0.5434782608695652,
      "grad_norm": 1.5657212734222412,
      "learning_rate": 9.807083650061063e-05,
      "loss": 0.0884,
      "step": 100
    },
    {
      "epoch": 0.5978260869565217,
      "grad_norm": 0.6505441069602966,
      "learning_rate": 9.710381687670675e-05,
      "loss": 0.1104,
      "step": 110
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 1.3734471797943115,
      "learning_rate": 9.594789058101153e-05,
      "loss": 0.0743,
      "step": 120
    },
    {
      "epoch": 0.7065217391304348,
      "grad_norm": 0.9640006422996521,
      "learning_rate": 9.46076933777546e-05,
      "loss": 0.0863,
      "step": 130
    },
    {
      "epoch": 0.7608695652173914,
      "grad_norm": 0.4518444836139679,
      "learning_rate": 9.308860003717748e-05,
      "loss": 0.0851,
      "step": 140
    },
    {
      "epoch": 0.8152173913043478,
      "grad_norm": 2.805725336074829,
      "learning_rate": 9.139670278038108e-05,
      "loss": 0.0751,
      "step": 150
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.9862080812454224,
      "learning_rate": 8.953878684688493e-05,
      "loss": 0.0637,
      "step": 160
    },
    {
      "epoch": 0.9239130434782609,
      "grad_norm": 0.8009901642799377,
      "learning_rate": 8.752230328288313e-05,
      "loss": 0.0779,
      "step": 170
    },
    {
      "epoch": 0.9782608695652174,
      "grad_norm": 1.24091374874115,
      "learning_rate": 8.535533905932738e-05,
      "loss": 0.0907,
      "step": 180
    },
    {
      "epoch": 1.0326086956521738,
      "grad_norm": 0.9697747230529785,
      "learning_rate": 8.304658463967705e-05,
      "loss": 0.0607,
      "step": 190
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.6713188290596008,
      "learning_rate": 8.060529912738315e-05,
      "loss": 0.0473,
      "step": 200
    },
    {
      "epoch": 1.141304347826087,
      "grad_norm": 0.8735457062721252,
      "learning_rate": 7.804127313288024e-05,
      "loss": 0.0571,
      "step": 210
    },
    {
      "epoch": 1.1956521739130435,
      "grad_norm": 1.1824345588684082,
      "learning_rate": 7.536478950900538e-05,
      "loss": 0.0338,
      "step": 220
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9940593242645264,
      "learning_rate": 7.258658211231235e-05,
      "loss": 0.0427,
      "step": 230
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.36847159266471863,
      "learning_rate": 6.971779275566593e-05,
      "loss": 0.0472,
      "step": 240
    },
    {
      "epoch": 1.358695652173913,
      "grad_norm": 0.6852331757545471,
      "learning_rate": 6.676992652475486e-05,
      "loss": 0.037,
      "step": 250
    },
    {
      "epoch": 1.4130434782608696,
      "grad_norm": 0.7785546183586121,
      "learning_rate": 6.37548056377239e-05,
      "loss": 0.0498,
      "step": 260
    },
    {
      "epoch": 1.4673913043478262,
      "grad_norm": 0.8679618239402771,
      "learning_rate": 6.068452203296754e-05,
      "loss": 0.051,
      "step": 270
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 0.49953368306159973,
      "learning_rate": 5.757138887522884e-05,
      "loss": 0.0406,
      "step": 280
    },
    {
      "epoch": 1.5760869565217392,
      "grad_norm": 0.47202277183532715,
      "learning_rate": 5.4427891174485016e-05,
      "loss": 0.0265,
      "step": 290
    },
    {
      "epoch": 1.6304347826086958,
      "grad_norm": 1.2572457790374756,
      "learning_rate": 5.1266635715659395e-05,
      "loss": 0.0385,
      "step": 300
    },
    {
      "epoch": 1.6847826086956523,
      "grad_norm": 0.8878734111785889,
      "learning_rate": 4.8100300499963045e-05,
      "loss": 0.0363,
      "step": 310
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.8931494355201721,
      "learning_rate": 4.49415839006284e-05,
      "loss": 0.0443,
      "step": 320
    },
    {
      "epoch": 1.7934782608695652,
      "grad_norm": 0.8381912708282471,
      "learning_rate": 4.180315373694225e-05,
      "loss": 0.0401,
      "step": 330
    },
    {
      "epoch": 1.8478260869565217,
      "grad_norm": 0.5204238891601562,
      "learning_rate": 3.869759647081326e-05,
      "loss": 0.0321,
      "step": 340
    },
    {
      "epoch": 1.9021739130434783,
      "grad_norm": 0.36053428053855896,
      "learning_rate": 3.563736672961777e-05,
      "loss": 0.0448,
      "step": 350
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 0.9117160439491272,
      "learning_rate": 3.263473735775899e-05,
      "loss": 0.0427,
      "step": 360
    },
    {
      "epoch": 2.010869565217391,
      "grad_norm": 0.43279218673706055,
      "learning_rate": 2.970175019725465e-05,
      "loss": 0.0323,
      "step": 370
    },
    {
      "epoch": 2.0652173913043477,
      "grad_norm": 0.15544387698173523,
      "learning_rate": 2.6850167794743962e-05,
      "loss": 0.0126,
      "step": 380
    },
    {
      "epoch": 2.119565217391304,
      "grad_norm": 0.16120043396949768,
      "learning_rate": 2.409142622858992e-05,
      "loss": 0.007,
      "step": 390
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.28078025579452515,
      "learning_rate": 2.1436589245260376e-05,
      "loss": 0.0092,
      "step": 400
    },
    {
      "epoch": 2.2282608695652173,
      "grad_norm": 0.05967940017580986,
      "learning_rate": 1.8896303888921314e-05,
      "loss": 0.011,
      "step": 410
    },
    {
      "epoch": 2.282608695652174,
      "grad_norm": 0.7012233734130859,
      "learning_rate": 1.648075780218607e-05,
      "loss": 0.0147,
      "step": 420
    },
    {
      "epoch": 2.3369565217391304,
      "grad_norm": 0.21308277547359467,
      "learning_rate": 1.4199638369263857e-05,
      "loss": 0.0167,
      "step": 430
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": 0.3627336621284485,
      "learning_rate": 1.2062093865360458e-05,
      "loss": 0.0109,
      "step": 440
    },
    {
      "epoch": 2.4456521739130435,
      "grad_norm": 0.16228607296943665,
      "learning_rate": 1.0076696768139326e-05,
      "loss": 0.0085,
      "step": 450
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.7843949794769287,
      "learning_rate": 8.251409378379638e-06,
      "loss": 0.0107,
      "step": 460
    },
    {
      "epoch": 2.5543478260869565,
      "grad_norm": 0.3962894678115845,
      "learning_rate": 6.593551887707578e-06,
      "loss": 0.0087,
      "step": 470
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.4494713246822357,
      "learning_rate": 5.109773021462921e-06,
      "loss": 0.0085,
      "step": 480
    },
    {
      "epoch": 2.6630434782608696,
      "grad_norm": 0.2793439030647278,
      "learning_rate": 3.8060233744356633e-06,
      "loss": 0.0064,
      "step": 490
    },
    {
      "epoch": 2.717391304347826,
      "grad_norm": 0.2920444905757904,
      "learning_rate": 2.6875315464081564e-06,
      "loss": 0.012,
      "step": 500
    },
    {
      "epoch": 2.7717391304347827,
      "grad_norm": 0.5550379157066345,
      "learning_rate": 1.7587831732092718e-06,
      "loss": 0.0084,
      "step": 510
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": 0.20607714354991913,
      "learning_rate": 1.0235029373752758e-06,
      "loss": 0.0077,
      "step": 520
    },
    {
      "epoch": 2.880434782608696,
      "grad_norm": 0.38838034868240356,
      "learning_rate": 4.846396305624612e-07,
      "loss": 0.0114,
      "step": 530
    },
    {
      "epoch": 2.9347826086956523,
      "grad_norm": 0.3470102846622467,
      "learning_rate": 1.4435432761762958e-07,
      "loss": 0.0062,
      "step": 540
    },
    {
      "epoch": 2.9891304347826084,
      "grad_norm": 0.23908516764640808,
      "learning_rate": 4.011719733570951e-09,
      "loss": 0.0114,
      "step": 550
    },
    {
      "epoch": 3.0,
      "step": 552,
      "total_flos": 3.911597201167483e+17,
      "train_loss": 0.16481145937670616,
      "train_runtime": 1209.6494,
      "train_samples_per_second": 7.299,
      "train_steps_per_second": 0.456
    }
  ],
  "logging_steps": 10,
  "max_steps": 552,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.911597201167483e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
