{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 735,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04081632653061224,
      "grad_norm": 36.43486022949219,
      "learning_rate": 1.3513513513513515e-05,
      "loss": 4.4479,
      "step": 10
    },
    {
      "epoch": 0.08163265306122448,
      "grad_norm": 16.34500503540039,
      "learning_rate": 2.702702702702703e-05,
      "loss": 1.3161,
      "step": 20
    },
    {
      "epoch": 0.12244897959183673,
      "grad_norm": 4.514997959136963,
      "learning_rate": 4.0540540540540545e-05,
      "loss": 0.392,
      "step": 30
    },
    {
      "epoch": 0.16326530612244897,
      "grad_norm": 2.7438158988952637,
      "learning_rate": 5.405405405405406e-05,
      "loss": 0.174,
      "step": 40
    },
    {
      "epoch": 0.20408163265306123,
      "grad_norm": 2.773007869720459,
      "learning_rate": 6.756756756756757e-05,
      "loss": 0.0564,
      "step": 50
    },
    {
      "epoch": 0.24489795918367346,
      "grad_norm": 2.8836159706115723,
      "learning_rate": 8.108108108108109e-05,
      "loss": 0.0505,
      "step": 60
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 1.9845224618911743,
      "learning_rate": 9.45945945945946e-05,
      "loss": 0.0526,
      "step": 70
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 1.172025442123413,
      "learning_rate": 9.997967128605077e-05,
      "loss": 0.0391,
      "step": 80
    },
    {
      "epoch": 0.3673469387755102,
      "grad_norm": 1.9755167961120605,
      "learning_rate": 9.985550011399889e-05,
      "loss": 0.0668,
      "step": 90
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 0.9312137365341187,
      "learning_rate": 9.961873159705425e-05,
      "loss": 0.0442,
      "step": 100
    },
    {
      "epoch": 0.4489795918367347,
      "grad_norm": 1.9413396120071411,
      "learning_rate": 9.92699004707285e-05,
      "loss": 0.0589,
      "step": 110
    },
    {
      "epoch": 0.4897959183673469,
      "grad_norm": 1.5565171241760254,
      "learning_rate": 9.880979456100974e-05,
      "loss": 0.0367,
      "step": 120
    },
    {
      "epoch": 0.5306122448979592,
      "grad_norm": 0.9560901522636414,
      "learning_rate": 9.823945300507816e-05,
      "loss": 0.0187,
      "step": 130
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.747117280960083,
      "learning_rate": 9.756016390444173e-05,
      "loss": 0.0488,
      "step": 140
    },
    {
      "epoch": 0.6122448979591837,
      "grad_norm": 3.4203884601593018,
      "learning_rate": 9.677346141579277e-05,
      "loss": 0.0272,
      "step": 150
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 1.6247884035110474,
      "learning_rate": 9.588112228615496e-05,
      "loss": 0.0245,
      "step": 160
    },
    {
      "epoch": 0.6938775510204082,
      "grad_norm": 0.9031839966773987,
      "learning_rate": 9.488516184014667e-05,
      "loss": 0.0259,
      "step": 170
    },
    {
      "epoch": 0.7346938775510204,
      "grad_norm": 2.901160717010498,
      "learning_rate": 9.378782942842292e-05,
      "loss": 0.0394,
      "step": 180
    },
    {
      "epoch": 0.7755102040816326,
      "grad_norm": 1.0972501039505005,
      "learning_rate": 9.259160334757574e-05,
      "loss": 0.0377,
      "step": 190
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 0.06339553743600845,
      "learning_rate": 9.129918524296594e-05,
      "loss": 0.0281,
      "step": 200
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.5852122902870178,
      "learning_rate": 8.99134940071277e-05,
      "loss": 0.0308,
      "step": 210
    },
    {
      "epoch": 0.8979591836734694,
      "grad_norm": 0.7666665315628052,
      "learning_rate": 8.8437659187526e-05,
      "loss": 0.0301,
      "step": 220
    },
    {
      "epoch": 0.9387755102040817,
      "grad_norm": 1.4714747667312622,
      "learning_rate": 8.687501391855539e-05,
      "loss": 0.0196,
      "step": 230
    },
    {
      "epoch": 0.9795918367346939,
      "grad_norm": 0.9911584258079529,
      "learning_rate": 8.5229087393743e-05,
      "loss": 0.0275,
      "step": 240
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.42202985286712646,
      "learning_rate": 8.35035968951572e-05,
      "loss": 0.015,
      "step": 250
    },
    {
      "epoch": 1.0612244897959184,
      "grad_norm": 1.5289491415023804,
      "learning_rate": 8.170243939802309e-05,
      "loss": 0.014,
      "step": 260
    },
    {
      "epoch": 1.1020408163265305,
      "grad_norm": 0.8011652827262878,
      "learning_rate": 7.982968276950568e-05,
      "loss": 0.0233,
      "step": 270
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.29768985509872437,
      "learning_rate": 7.788955658153829e-05,
      "loss": 0.0155,
      "step": 280
    },
    {
      "epoch": 1.183673469387755,
      "grad_norm": 0.5711266994476318,
      "learning_rate": 7.588644255844464e-05,
      "loss": 0.014,
      "step": 290
    },
    {
      "epoch": 1.2244897959183674,
      "grad_norm": 0.03395003825426102,
      "learning_rate": 7.382486468092898e-05,
      "loss": 0.0166,
      "step": 300
    },
    {
      "epoch": 1.2653061224489797,
      "grad_norm": 1.2128322124481201,
      "learning_rate": 7.170947896878392e-05,
      "loss": 0.0199,
      "step": 310
    },
    {
      "epoch": 1.306122448979592,
      "grad_norm": 0.7623024582862854,
      "learning_rate": 6.954506296539112e-05,
      "loss": 0.013,
      "step": 320
    },
    {
      "epoch": 1.346938775510204,
      "grad_norm": 0.49214521050453186,
      "learning_rate": 6.73365049477645e-05,
      "loss": 0.0145,
      "step": 330
    },
    {
      "epoch": 1.3877551020408163,
      "grad_norm": 0.06299881637096405,
      "learning_rate": 6.508879288650431e-05,
      "loss": 0.008,
      "step": 340
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.4469776153564453,
      "learning_rate": 6.280700318059562e-05,
      "loss": 0.0072,
      "step": 350
    },
    {
      "epoch": 1.469387755102041,
      "grad_norm": 1.3652061223983765,
      "learning_rate": 6.049628919249399e-05,
      "loss": 0.0111,
      "step": 360
    },
    {
      "epoch": 1.510204081632653,
      "grad_norm": 0.9855672717094421,
      "learning_rate": 5.816186960939084e-05,
      "loss": 0.0084,
      "step": 370
    },
    {
      "epoch": 1.5510204081632653,
      "grad_norm": 1.7508575916290283,
      "learning_rate": 5.580901665694471e-05,
      "loss": 0.0112,
      "step": 380
    },
    {
      "epoch": 1.5918367346938775,
      "grad_norm": 1.7806588411331177,
      "learning_rate": 5.344304419209748e-05,
      "loss": 0.0073,
      "step": 390
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 0.26720625162124634,
      "learning_rate": 5.106929570186706e-05,
      "loss": 0.0094,
      "step": 400
    },
    {
      "epoch": 1.6734693877551021,
      "grad_norm": 0.8632204532623291,
      "learning_rate": 4.869313223522158e-05,
      "loss": 0.0102,
      "step": 410
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.3268177807331085,
      "learning_rate": 4.631992029529037e-05,
      "loss": 0.0031,
      "step": 420
    },
    {
      "epoch": 1.7551020408163265,
      "grad_norm": 0.4895034432411194,
      "learning_rate": 4.395501971925676e-05,
      "loss": 0.0116,
      "step": 430
    },
    {
      "epoch": 1.7959183673469388,
      "grad_norm": 0.9117112755775452,
      "learning_rate": 4.16037715733058e-05,
      "loss": 0.0103,
      "step": 440
    },
    {
      "epoch": 1.836734693877551,
      "grad_norm": 0.019520388916134834,
      "learning_rate": 3.9271486089965694e-05,
      "loss": 0.0062,
      "step": 450
    },
    {
      "epoch": 1.8775510204081631,
      "grad_norm": 0.08867088705301285,
      "learning_rate": 3.696343067508651e-05,
      "loss": 0.008,
      "step": 460
    },
    {
      "epoch": 1.9183673469387754,
      "grad_norm": 0.6991797685623169,
      "learning_rate": 3.468481801154148e-05,
      "loss": 0.0198,
      "step": 470
    },
    {
      "epoch": 1.9591836734693877,
      "grad_norm": 0.5131143927574158,
      "learning_rate": 3.2440794286518896e-05,
      "loss": 0.0121,
      "step": 480
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.14134618639945984,
      "learning_rate": 3.0236427568992842e-05,
      "loss": 0.0053,
      "step": 490
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.4779711067676544,
      "learning_rate": 2.807669636362169e-05,
      "loss": 0.002,
      "step": 500
    },
    {
      "epoch": 2.0816326530612246,
      "grad_norm": 0.05242765322327614,
      "learning_rate": 2.5966478366925406e-05,
      "loss": 0.0016,
      "step": 510
    },
    {
      "epoch": 2.122448979591837,
      "grad_norm": 0.3391241133213043,
      "learning_rate": 2.391053945113533e-05,
      "loss": 0.0016,
      "step": 520
    },
    {
      "epoch": 2.163265306122449,
      "grad_norm": 0.01540691964328289,
      "learning_rate": 2.191352290059621e-05,
      "loss": 0.0007,
      "step": 530
    },
    {
      "epoch": 2.204081632653061,
      "grad_norm": 0.2574493885040283,
      "learning_rate": 1.9979938925029827e-05,
      "loss": 0.0015,
      "step": 540
    },
    {
      "epoch": 2.2448979591836733,
      "grad_norm": 0.003610443091019988,
      "learning_rate": 1.811415447334408e-05,
      "loss": 0.0016,
      "step": 550
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.027651486918330193,
      "learning_rate": 1.632038337099297e-05,
      "loss": 0.0011,
      "step": 560
    },
    {
      "epoch": 2.326530612244898,
      "grad_norm": 0.03713172301650047,
      "learning_rate": 1.460267680316184e-05,
      "loss": 0.0006,
      "step": 570
    },
    {
      "epoch": 2.36734693877551,
      "grad_norm": 0.005085852928459644,
      "learning_rate": 1.296491416527147e-05,
      "loss": 0.0004,
      "step": 580
    },
    {
      "epoch": 2.4081632653061225,
      "grad_norm": 0.07419341057538986,
      "learning_rate": 1.1410794301464817e-05,
      "loss": 0.0006,
      "step": 590
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 0.30408796668052673,
      "learning_rate": 9.943827150864144e-06,
      "loss": 0.0005,
      "step": 600
    },
    {
      "epoch": 2.489795918367347,
      "grad_norm": 0.18364858627319336,
      "learning_rate": 8.567325820465156e-06,
      "loss": 0.001,
      "step": 610
    },
    {
      "epoch": 2.5306122448979593,
      "grad_norm": 0.0772504135966301,
      "learning_rate": 7.28439910257141e-06,
      "loss": 0.0018,
      "step": 620
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.03949340432882309,
      "learning_rate": 6.097944453668081e-06,
      "loss": 0.0007,
      "step": 630
    },
    {
      "epoch": 2.612244897959184,
      "grad_norm": 0.005067718215286732,
      "learning_rate": 5.0106414505921575e-06,
      "loss": 0.0016,
      "step": 640
    },
    {
      "epoch": 2.6530612244897958,
      "grad_norm": 0.2373161017894745,
      "learning_rate": 4.024945738778163e-06,
      "loss": 0.0009,
      "step": 650
    },
    {
      "epoch": 2.693877551020408,
      "grad_norm": 0.006680735386908054,
      "learning_rate": 3.1430834862470393e-06,
      "loss": 0.0002,
      "step": 660
    },
    {
      "epoch": 2.7346938775510203,
      "grad_norm": 0.05914086475968361,
      "learning_rate": 2.3670463558638555e-06,
      "loss": 0.0013,
      "step": 670
    },
    {
      "epoch": 2.7755102040816326,
      "grad_norm": 0.005891785956919193,
      "learning_rate": 1.6985870072192156e-06,
      "loss": 0.0004,
      "step": 680
    },
    {
      "epoch": 2.816326530612245,
      "grad_norm": 0.003156296443194151,
      "learning_rate": 1.1392151382933647e-06,
      "loss": 0.0008,
      "step": 690
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.08643171191215515,
      "learning_rate": 6.901940758427206e-07,
      "loss": 0.0006,
      "step": 700
    },
    {
      "epoch": 2.8979591836734695,
      "grad_norm": 0.36880090832710266,
      "learning_rate": 3.5253792220940606e-07,
      "loss": 0.0019,
      "step": 710
    },
    {
      "epoch": 2.938775510204082,
      "grad_norm": 0.0038231275975704193,
      "learning_rate": 1.2700926499756293e-07,
      "loss": 0.0005,
      "step": 720
    },
    {
      "epoch": 2.979591836734694,
      "grad_norm": 0.009248516522347927,
      "learning_rate": 1.4117454789208672e-08,
      "loss": 0.0003,
      "step": 730
    },
    {
      "epoch": 3.0,
      "step": 735,
      "total_flos": 5.20837670771884e+17,
      "train_loss": 0.10085546051684235,
      "train_runtime": 1617.7938,
      "train_samples_per_second": 7.252,
      "train_steps_per_second": 0.454
    }
  ],
  "logging_steps": 10,
  "max_steps": 735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.20837670771884e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
