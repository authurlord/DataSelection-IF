{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 441,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06802721088435375,
      "grad_norm": 23.089075088500977,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 3.349,
      "step": 10
    },
    {
      "epoch": 0.1360544217687075,
      "grad_norm": 12.7747163772583,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.5548,
      "step": 20
    },
    {
      "epoch": 0.20408163265306123,
      "grad_norm": 0.6040875315666199,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0978,
      "step": 30
    },
    {
      "epoch": 0.272108843537415,
      "grad_norm": 0.871001124382019,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.0515,
      "step": 40
    },
    {
      "epoch": 0.3401360544217687,
      "grad_norm": 0.2906267046928406,
      "learning_rate": 9.996066923030484e-05,
      "loss": 0.0446,
      "step": 50
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 3.7199866771698,
      "learning_rate": 9.964639423366442e-05,
      "loss": 0.0133,
      "step": 60
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 0.6686229109764099,
      "learning_rate": 9.901982117093786e-05,
      "loss": 0.0318,
      "step": 70
    },
    {
      "epoch": 0.54421768707483,
      "grad_norm": 0.8777481317520142,
      "learning_rate": 9.808489146745466e-05,
      "loss": 0.0121,
      "step": 80
    },
    {
      "epoch": 0.6122448979591837,
      "grad_norm": 1.4440205097198486,
      "learning_rate": 9.68474862499881e-05,
      "loss": 0.0358,
      "step": 90
    },
    {
      "epoch": 0.6802721088435374,
      "grad_norm": 1.230894684791565,
      "learning_rate": 9.53153893518325e-05,
      "loss": 0.0132,
      "step": 100
    },
    {
      "epoch": 0.7482993197278912,
      "grad_norm": 2.5702292919158936,
      "learning_rate": 9.349823834900395e-05,
      "loss": 0.0245,
      "step": 110
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 0.02611689828336239,
      "learning_rate": 9.140746393556854e-05,
      "loss": 0.0119,
      "step": 120
    },
    {
      "epoch": 0.8843537414965986,
      "grad_norm": 0.03306883946061134,
      "learning_rate": 8.905621801945467e-05,
      "loss": 0.0091,
      "step": 130
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.121004581451416,
      "learning_rate": 8.645929099105887e-05,
      "loss": 0.0118,
      "step": 140
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 1.324723720550537,
      "learning_rate": 8.363301868506264e-05,
      "loss": 0.0055,
      "step": 150
    },
    {
      "epoch": 1.08843537414966,
      "grad_norm": 0.12027827650308609,
      "learning_rate": 8.059517962071233e-05,
      "loss": 0.006,
      "step": 160
    },
    {
      "epoch": 1.1564625850340136,
      "grad_norm": 0.7083194851875305,
      "learning_rate": 7.736488316696663e-05,
      "loss": 0.0057,
      "step": 170
    },
    {
      "epoch": 1.2244897959183674,
      "grad_norm": 0.014392786659300327,
      "learning_rate": 7.396244933600285e-05,
      "loss": 0.013,
      "step": 180
    },
    {
      "epoch": 1.2925170068027212,
      "grad_norm": 108.80509185791016,
      "learning_rate": 7.040928096123516e-05,
      "loss": 0.0197,
      "step": 190
    },
    {
      "epoch": 1.3605442176870748,
      "grad_norm": 3.0646464824676514,
      "learning_rate": 6.672772906390177e-05,
      "loss": 0.0064,
      "step": 200
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.07787089794874191,
      "learning_rate": 6.294095225512603e-05,
      "loss": 0.0056,
      "step": 210
    },
    {
      "epoch": 1.4965986394557822,
      "grad_norm": 0.66605144739151,
      "learning_rate": 5.9072771057875134e-05,
      "loss": 0.0083,
      "step": 220
    },
    {
      "epoch": 1.564625850340136,
      "grad_norm": 1.436870813369751,
      "learning_rate": 5.514751806519673e-05,
      "loss": 0.0067,
      "step": 230
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 0.018495803698897362,
      "learning_rate": 5.1189884877305375e-05,
      "loss": 0.0029,
      "step": 240
    },
    {
      "epoch": 1.7006802721088436,
      "grad_norm": 0.02502557449042797,
      "learning_rate": 4.7224766780353005e-05,
      "loss": 0.015,
      "step": 250
    },
    {
      "epoch": 1.7687074829931972,
      "grad_norm": 0.22583098709583282,
      "learning_rate": 4.3277106143923416e-05,
      "loss": 0.0028,
      "step": 260
    },
    {
      "epoch": 1.836734693877551,
      "grad_norm": 0.0198652483522892,
      "learning_rate": 3.937173552235117e-05,
      "loss": 0.0012,
      "step": 270
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 0.05193839967250824,
      "learning_rate": 3.553322144682737e-05,
      "loss": 0.0036,
      "step": 280
    },
    {
      "epoch": 1.9727891156462585,
      "grad_norm": 0.030081480741500854,
      "learning_rate": 3.178570989091028e-05,
      "loss": 0.0028,
      "step": 290
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.004424124024808407,
      "learning_rate": 2.8152774381532033e-05,
      "loss": 0.001,
      "step": 300
    },
    {
      "epoch": 2.108843537414966,
      "grad_norm": 0.6890411972999573,
      "learning_rate": 2.4657267710950858e-05,
      "loss": 0.0005,
      "step": 310
    },
    {
      "epoch": 2.17687074829932,
      "grad_norm": 0.011058658361434937,
      "learning_rate": 2.132117818244771e-05,
      "loss": 0.0033,
      "step": 320
    },
    {
      "epoch": 2.2448979591836733,
      "grad_norm": 0.0027984173502773046,
      "learning_rate": 1.8165491294045593e-05,
      "loss": 0.0015,
      "step": 330
    },
    {
      "epoch": 2.312925170068027,
      "grad_norm": 0.00918616447597742,
      "learning_rate": 1.5210057730323617e-05,
      "loss": 0.0002,
      "step": 340
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.061603982001543045,
      "learning_rate": 1.2473468492715895e-05,
      "loss": 0.0002,
      "step": 350
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 0.0009043778409250081,
      "learning_rate": 9.972937953781986e-06,
      "loss": 0.0002,
      "step": 360
    },
    {
      "epoch": 2.5170068027210886,
      "grad_norm": 0.020987194031476974,
      "learning_rate": 7.724195571089787e-06,
      "loss": 0.0001,
      "step": 370
    },
    {
      "epoch": 2.5850340136054424,
      "grad_norm": 0.0045067016035318375,
      "learning_rate": 5.7413869418791784e-06,
      "loss": 0.0002,
      "step": 380
    },
    {
      "epoch": 2.6530612244897958,
      "grad_norm": 0.005202644504606724,
      "learning_rate": 4.036984820916723e-06,
      "loss": 0.0013,
      "step": 390
    },
    {
      "epoch": 2.7210884353741496,
      "grad_norm": 1.7458100318908691,
      "learning_rate": 2.621710661279253e-06,
      "loss": 0.0022,
      "step": 400
    },
    {
      "epoch": 2.7891156462585034,
      "grad_norm": 0.0055892555974423885,
      "learning_rate": 1.5044671716097413e-06,
      "loss": 0.0001,
      "step": 410
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.008151457644999027,
      "learning_rate": 6.922823140906753e-07,
      "loss": 0.0005,
      "step": 420
    },
    {
      "epoch": 2.925170068027211,
      "grad_norm": 0.0011853381292894483,
      "learning_rate": 1.9026509541272275e-07,
      "loss": 0.0001,
      "step": 430
    },
    {
      "epoch": 2.9931972789115644,
      "grad_norm": 0.01289326511323452,
      "learning_rate": 1.5734288333457692e-09,
      "loss": 0.0008,
      "step": 440
    }
  ],
  "logging_steps": 10,
  "max_steps": 441,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.125026024765522e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
