{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas(desc='pandas bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTA task WebTable Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check https://github.com/ysunbp/RECA-paper/tree/main/WebTables to download raw-data(k0-k4) for 5-fold validation\n",
    "- for simplicity, we treat `k3` as test data, and sample 20% of `k0,k1,k2,k4` as training data. The selection is listed in `index` column\n",
    "- We furthur demonstrate how to merge multiple sub-tables in original file into one dataframe, take `k3` as an example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def merge_json_files_in_folder(folder_path):\n",
    "    # 初始化一个空的DataFrame来存放所有数据\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # 遍历文件夹中的每个文件\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # 确保只处理JSON文件\n",
    "        if file_path.endswith('.json'):\n",
    "            # 读取JSON文件\n",
    "            df = pd.read_json(file_path, lines=True)\n",
    "            \n",
    "            # 合并到主DataFrame\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# 使用函数\n",
    "folder_path = '../raw_data/CTA/WebTable/K3'  # 替换为你的文件夹路径\n",
    "k3 = merge_json_files_in_folder(folder_path)\n",
    "def append_content(row):\n",
    "    id = row[0]\n",
    "    content = np.array(pd.read_csv('/data/yanmengyi/simpleT5-main/examples/KGC/sato-table/sato_tables/multionly/K3/%s' % id).fillna('').drop_duplicates()).tolist()\n",
    "    return content\n",
    "k3['content'] = k3.progress_apply(append_content,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "webtable_train = pd.read_csv('../raw_dataset/CTA/WebTable/CTA_webtable_train_few_shot.csv',index_col=0)\n",
    "webtable_test = pd.read_csv('../raw_dataset/CTA/WebTable/CTA_webtable_test.csv',index_col=0)\n",
    "webtable_test['index'] = webtable_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_SBERT_Dict_WebTable(row): ## This is for WebTable\n",
    "    target = int(row['target'])\n",
    "    label = row['label']\n",
    "    try:\n",
    "        content = np.array(eval(row['content']))\n",
    "    except: ## inf is the occupation format, replace it with empty string\n",
    "        content = np.array(eval(row['content'].replace('inf',\"''\")))\n",
    "    header = eval(row['header'])\n",
    "    length = content.shape[1]\n",
    "    text_former = []\n",
    "    # text_latter = []\n",
    "    for t in content:\n",
    "        text = {}\n",
    "        for l in range(length):\n",
    "            if(l!=target): ## mask label列\n",
    "                text[header[l]] = t[l]\n",
    "            else:\n",
    "                text['col_1'] = t[l]\n",
    "        # text += '[SEP]'\n",
    "        # text += '%s: %s|' % ('col_1',t[target])\n",
    "        text_former.append(text)\n",
    "    return text_former\n",
    "import json\n",
    "def random_dicts_to_str(input_list, k=5):\n",
    "    \"\"\"\n",
    "    Convert k random dictionaries from a list to JSON strings and join them into a single string separated by newlines.\n",
    "    \n",
    "    Parameters:\n",
    "    input_list (list): The input list containing dictionary elements.\n",
    "    k (int): The number of dictionaries to randomly select and convert to JSON strings.\n",
    "    \n",
    "    Returns:\n",
    "    str: A string composed of k random JSON strings from the input list, separated by newlines.\n",
    "    \"\"\"\n",
    "    # 确保 k 不大于列表的长度\n",
    "    k = min(k, len(input_list))\n",
    "    \n",
    "    # 随机选择 k 个字典\n",
    "    selected_dicts = random.sample(input_list, k)\n",
    "    # 将选中的字典转换为JSON字符串\n",
    "    if(len(selected_dicts)>1):\n",
    "        # json_strings = [json.dumps(d, ensure_ascii=True) for d in selected_dicts]\n",
    "        json_strings = [str(d) for d in selected_dicts]\n",
    "    else: ## 只有一行\n",
    "        json_strings = [str(selected_dicts[0])]\n",
    "    \n",
    "    # 将JSON字符串以换行符分隔拼接成一个字符串\n",
    "    \n",
    "    result_str = '\\n'.join(json_strings)\n",
    "    \n",
    "    return result_str\n",
    "def sample_rows_with_all_values_WebTable(df, k):\n",
    "    \"\"\"\n",
    "    Randomly sample k rows from a dataframe, ensuring that the sampled rows include all unique values in the 'pred' column.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe.\n",
    "    k (int): The number of rows to sample.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A dataframe consisting of k randomly sampled rows.\n",
    "    \"\"\"\n",
    "    # 确保k不小于pred列中唯一值的数量\n",
    "    unique_values = df['label'].unique()\n",
    "    num_unique_values = len(unique_values)\n",
    "    k = max(k, num_unique_values)\n",
    "    \n",
    "    # 分别从每个唯一值对应的行中随机选取一行\n",
    "    sampled_rows = [df[df['label'] == val].sample(1) for val in unique_values]\n",
    "    \n",
    "    # 如果需要更多的行来达到k，从整个DataFrame中随机选取剩余的行\n",
    "    additional_rows_needed = k - num_unique_values\n",
    "    if additional_rows_needed > 0:\n",
    "        # 从除了已选的行之外的行中随机选择\n",
    "        remaining_rows = df[~df.index.isin([row.index[0] for row in sampled_rows])]\n",
    "        additional_sampled_rows = remaining_rows.sample(additional_rows_needed)\n",
    "        sampled_rows.append(additional_sampled_rows)\n",
    "    \n",
    "    # 将所有选中的行合并成一个DataFrame\n",
    "    sampled_df = pd.concat(sampled_rows)\n",
    "    \n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc568bd78f134affbd74eff752a6092e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_list_webtable_train = {}\n",
    "# for i in tqdm(range(len(webtable_train_list_pd['index'].unique()))):\n",
    "for i in tqdm(webtable_train['index'].unique()):\n",
    "    dict_list_webtable_train[i] = Generate_SBERT_Dict_WebTable(webtable_train[webtable_train['index']==i].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a03338c0634e52b6645939a57e332c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas bar:   0%|          | 0/14856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "def RAG_WebTable(row):\n",
    "    tmp_dict = {}\n",
    "    index = row['index']\n",
    "    tmp_dict['type'] = ''\n",
    "    output_dict = {}\n",
    "    output_dict['type'] = row['label']\n",
    "    options = eval(row['pred_list'])\n",
    "    target_col = eval(row['header'])[row['target']]\n",
    "    random.shuffle(options)\n",
    "    text = \"You are an expert in relation extraction from wikipedia web table to knowledge graph. Given table title and column pair for Table 1, please choose the most proper type from the provided options. Return in json format.\\n\\nColumn: %s\\n\\nOptions:%s\\n\\nOutput Format Example:\\n\\n%s\\n\\nTable 1:\\n\\n%s\\n\\nReference tables:\\n\\n\" % ('col_1',json.dumps(options),json.dumps(tmp_dict),random_dicts_to_str(dict_list_webtable_train[index]))\n",
    "    RAG = ''\n",
    "    RAG_df = webtable_train[webtable_train['label'].isin(options)]\n",
    "    RAG_df_sample = sample_rows_with_all_values_WebTable(RAG_df,k=5)\n",
    "    RAG_df_index = RAG_df_sample['index'].to_list()\n",
    "    for RAG_tuple_index in RAG_df_index:\n",
    "        RAG_dict = {}\n",
    "        RAG_row = RAG_df_sample[RAG_df_sample['index']==RAG_tuple_index].iloc[0] ## 被选择的一个Tuple\n",
    "        RAG_dict['Table'] = random_dicts_to_str(dict_list_webtable_train[RAG_tuple_index],k=4) ## \n",
    "        RAG_dict['Column'] = 'col_1'\n",
    "        RAG_dict['type'] = RAG_row['label']\n",
    "        # RAG += '%s\\n\\n' % json.dumps(RAG_dict, ensure_ascii=False)\n",
    "        RAG += '%s\\n\\n' % str(RAG_dict)\n",
    "    return text + RAG, '', json.dumps(output_dict), index\n",
    "# print(RAG_WebTable(webtable_train_few_shot.iloc[0])[0])\n",
    "# print(RAG_WebTable(webtable_train[webtable_train['index']==19493].iloc[0])[0])\n",
    "webtable_train_output = webtable_train.progress_apply(RAG_WebTable,axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "webtable_train_output.columns = ['instruction','input','output','index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(webtable_train_output.to_dict(orient='records'), open('../train/CTA/WebTable/WebTable-train.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b2df0b5aa24bcc9c80a09a9463c476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "webtable_test_list = []\n",
    "for index,row in tqdm(webtable_test.iterrows()):\n",
    "    query = eval(row['query'])\n",
    "    for q in query:\n",
    "        webtable_test_list.append([q,row['label'],row['index']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
