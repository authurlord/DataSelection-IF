{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 732,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.040983606557377046,
      "grad_norm": 91.80728149414062,
      "learning_rate": 1.3513513513513515e-05,
      "loss": 4.21,
      "step": 10
    },
    {
      "epoch": 0.08196721311475409,
      "grad_norm": 7.002516746520996,
      "learning_rate": 2.702702702702703e-05,
      "loss": 1.0228,
      "step": 20
    },
    {
      "epoch": 0.12295081967213115,
      "grad_norm": 0.6540793180465698,
      "learning_rate": 4.0540540540540545e-05,
      "loss": 0.1077,
      "step": 30
    },
    {
      "epoch": 0.16393442622950818,
      "grad_norm": 4.188938140869141,
      "learning_rate": 5.405405405405406e-05,
      "loss": 0.1614,
      "step": 40
    },
    {
      "epoch": 0.20491803278688525,
      "grad_norm": 5.91387414932251,
      "learning_rate": 6.756756756756757e-05,
      "loss": 0.055,
      "step": 50
    },
    {
      "epoch": 0.2459016393442623,
      "grad_norm": 1.4360496997833252,
      "learning_rate": 8.108108108108109e-05,
      "loss": 0.0417,
      "step": 60
    },
    {
      "epoch": 0.28688524590163933,
      "grad_norm": 1.9281392097473145,
      "learning_rate": 9.45945945945946e-05,
      "loss": 0.0294,
      "step": 70
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 2.8631112575531006,
      "learning_rate": 9.997948550797227e-05,
      "loss": 0.0227,
      "step": 80
    },
    {
      "epoch": 0.36885245901639346,
      "grad_norm": 1.6993581056594849,
      "learning_rate": 9.98541801244351e-05,
      "loss": 0.0665,
      "step": 90
    },
    {
      "epoch": 0.4098360655737705,
      "grad_norm": 2.772864580154419,
      "learning_rate": 9.961525153583327e-05,
      "loss": 0.0367,
      "step": 100
    },
    {
      "epoch": 0.45081967213114754,
      "grad_norm": 1.430863380432129,
      "learning_rate": 9.926324428691611e-05,
      "loss": 0.0344,
      "step": 110
    },
    {
      "epoch": 0.4918032786885246,
      "grad_norm": 1.799185037612915,
      "learning_rate": 9.879896064123961e-05,
      "loss": 0.034,
      "step": 120
    },
    {
      "epoch": 0.5327868852459017,
      "grad_norm": 0.6366633772850037,
      "learning_rate": 9.822345875271883e-05,
      "loss": 0.0147,
      "step": 130
    },
    {
      "epoch": 0.5737704918032787,
      "grad_norm": 0.33766111731529236,
      "learning_rate": 9.753805025397779e-05,
      "loss": 0.061,
      "step": 140
    },
    {
      "epoch": 0.6147540983606558,
      "grad_norm": 1.1072735786437988,
      "learning_rate": 9.674429726699323e-05,
      "loss": 0.03,
      "step": 150
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.209239199757576,
      "learning_rate": 9.584400884284545e-05,
      "loss": 0.0176,
      "step": 160
    },
    {
      "epoch": 0.6967213114754098,
      "grad_norm": 12.84887409210205,
      "learning_rate": 9.483923683869024e-05,
      "loss": 0.0264,
      "step": 170
    },
    {
      "epoch": 0.7377049180327869,
      "grad_norm": 1.9471763372421265,
      "learning_rate": 9.373227124134888e-05,
      "loss": 0.0256,
      "step": 180
    },
    {
      "epoch": 0.7786885245901639,
      "grad_norm": 1.145459771156311,
      "learning_rate": 9.252563494817425e-05,
      "loss": 0.0213,
      "step": 190
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.43186265230178833,
      "learning_rate": 9.122207801708802e-05,
      "loss": 0.0187,
      "step": 200
    },
    {
      "epoch": 0.860655737704918,
      "grad_norm": 2.195230484008789,
      "learning_rate": 8.982457139889357e-05,
      "loss": 0.0101,
      "step": 210
    },
    {
      "epoch": 0.9016393442622951,
      "grad_norm": 0.1256132572889328,
      "learning_rate": 8.833630016614976e-05,
      "loss": 0.0112,
      "step": 220
    },
    {
      "epoch": 0.9426229508196722,
      "grad_norm": 0.22933603823184967,
      "learning_rate": 8.676065625403733e-05,
      "loss": 0.0405,
      "step": 230
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 1.4963536262512207,
      "learning_rate": 8.510123072976239e-05,
      "loss": 0.0223,
      "step": 240
    },
    {
      "epoch": 1.0245901639344261,
      "grad_norm": 0.10351481288671494,
      "learning_rate": 8.336180560811619e-05,
      "loss": 0.0224,
      "step": 250
    },
    {
      "epoch": 1.0655737704918034,
      "grad_norm": 1.4638274908065796,
      "learning_rate": 8.154634523184388e-05,
      "loss": 0.0275,
      "step": 260
    },
    {
      "epoch": 1.1065573770491803,
      "grad_norm": 0.018095482140779495,
      "learning_rate": 7.965898723646776e-05,
      "loss": 0.0077,
      "step": 270
    },
    {
      "epoch": 1.1475409836065573,
      "grad_norm": 0.15699277818202972,
      "learning_rate": 7.770403312015721e-05,
      "loss": 0.0068,
      "step": 280
    },
    {
      "epoch": 1.1885245901639343,
      "grad_norm": 0.00738665834069252,
      "learning_rate": 7.568593844013718e-05,
      "loss": 0.0083,
      "step": 290
    },
    {
      "epoch": 1.2295081967213115,
      "grad_norm": 0.013089553453028202,
      "learning_rate": 7.360930265797935e-05,
      "loss": 0.0019,
      "step": 300
    },
    {
      "epoch": 1.2704918032786885,
      "grad_norm": 0.033139199018478394,
      "learning_rate": 7.147885865691899e-05,
      "loss": 0.008,
      "step": 310
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 0.44455939531326294,
      "learning_rate": 6.929946195508932e-05,
      "loss": 0.0105,
      "step": 320
    },
    {
      "epoch": 1.3524590163934427,
      "grad_norm": 0.433014839887619,
      "learning_rate": 6.707607963925724e-05,
      "loss": 0.0062,
      "step": 330
    },
    {
      "epoch": 1.3934426229508197,
      "grad_norm": 0.24721604585647583,
      "learning_rate": 6.481377904428171e-05,
      "loss": 0.0059,
      "step": 340
    },
    {
      "epoch": 1.4344262295081966,
      "grad_norm": 0.6410855054855347,
      "learning_rate": 6.251771620409563e-05,
      "loss": 0.0063,
      "step": 350
    },
    {
      "epoch": 1.4754098360655736,
      "grad_norm": 0.002312188036739826,
      "learning_rate": 6.019312410053286e-05,
      "loss": 0.0022,
      "step": 360
    },
    {
      "epoch": 1.5163934426229508,
      "grad_norm": 0.005895296111702919,
      "learning_rate": 5.7845300736782204e-05,
      "loss": 0.0051,
      "step": 370
    },
    {
      "epoch": 1.5573770491803278,
      "grad_norm": 0.7625691294670105,
      "learning_rate": 5.547959706265068e-05,
      "loss": 0.011,
      "step": 380
    },
    {
      "epoch": 1.598360655737705,
      "grad_norm": 0.0025805409532040358,
      "learning_rate": 5.310140477915544e-05,
      "loss": 0.0026,
      "step": 390
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 0.2765175402164459,
      "learning_rate": 5.0716144050239375e-05,
      "loss": 0.0013,
      "step": 400
    },
    {
      "epoch": 1.680327868852459,
      "grad_norm": 0.21754112839698792,
      "learning_rate": 4.832925114961629e-05,
      "loss": 0.0081,
      "step": 410
    },
    {
      "epoch": 1.721311475409836,
      "grad_norm": 0.03206416592001915,
      "learning_rate": 4.594616607090028e-05,
      "loss": 0.0116,
      "step": 420
    },
    {
      "epoch": 1.762295081967213,
      "grad_norm": 2.6022541522979736,
      "learning_rate": 4.357232012925714e-05,
      "loss": 0.0094,
      "step": 430
    },
    {
      "epoch": 1.8032786885245902,
      "grad_norm": 0.021930571645498276,
      "learning_rate": 4.121312358283463e-05,
      "loss": 0.0018,
      "step": 440
    },
    {
      "epoch": 1.8442622950819674,
      "grad_norm": 0.035140544176101685,
      "learning_rate": 3.887395330218429e-05,
      "loss": 0.0026,
      "step": 450
    },
    {
      "epoch": 1.8852459016393444,
      "grad_norm": 0.8142107129096985,
      "learning_rate": 3.656014051577713e-05,
      "loss": 0.0052,
      "step": 460
    },
    {
      "epoch": 1.9262295081967213,
      "grad_norm": 0.1602378487586975,
      "learning_rate": 3.427695865954284e-05,
      "loss": 0.0046,
      "step": 470
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 1.1314126253128052,
      "learning_rate": 3.202961135812437e-05,
      "loss": 0.0034,
      "step": 480
    },
    {
      "epoch": 2.0081967213114753,
      "grad_norm": 0.21780775487422943,
      "learning_rate": 2.9823220565240394e-05,
      "loss": 0.0011,
      "step": 490
    },
    {
      "epoch": 2.0491803278688523,
      "grad_norm": 0.17542332410812378,
      "learning_rate": 2.7662814890184818e-05,
      "loss": 0.0006,
      "step": 500
    },
    {
      "epoch": 2.0901639344262297,
      "grad_norm": 0.012329707853496075,
      "learning_rate": 2.555331813706847e-05,
      "loss": 0.0002,
      "step": 510
    },
    {
      "epoch": 2.1311475409836067,
      "grad_norm": 0.0016815389972180128,
      "learning_rate": 2.3499538082923606e-05,
      "loss": 0.0002,
      "step": 520
    },
    {
      "epoch": 2.1721311475409837,
      "grad_norm": 0.06172017380595207,
      "learning_rate": 2.1506155520246797e-05,
      "loss": 0.0003,
      "step": 530
    },
    {
      "epoch": 2.2131147540983607,
      "grad_norm": 0.041096560657024384,
      "learning_rate": 1.9577713588953795e-05,
      "loss": 0.0004,
      "step": 540
    },
    {
      "epoch": 2.2540983606557377,
      "grad_norm": 0.03869401663541794,
      "learning_rate": 1.771860742205988e-05,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 0.0005463281995616853,
      "learning_rate": 1.5933074128684332e-05,
      "loss": 0.0025,
      "step": 560
    },
    {
      "epoch": 2.3360655737704916,
      "grad_norm": 0.008900528773665428,
      "learning_rate": 1.4225183137208776e-05,
      "loss": 0.0001,
      "step": 570
    },
    {
      "epoch": 2.3770491803278686,
      "grad_norm": 0.010568535886704922,
      "learning_rate": 1.2598826920598772e-05,
      "loss": 0.0003,
      "step": 580
    },
    {
      "epoch": 2.418032786885246,
      "grad_norm": 0.006362142972648144,
      "learning_rate": 1.1057712125026116e-05,
      "loss": 0.0011,
      "step": 590
    },
    {
      "epoch": 2.459016393442623,
      "grad_norm": 0.021805131807923317,
      "learning_rate": 9.605351122011309e-06,
      "loss": 0.0001,
      "step": 600
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.016903746873140335,
      "learning_rate": 8.245054003339247e-06,
      "loss": 0.0025,
      "step": 610
    },
    {
      "epoch": 2.540983606557377,
      "grad_norm": 0.001720335683785379,
      "learning_rate": 6.979921036993042e-06,
      "loss": 0.0002,
      "step": 620
    },
    {
      "epoch": 2.581967213114754,
      "grad_norm": 3.1918392181396484,
      "learning_rate": 5.8128356012994375e-06,
      "loss": 0.0014,
      "step": 630
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 0.004126169253140688,
      "learning_rate": 4.746457613389904e-06,
      "loss": 0.003,
      "step": 640
    },
    {
      "epoch": 2.663934426229508,
      "grad_norm": 0.04207523539662361,
      "learning_rate": 3.783217466954503e-06,
      "loss": 0.0002,
      "step": 650
    },
    {
      "epoch": 2.7049180327868854,
      "grad_norm": 0.0005877958610653877,
      "learning_rate": 2.925310493105099e-06,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 2.7459016393442623,
      "grad_norm": 0.0034212186001241207,
      "learning_rate": 2.1746919569723855e-06,
      "loss": 0.0001,
      "step": 670
    },
    {
      "epoch": 2.7868852459016393,
      "grad_norm": 0.010156973265111446,
      "learning_rate": 1.5330726014397668e-06,
      "loss": 0.0049,
      "step": 680
    },
    {
      "epoch": 2.8278688524590163,
      "grad_norm": 0.0057098837569355965,
      "learning_rate": 1.0019147481706625e-06,
      "loss": 0.0001,
      "step": 690
    },
    {
      "epoch": 2.8688524590163933,
      "grad_norm": 0.0018550455570220947,
      "learning_rate": 5.824289648152126e-07,
      "loss": 0.0003,
      "step": 700
    },
    {
      "epoch": 2.9098360655737707,
      "grad_norm": 0.005363147705793381,
      "learning_rate": 2.75571305992417e-07,
      "loss": 0.0012,
      "step": 710
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 0.005864033941179514,
      "learning_rate": 8.204113433559201e-08,
      "loss": 0.0001,
      "step": 720
    },
    {
      "epoch": 2.9918032786885247,
      "grad_norm": 0.04919269680976868,
      "learning_rate": 2.279526567411372e-09,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 3.0,
      "step": 732,
      "total_flos": 5.187118027547607e+17,
      "train_loss": 0.08638261916293048,
      "train_runtime": 1620.2195,
      "train_samples_per_second": 7.208,
      "train_steps_per_second": 0.452
    }
  ],
  "logging_steps": 10,
  "max_steps": 732,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.187118027547607e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
