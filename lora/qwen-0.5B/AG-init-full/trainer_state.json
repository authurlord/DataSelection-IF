{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 765,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 5.500029563903809,
      "learning_rate": 1.2987012987012986e-05,
      "loss": 1.5014,
      "step": 10
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 5.805402755737305,
      "learning_rate": 2.5974025974025972e-05,
      "loss": 1.3744,
      "step": 20
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 3.918999195098877,
      "learning_rate": 3.8961038961038966e-05,
      "loss": 0.9265,
      "step": 30
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 6.1525421142578125,
      "learning_rate": 5.1948051948051944e-05,
      "loss": 0.4516,
      "step": 40
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.612966775894165,
      "learning_rate": 6.493506493506494e-05,
      "loss": 0.1171,
      "step": 50
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.1847400814294815,
      "learning_rate": 7.792207792207793e-05,
      "loss": 0.0458,
      "step": 60
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.24267122149467468,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.0416,
      "step": 70
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.9689000248908997,
      "learning_rate": 9.999530864178371e-05,
      "loss": 0.0346,
      "step": 80
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.8094587922096252,
      "learning_rate": 9.991193120617212e-05,
      "loss": 0.0245,
      "step": 90
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 1.6158385276794434,
      "learning_rate": 9.972450144764713e-05,
      "loss": 0.016,
      "step": 100
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.07219074666500092,
      "learning_rate": 9.943341010448086e-05,
      "loss": 0.0129,
      "step": 110
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.8569684028625488,
      "learning_rate": 9.903926402016153e-05,
      "loss": 0.0108,
      "step": 120
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.10573536157608032,
      "learning_rate": 9.854288487829562e-05,
      "loss": 0.006,
      "step": 130
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.3743061423301697,
      "learning_rate": 9.794530748962894e-05,
      "loss": 0.0091,
      "step": 140
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.9045050740242004,
      "learning_rate": 9.724777763475764e-05,
      "loss": 0.0071,
      "step": 150
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.6224331855773926,
      "learning_rate": 9.645174946702634e-05,
      "loss": 0.008,
      "step": 160
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.1888422816991806,
      "learning_rate": 9.55588824810279e-05,
      "loss": 0.0074,
      "step": 170
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 1.0798451900482178,
      "learning_rate": 9.457103805302454e-05,
      "loss": 0.0017,
      "step": 180
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.0551861897110939,
      "learning_rate": 9.349027556050225e-05,
      "loss": 0.0032,
      "step": 190
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 1.2289149761199951,
      "learning_rate": 9.231884808894878e-05,
      "loss": 0.0025,
      "step": 200
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.2734887897968292,
      "learning_rate": 9.105919773480464e-05,
      "loss": 0.0053,
      "step": 210
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.055622782558202744,
      "learning_rate": 8.97139505143798e-05,
      "loss": 0.0027,
      "step": 220
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.5954701900482178,
      "learning_rate": 8.828591088934893e-05,
      "loss": 0.0026,
      "step": 230
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.4298841655254364,
      "learning_rate": 8.677805592023859e-05,
      "loss": 0.0064,
      "step": 240
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.0371432825922966,
      "learning_rate": 8.519352906009416e-05,
      "loss": 0.0036,
      "step": 250
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.6226780414581299,
      "learning_rate": 8.353563360126548e-05,
      "loss": 0.0015,
      "step": 260
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 1.2898013591766357,
      "learning_rate": 8.180782578897224e-05,
      "loss": 0.0018,
      "step": 270
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.06572438776493073,
      "learning_rate": 8.001370761600597e-05,
      "loss": 0.0017,
      "step": 280
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.02813933789730072,
      "learning_rate": 7.815701931358935e-05,
      "loss": 0.0039,
      "step": 290
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.017161661759018898,
      "learning_rate": 7.624163155404702e-05,
      "loss": 0.0046,
      "step": 300
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.0897202342748642,
      "learning_rate": 7.427153738154391e-05,
      "loss": 0.0016,
      "step": 310
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 0.02604006417095661,
      "learning_rate": 7.225084388771225e-05,
      "loss": 0.0011,
      "step": 320
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.020776739344000816,
      "learning_rate": 7.018376364952209e-05,
      "loss": 0.0002,
      "step": 330
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.027132902294397354,
      "learning_rate": 6.807460594724439e-05,
      "loss": 0.0003,
      "step": 340
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 0.016709018498659134,
      "learning_rate": 6.5927767780815e-05,
      "loss": 0.0002,
      "step": 350
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.0043611228466033936,
      "learning_rate": 6.374772470332793e-05,
      "loss": 0.0015,
      "step": 360
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.0016035059234127402,
      "learning_rate": 6.15390214907672e-05,
      "loss": 0.0017,
      "step": 370
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.01322847418487072,
      "learning_rate": 5.930626266742871e-05,
      "loss": 0.0015,
      "step": 380
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 1.854671835899353,
      "learning_rate": 5.7054102906783524e-05,
      "loss": 0.0014,
      "step": 390
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.002188116544857621,
      "learning_rate": 5.478723732779422e-05,
      "loss": 0.0001,
      "step": 400
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.002913899952545762,
      "learning_rate": 5.2510391706913986e-05,
      "loss": 0.0002,
      "step": 410
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.006499127950519323,
      "learning_rate": 5.022831262617328e-05,
      "loss": 0.0001,
      "step": 420
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.01056190300732851,
      "learning_rate": 4.7945757577892734e-05,
      "loss": 0.0003,
      "step": 430
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.0018349455203860998,
      "learning_rate": 4.566748504665135e-05,
      "loss": 0.0002,
      "step": 440
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.23034609854221344,
      "learning_rate": 4.3398244589185914e-05,
      "loss": 0.0036,
      "step": 450
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 0.0014445629203692079,
      "learning_rate": 4.114276693290248e-05,
      "loss": 0.0008,
      "step": 460
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 0.0013271867064759135,
      "learning_rate": 3.890575411364187e-05,
      "loss": 0.0005,
      "step": 470
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 0.18688271939754486,
      "learning_rate": 3.669186967325884e-05,
      "loss": 0.001,
      "step": 480
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 0.014937872998416424,
      "learning_rate": 3.4505728937450435e-05,
      "loss": 0.0001,
      "step": 490
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 0.011811421252787113,
      "learning_rate": 3.235188939410135e-05,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.3614449203014374,
      "learning_rate": 3.0234841192205097e-05,
      "loss": 0.0026,
      "step": 510
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 0.030790816992521286,
      "learning_rate": 2.8158997781167527e-05,
      "loss": 0.0003,
      "step": 520
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 0.02021782286465168,
      "learning_rate": 2.612868671000755e-05,
      "loss": 0.0009,
      "step": 530
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.012301531620323658,
      "learning_rate": 2.4148140605635923e-05,
      "loss": 0.0002,
      "step": 540
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 0.032590728253126144,
      "learning_rate": 2.2221488349019903e-05,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 0.02223496325314045,
      "learning_rate": 2.035274646762902e-05,
      "loss": 0.0002,
      "step": 560
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 0.0011288761161267757,
      "learning_rate": 1.8545810762106265e-05,
      "loss": 0.0001,
      "step": 570
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 0.0015406361781060696,
      "learning_rate": 1.6804448184620598e-05,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 0.008336229249835014,
      "learning_rate": 1.5132288985832382e-05,
      "loss": 0.0001,
      "step": 590
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 0.004288028925657272,
      "learning_rate": 1.3532819146842935e-05,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 0.001289036008529365,
      "learning_rate": 1.2009373111905487e-05,
      "loss": 0.0003,
      "step": 610
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 0.005161699838936329,
      "learning_rate": 1.0565126837047717e-05,
      "loss": 0.0002,
      "step": 620
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.016935957595705986,
      "learning_rate": 9.20309116909776e-06,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 0.012027284130454063,
      "learning_rate": 7.926105568916292e-06,
      "loss": 0.0001,
      "step": 640
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 0.009773996658623219,
      "learning_rate": 6.7368321919201836e-06,
      "loss": 0.0001,
      "step": 650
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.016534801572561264,
      "learning_rate": 5.6377503382379626e-06,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 0.012922647409141064,
      "learning_rate": 4.631151284067209e-06,
      "loss": 0.0001,
      "step": 670
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.016638731583952904,
      "learning_rate": 3.7191335050087926e-06,
      "loss": 0.0001,
      "step": 680
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 0.0010415940778329968,
      "learning_rate": 2.9035983013361523e-06,
      "loss": 0.0001,
      "step": 690
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 0.0013280740240588784,
      "learning_rate": 2.186245834319517e-06,
      "loss": 0.0001,
      "step": 700
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 0.0057462588883936405,
      "learning_rate": 1.5685715818684333e-06,
      "loss": 0.0001,
      "step": 710
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.004440598655492067,
      "learning_rate": 1.0518632208813272e-06,
      "loss": 0.0001,
      "step": 720
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 0.005032060667872429,
      "learning_rate": 6.371979428018371e-07,
      "loss": 0.0001,
      "step": 730
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.0021297845523804426,
      "learning_rate": 3.254402079778618e-07,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 0.005955313798040152,
      "learning_rate": 1.1723994350521517e-07,
      "loss": 0.002,
      "step": 750
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 0.0023731051478534937,
      "learning_rate": 1.3031188312573329e-08,
      "loss": 0.0001,
      "step": 760
    },
    {
      "epoch": 5.0,
      "step": 765,
      "total_flos": 1.5800743382482944e+16,
      "train_loss": 0.06093949565376319,
      "train_runtime": 130.1488,
      "train_samples_per_second": 140.724,
      "train_steps_per_second": 5.878
    }
  ],
  "logging_steps": 10,
  "max_steps": 765,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5800743382482944e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
