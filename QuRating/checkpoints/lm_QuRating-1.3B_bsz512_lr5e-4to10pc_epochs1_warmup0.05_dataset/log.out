[W801 03:39:40.831801081 socket.cpp:759] [c10d] The client socket cannot be initialized to connect to [localhost]:54616 (errno: 97 - Address family not supported by protocol).
[W801 03:39:40.940993220 socket.cpp:759] [c10d] The client socket cannot be initialized to connect to [12-43]:42365 (errno: 97 - Address family not supported by protocol).
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.
  warnings.warn(
usage: train_language_model.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                               [--config_overrides CONFIG_OVERRIDES]
                               [--config_overrides_json CONFIG_OVERRIDES_JSON]
                               [--config_name CONFIG_NAME]
                               [--tokenizer_name TOKENIZER_NAME]
                               [--cache_dir CACHE_DIR]
                               [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                               [--no_use_fast_tokenizer]
                               [--model_revision MODEL_REVISION]
                               [--use_auth_token [USE_AUTH_TOKEN]]
                               [--tokenized_train_dataset TOKENIZED_TRAIN_DATASET [TOKENIZED_TRAIN_DATASET ...]]
                               [--tokenized_validation_dataset TOKENIZED_VALIDATION_DATASET]
                               [--tokenized_test_dataset TOKENIZED_TEST_DATASET]
                               [--half_precision_training [HALF_PRECISION_TRAINING]]
                               [--lora [LORA]] [--lora_path LORA_PATH]
                               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                               [--lora_r LORA_R]
                               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                               [--lora_alpha LORA_ALPHA]
                               [--lora_dropout LORA_DROPOUT]
                               [--infill_proportion INFILL_PROPORTION]
                               [--infill_rate_min INFILL_RATE_MIN]
                               [--infill_rate_max INFILL_RATE_MAX]
                               [--infill_mean_length_min INFILL_MEAN_LENGTH_MIN]
                               [--infill_mean_length_max INFILL_MEAN_LENGTH_MAX]
                               [--infill_random_order [INFILL_RANDOM_ORDER]]
                               [--infill_ignore_run_in INFILL_IGNORE_RUN_IN]
                               [--sort_by SORT_BY]
                               [--reverse_sort [REVERSE_SORT]]
                               [--output_dir OUTPUT_DIR]
                               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                               [--do_predict [DO_PREDICT]]
                               [--eval_strategy {no,steps,epoch}]
                               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                               [--eval_delay EVAL_DELAY]
                               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
                               [--learning_rate LEARNING_RATE]
                               [--weight_decay WEIGHT_DECAY]
                               [--adam_beta1 ADAM_BETA1]
                               [--adam_beta2 ADAM_BETA2]
                               [--adam_epsilon ADAM_EPSILON]
                               [--max_grad_norm MAX_GRAD_NORM]
                               [--num_train_epochs NUM_TRAIN_EPOCHS]
                               [--max_steps MAX_STEPS]
                               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
                               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
                               [--warmup_ratio WARMUP_RATIO]
                               [--warmup_steps WARMUP_STEPS]
                               [--log_level {detail,debug,info,warning,error,critical,passive}]
                               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
                               [--log_on_each_node [LOG_ON_EACH_NODE]]
                               [--no_log_on_each_node]
                               [--logging_dir LOGGING_DIR]
                               [--logging_strategy {no,steps,epoch}]
                               [--logging_first_step [LOGGING_FIRST_STEP]]
                               [--logging_steps LOGGING_STEPS]
                               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
                               [--no_logging_nan_inf_filter]
                               [--save_strategy {no,steps,epoch,best}]
                               [--save_steps SAVE_STEPS]
                               [--save_total_limit SAVE_TOTAL_LIMIT]
                               [--save_safetensors [SAVE_SAFETENSORS]]
                               [--no_save_safetensors]
                               [--save_on_each_node [SAVE_ON_EACH_NODE]]
                               [--save_only_model [SAVE_ONLY_MODEL]]
                               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
                               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
                               [--use_mps_device [USE_MPS_DEVICE]]
                               [--seed SEED] [--data_seed DATA_SEED]
                               [--jit_mode_eval [JIT_MODE_EVAL]]
                               [--use_ipex [USE_IPEX]] [--bf16 [BF16]]
                               [--fp16 [FP16]]
                               [--fp16_opt_level FP16_OPT_LEVEL]
                               [--half_precision_backend {auto,apex,cpu_amp}]
                               [--bf16_full_eval [BF16_FULL_EVAL]]
                               [--fp16_full_eval [FP16_FULL_EVAL]]
                               [--tf32 TF32] [--local_rank LOCAL_RANK]
                               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
                               [--tpu_num_cores TPU_NUM_CORES]
                               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                               [--debug DEBUG [DEBUG ...]]
                               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                               [--eval_steps EVAL_STEPS]
                               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
                               [--past_index PAST_INDEX] [--run_name RUN_NAME]
                               [--disable_tqdm DISABLE_TQDM]
                               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                               [--no_remove_unused_columns]
                               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                               [--greater_is_better GREATER_IS_BETTER]
                               [--ignore_data_skip [IGNORE_DATA_SKIP]]
                               [--fsdp FSDP]
                               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                               [--fsdp_config FSDP_CONFIG]
                               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                               [--accelerator_config ACCELERATOR_CONFIG]
                               [--deepspeed DEEPSPEED]
                               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
                               [--optim_args OPTIM_ARGS]
                               [--adafactor [ADAFACTOR]]
                               [--group_by_length [GROUP_BY_LENGTH]]
                               [--length_column_name LENGTH_COLUMN_NAME]
                               [--report_to REPORT_TO]
                               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
                               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
                               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                               [--no_dataloader_pin_memory]
                               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
                               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                               [--no_skip_memory_metrics]
                               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                               [--push_to_hub [PUSH_TO_HUB]]
                               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                               [--hub_model_id HUB_MODEL_ID]
                               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
                               [--hub_token HUB_TOKEN]
                               [--hub_private_repo HUB_PRIVATE_REPO]
                               [--hub_always_push [HUB_ALWAYS_PUSH]]
                               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
                               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
                               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
                               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
                               [--no_eval_do_concat_batches]
                               [--fp16_backend {auto,apex,cpu_amp}]
                               [--evaluation_strategy {no,steps,epoch}]
                               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                               [--mp_parameters MP_PARAMETERS]
                               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
                               [--full_determinism [FULL_DETERMINISM]]
                               [--torchdynamo TORCHDYNAMO]
                               [--ray_scope RAY_SCOPE]
                               [--ddp_timeout DDP_TIMEOUT]
                               [--torch_compile [TORCH_COMPILE]]
                               [--torch_compile_backend TORCH_COMPILE_BACKEND]
                               [--torch_compile_mode TORCH_COMPILE_MODE]
                               [--dispatch_batches DISPATCH_BATCHES]
                               [--split_batches SPLIT_BATCHES]
                               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
                               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
                               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
                               [--optim_target_modules OPTIM_TARGET_MODULES]
                               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
                               [--eval_on_start [EVAL_ON_START]]
                               [--use_liger_kernel [USE_LIGER_KERNEL]]
                               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
                               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
                               [--min_lr_ratio MIN_LR_RATIO]
                               [--ordered [ORDERED]]
                               [--cuda_empty_cache [CUDA_EMPTY_CACHE]]
train_language_model.py: error: argument --tokenized_train_dataset/--tokenized-train-dataset: expected at least one argument
W0801 03:39:44.918319 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1668018 closing signal SIGTERM
W0801 03:39:44.919280 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1668019 closing signal SIGTERM
W0801 03:39:44.919878 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1668020 closing signal SIGTERM
W0801 03:39:44.920398 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1668021 closing signal SIGTERM
W0801 03:39:44.920911 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1668022 closing signal SIGTERM
W0801 03:39:44.921154 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1668024 closing signal SIGTERM
W0801 03:39:44.921319 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1668025 closing signal SIGTERM
E0801 03:39:44.985186 1667991 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 5 (pid: 1668023) of binary: /data/home/wangys/anaconda3/envs/verl/bin/python
Traceback (most recent call last):
  File "/data/home/wangys/anaconda3/envs/verl/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/home/wangys/anaconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
training.train_language_model FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-01_03:39:44
  host      : 12-43
  rank      : 5 (local_rank: 5)
  exitcode  : 2 (pid: 1668023)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
