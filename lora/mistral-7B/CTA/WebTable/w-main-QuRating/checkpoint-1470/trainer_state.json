{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1470,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02040816326530612,
      "grad_norm": 156.74534606933594,
      "learning_rate": 6.122448979591837e-06,
      "loss": 5.12,
      "step": 10
    },
    {
      "epoch": 0.04081632653061224,
      "grad_norm": 42.83641052246094,
      "learning_rate": 1.2925170068027212e-05,
      "loss": 2.6578,
      "step": 20
    },
    {
      "epoch": 0.061224489795918366,
      "grad_norm": 21.326263427734375,
      "learning_rate": 1.9727891156462584e-05,
      "loss": 0.4867,
      "step": 30
    },
    {
      "epoch": 0.08163265306122448,
      "grad_norm": 7.060823440551758,
      "learning_rate": 2.6530612244897963e-05,
      "loss": 0.5393,
      "step": 40
    },
    {
      "epoch": 0.10204081632653061,
      "grad_norm": 5.299325942993164,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.1665,
      "step": 50
    },
    {
      "epoch": 0.12244897959183673,
      "grad_norm": 6.232720851898193,
      "learning_rate": 4.013605442176871e-05,
      "loss": 0.1031,
      "step": 60
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 6.055188179016113,
      "learning_rate": 4.6938775510204086e-05,
      "loss": 0.0559,
      "step": 70
    },
    {
      "epoch": 0.16326530612244897,
      "grad_norm": 2.601101875305176,
      "learning_rate": 5.374149659863946e-05,
      "loss": 0.0464,
      "step": 80
    },
    {
      "epoch": 0.1836734693877551,
      "grad_norm": 3.67909574508667,
      "learning_rate": 6.0544217687074836e-05,
      "loss": 0.0668,
      "step": 90
    },
    {
      "epoch": 0.20408163265306123,
      "grad_norm": 0.408082515001297,
      "learning_rate": 6.73469387755102e-05,
      "loss": 0.0356,
      "step": 100
    },
    {
      "epoch": 0.22448979591836735,
      "grad_norm": 8.66746711730957,
      "learning_rate": 7.414965986394559e-05,
      "loss": 0.0577,
      "step": 110
    },
    {
      "epoch": 0.24489795918367346,
      "grad_norm": 1.6910176277160645,
      "learning_rate": 8.095238095238096e-05,
      "loss": 0.0763,
      "step": 120
    },
    {
      "epoch": 0.2653061224489796,
      "grad_norm": 2.0025253295898438,
      "learning_rate": 8.775510204081632e-05,
      "loss": 0.0421,
      "step": 130
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 1.5848242044448853,
      "learning_rate": 9.455782312925171e-05,
      "loss": 0.0569,
      "step": 140
    },
    {
      "epoch": 0.30612244897959184,
      "grad_norm": 2.47515606880188,
      "learning_rate": 9.999943612967331e-05,
      "loss": 0.0579,
      "step": 150
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 1.2738540172576904,
      "learning_rate": 9.99797020035959e-05,
      "loss": 0.0656,
      "step": 160
    },
    {
      "epoch": 0.3469387755102041,
      "grad_norm": 2.699596643447876,
      "learning_rate": 9.99317870778844e-05,
      "loss": 0.0586,
      "step": 170
    },
    {
      "epoch": 0.3673469387755102,
      "grad_norm": 2.465975046157837,
      "learning_rate": 9.985571836912485e-05,
      "loss": 0.0624,
      "step": 180
    },
    {
      "epoch": 0.3877551020408163,
      "grad_norm": 22.586673736572266,
      "learning_rate": 9.975153876827008e-05,
      "loss": 0.0751,
      "step": 190
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 3.9327895641326904,
      "learning_rate": 9.961930701645577e-05,
      "loss": 0.0352,
      "step": 200
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 2.6166772842407227,
      "learning_rate": 9.945909767187964e-05,
      "loss": 0.0482,
      "step": 210
    },
    {
      "epoch": 0.4489795918367347,
      "grad_norm": 1.4248632192611694,
      "learning_rate": 9.927100106776212e-05,
      "loss": 0.0426,
      "step": 220
    },
    {
      "epoch": 0.46938775510204084,
      "grad_norm": 4.477366924285889,
      "learning_rate": 9.90551232614125e-05,
      "loss": 0.068,
      "step": 230
    },
    {
      "epoch": 0.4897959183673469,
      "grad_norm": 0.024075616151094437,
      "learning_rate": 9.881158597442901e-05,
      "loss": 0.0344,
      "step": 240
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 0.22947056591510773,
      "learning_rate": 9.854052652406666e-05,
      "loss": 0.0273,
      "step": 250
    },
    {
      "epoch": 0.5306122448979592,
      "grad_norm": 3.0178191661834717,
      "learning_rate": 9.824209774581174e-05,
      "loss": 0.0733,
      "step": 260
    },
    {
      "epoch": 0.5510204081632653,
      "grad_norm": 1.0130572319030762,
      "learning_rate": 9.791646790720628e-05,
      "loss": 0.075,
      "step": 270
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 4.091745376586914,
      "learning_rate": 9.75638206129711e-05,
      "loss": 0.0523,
      "step": 280
    },
    {
      "epoch": 0.5918367346938775,
      "grad_norm": 0.5322292447090149,
      "learning_rate": 9.718435470148147e-05,
      "loss": 0.0169,
      "step": 290
    },
    {
      "epoch": 0.6122448979591837,
      "grad_norm": 0.3530377447605133,
      "learning_rate": 9.677828413265291e-05,
      "loss": 0.0273,
      "step": 300
    },
    {
      "epoch": 0.6326530612244898,
      "grad_norm": 0.3968906104564667,
      "learning_rate": 9.63458378673011e-05,
      "loss": 0.0234,
      "step": 310
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 0.11313490569591522,
      "learning_rate": 9.588725973804342e-05,
      "loss": 0.0257,
      "step": 320
    },
    {
      "epoch": 0.673469387755102,
      "grad_norm": 2.8695068359375,
      "learning_rate": 9.540280831181525e-05,
      "loss": 0.0391,
      "step": 330
    },
    {
      "epoch": 0.6938775510204082,
      "grad_norm": 0.10423261672258377,
      "learning_rate": 9.489275674407826e-05,
      "loss": 0.0322,
      "step": 340
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.589962363243103,
      "learning_rate": 9.43573926248031e-05,
      "loss": 0.0276,
      "step": 350
    },
    {
      "epoch": 0.7346938775510204,
      "grad_norm": 0.08879964798688889,
      "learning_rate": 9.379701781631335e-05,
      "loss": 0.0226,
      "step": 360
    },
    {
      "epoch": 0.7551020408163265,
      "grad_norm": 3.785182476043701,
      "learning_rate": 9.321194828308185e-05,
      "loss": 0.0157,
      "step": 370
    },
    {
      "epoch": 0.7755102040816326,
      "grad_norm": 3.279902458190918,
      "learning_rate": 9.260251391357586e-05,
      "loss": 0.0498,
      "step": 380
    },
    {
      "epoch": 0.7959183673469388,
      "grad_norm": 6.590975284576416,
      "learning_rate": 9.196905833425111e-05,
      "loss": 0.0453,
      "step": 390
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 1.7421021461486816,
      "learning_rate": 9.131193871579975e-05,
      "loss": 0.0153,
      "step": 400
    },
    {
      "epoch": 0.8367346938775511,
      "grad_norm": 1.9509028196334839,
      "learning_rate": 9.063152557176149e-05,
      "loss": 0.0698,
      "step": 410
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.018173720687627792,
      "learning_rate": 8.992820254961143e-05,
      "loss": 0.0155,
      "step": 420
    },
    {
      "epoch": 0.8775510204081632,
      "grad_norm": 0.1109803169965744,
      "learning_rate": 8.920236621444243e-05,
      "loss": 0.0441,
      "step": 430
    },
    {
      "epoch": 0.8979591836734694,
      "grad_norm": 0.07280241698026657,
      "learning_rate": 8.845442582536385e-05,
      "loss": 0.0295,
      "step": 440
    },
    {
      "epoch": 0.9183673469387755,
      "grad_norm": 5.706305027008057,
      "learning_rate": 8.768480310474294e-05,
      "loss": 0.0115,
      "step": 450
    },
    {
      "epoch": 0.9387755102040817,
      "grad_norm": 4.171199321746826,
      "learning_rate": 8.689393200041879e-05,
      "loss": 0.0593,
      "step": 460
    },
    {
      "epoch": 0.9591836734693877,
      "grad_norm": 9.971207618713379,
      "learning_rate": 8.60822584410231e-05,
      "loss": 0.0745,
      "step": 470
    },
    {
      "epoch": 0.9795918367346939,
      "grad_norm": 2.8018605709075928,
      "learning_rate": 8.525024008454561e-05,
      "loss": 0.0282,
      "step": 480
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.01496098656207323,
      "learning_rate": 8.439834606028594e-05,
      "loss": 0.0137,
      "step": 490
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.13213811814785004,
      "learning_rate": 8.352705670433741e-05,
      "loss": 0.0149,
      "step": 500
    },
    {
      "epoch": 1.0408163265306123,
      "grad_norm": 0.6597279906272888,
      "learning_rate": 8.263686328875206e-05,
      "loss": 0.0196,
      "step": 510
    },
    {
      "epoch": 1.0612244897959184,
      "grad_norm": 1.1810485124588013,
      "learning_rate": 8.172826774453936e-05,
      "loss": 0.0258,
      "step": 520
    },
    {
      "epoch": 1.0816326530612246,
      "grad_norm": 0.9352712035179138,
      "learning_rate": 8.080178237865503e-05,
      "loss": 0.0063,
      "step": 530
    },
    {
      "epoch": 1.1020408163265305,
      "grad_norm": 0.025573987513780594,
      "learning_rate": 7.985792958513931e-05,
      "loss": 0.0079,
      "step": 540
    },
    {
      "epoch": 1.1224489795918366,
      "grad_norm": 0.0006326187867671251,
      "learning_rate": 7.889724155056777e-05,
      "loss": 0.0104,
      "step": 550
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.011566614732146263,
      "learning_rate": 7.792025995398068e-05,
      "loss": 0.0193,
      "step": 560
    },
    {
      "epoch": 1.163265306122449,
      "grad_norm": 2.6566975116729736,
      "learning_rate": 7.692753566145998e-05,
      "loss": 0.0162,
      "step": 570
    },
    {
      "epoch": 1.183673469387755,
      "grad_norm": 0.0014012401225045323,
      "learning_rate": 7.591962841552627e-05,
      "loss": 0.018,
      "step": 580
    },
    {
      "epoch": 1.2040816326530612,
      "grad_norm": 0.0739392414689064,
      "learning_rate": 7.489710651953089e-05,
      "loss": 0.0325,
      "step": 590
    },
    {
      "epoch": 1.2244897959183674,
      "grad_norm": 0.006602475885301828,
      "learning_rate": 7.386054651722098e-05,
      "loss": 0.0112,
      "step": 600
    },
    {
      "epoch": 1.2448979591836735,
      "grad_norm": 0.01898200251162052,
      "learning_rate": 7.281053286765815e-05,
      "loss": 0.0039,
      "step": 610
    },
    {
      "epoch": 1.2653061224489797,
      "grad_norm": 0.13079290091991425,
      "learning_rate": 7.174765761567432e-05,
      "loss": 0.0132,
      "step": 620
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.18969587981700897,
      "learning_rate": 7.067252005805019e-05,
      "loss": 0.0286,
      "step": 630
    },
    {
      "epoch": 1.306122448979592,
      "grad_norm": 0.10180138796567917,
      "learning_rate": 6.958572640560492e-05,
      "loss": 0.0096,
      "step": 640
    },
    {
      "epoch": 1.3265306122448979,
      "grad_norm": 0.1707713007926941,
      "learning_rate": 6.848788944138705e-05,
      "loss": 0.0118,
      "step": 650
    },
    {
      "epoch": 1.346938775510204,
      "grad_norm": 0.05171835422515869,
      "learning_rate": 6.737962817516022e-05,
      "loss": 0.0079,
      "step": 660
    },
    {
      "epoch": 1.3673469387755102,
      "grad_norm": 0.023897085338830948,
      "learning_rate": 6.626156749437736e-05,
      "loss": 0.0109,
      "step": 670
    },
    {
      "epoch": 1.3877551020408163,
      "grad_norm": 0.0025118710473179817,
      "learning_rate": 6.51343378118413e-05,
      "loss": 0.0021,
      "step": 680
    },
    {
      "epoch": 1.4081632653061225,
      "grad_norm": 0.00813466589897871,
      "learning_rate": 6.399857471024965e-05,
      "loss": 0.0266,
      "step": 690
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.019722266122698784,
      "learning_rate": 6.285491858382475e-05,
      "loss": 0.0235,
      "step": 700
    },
    {
      "epoch": 1.4489795918367347,
      "grad_norm": 0.21527841687202454,
      "learning_rate": 6.170401427723067e-05,
      "loss": 0.0151,
      "step": 710
    },
    {
      "epoch": 1.469387755102041,
      "grad_norm": 0.03950738161802292,
      "learning_rate": 6.054651072198085e-05,
      "loss": 0.0061,
      "step": 720
    },
    {
      "epoch": 1.489795918367347,
      "grad_norm": 0.08705093711614609,
      "learning_rate": 5.9383060570541384e-05,
      "loss": 0.0154,
      "step": 730
    },
    {
      "epoch": 1.510204081632653,
      "grad_norm": 0.023473531007766724,
      "learning_rate": 5.8214319828336194e-05,
      "loss": 0.0014,
      "step": 740
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 2.7474758625030518,
      "learning_rate": 5.704094748386184e-05,
      "loss": 0.0426,
      "step": 750
    },
    {
      "epoch": 1.5510204081632653,
      "grad_norm": 2.6704647541046143,
      "learning_rate": 5.58636051371201e-05,
      "loss": 0.0057,
      "step": 760
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.0010830298997461796,
      "learning_rate": 5.468295662657829e-05,
      "loss": 0.0164,
      "step": 770
    },
    {
      "epoch": 1.5918367346938775,
      "grad_norm": 0.012409155257046223,
      "learning_rate": 5.349966765486728e-05,
      "loss": 0.006,
      "step": 780
    },
    {
      "epoch": 1.6122448979591837,
      "grad_norm": 0.009279114194214344,
      "learning_rate": 5.2314405413428456e-05,
      "loss": 0.001,
      "step": 790
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 0.008056833408772945,
      "learning_rate": 5.1127838206321335e-05,
      "loss": 0.0136,
      "step": 800
    },
    {
      "epoch": 1.6530612244897958,
      "grad_norm": 5.688827991485596,
      "learning_rate": 4.994063507340356e-05,
      "loss": 0.0046,
      "step": 810
    },
    {
      "epoch": 1.6734693877551021,
      "grad_norm": 0.021618137136101723,
      "learning_rate": 4.875346541309637e-05,
      "loss": 0.002,
      "step": 820
    },
    {
      "epoch": 1.693877551020408,
      "grad_norm": 0.3618466854095459,
      "learning_rate": 4.7566998604947585e-05,
      "loss": 0.0123,
      "step": 830
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.0068455589935183525,
      "learning_rate": 4.638190363220547e-05,
      "loss": 0.0103,
      "step": 840
    },
    {
      "epoch": 1.7346938775510203,
      "grad_norm": 0.27623048424720764,
      "learning_rate": 4.5198848704615914e-05,
      "loss": 0.0164,
      "step": 850
    },
    {
      "epoch": 1.7551020408163265,
      "grad_norm": 0.05779486149549484,
      "learning_rate": 4.401850088165571e-05,
      "loss": 0.0039,
      "step": 860
    },
    {
      "epoch": 1.7755102040816326,
      "grad_norm": 0.0004895946476608515,
      "learning_rate": 4.28415256964146e-05,
      "loss": 0.0036,
      "step": 870
    },
    {
      "epoch": 1.7959183673469388,
      "grad_norm": 0.768013596534729,
      "learning_rate": 4.166858678033771e-05,
      "loss": 0.0134,
      "step": 880
    },
    {
      "epoch": 1.816326530612245,
      "grad_norm": 1.133692741394043,
      "learning_rate": 4.0500345489040515e-05,
      "loss": 0.0083,
      "step": 890
    },
    {
      "epoch": 1.836734693877551,
      "grad_norm": 0.05254926532506943,
      "learning_rate": 3.933746052940664e-05,
      "loss": 0.0077,
      "step": 900
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.8505430221557617,
      "learning_rate": 3.818058758817956e-05,
      "loss": 0.0242,
      "step": 910
    },
    {
      "epoch": 1.8775510204081631,
      "grad_norm": 2.3085079193115234,
      "learning_rate": 3.703037896225686e-05,
      "loss": 0.0273,
      "step": 920
    },
    {
      "epoch": 1.8979591836734695,
      "grad_norm": 0.013207762502133846,
      "learning_rate": 3.588748319089596e-05,
      "loss": 0.0042,
      "step": 930
    },
    {
      "epoch": 1.9183673469387754,
      "grad_norm": 0.004490827675908804,
      "learning_rate": 3.4752544690038647e-05,
      "loss": 0.0138,
      "step": 940
    },
    {
      "epoch": 1.9387755102040818,
      "grad_norm": 0.006205188110470772,
      "learning_rate": 3.362620338896032e-05,
      "loss": 0.0173,
      "step": 950
    },
    {
      "epoch": 1.9591836734693877,
      "grad_norm": 0.0880155861377716,
      "learning_rate": 3.250909436944928e-05,
      "loss": 0.0033,
      "step": 960
    },
    {
      "epoch": 1.9795918367346939,
      "grad_norm": 0.15165895223617554,
      "learning_rate": 3.140184750771895e-05,
      "loss": 0.0087,
      "step": 970
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0002902104170061648,
      "learning_rate": 3.0305087119255547e-05,
      "loss": 0.0027,
      "step": 980
    },
    {
      "epoch": 2.020408163265306,
      "grad_norm": 0.009533761069178581,
      "learning_rate": 2.9219431606800897e-05,
      "loss": 0.0059,
      "step": 990
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.09130481630563736,
      "learning_rate": 2.8145493111669186e-05,
      "loss": 0.0026,
      "step": 1000
    },
    {
      "epoch": 2.061224489795918,
      "grad_norm": 0.020419057458639145,
      "learning_rate": 2.708387716859425e-05,
      "loss": 0.0007,
      "step": 1010
    },
    {
      "epoch": 2.0816326530612246,
      "grad_norm": 0.003631926141679287,
      "learning_rate": 2.603518236430195e-05,
      "loss": 0.0017,
      "step": 1020
    },
    {
      "epoch": 2.1020408163265305,
      "grad_norm": 0.013878022320568562,
      "learning_rate": 2.500000000000001e-05,
      "loss": 0.0062,
      "step": 1030
    },
    {
      "epoch": 2.122448979591837,
      "grad_norm": 0.029890991747379303,
      "learning_rate": 2.3978913757975907e-05,
      "loss": 0.0019,
      "step": 1040
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.26849937438964844,
      "learning_rate": 2.297249937249058e-05,
      "loss": 0.0012,
      "step": 1050
    },
    {
      "epoch": 2.163265306122449,
      "grad_norm": 0.48884618282318115,
      "learning_rate": 2.1981324305153643e-05,
      "loss": 0.0017,
      "step": 1060
    },
    {
      "epoch": 2.183673469387755,
      "grad_norm": 0.0314396470785141,
      "learning_rate": 2.100594742496303e-05,
      "loss": 0.0023,
      "step": 1070
    },
    {
      "epoch": 2.204081632653061,
      "grad_norm": 1.0634057521820068,
      "learning_rate": 2.004691869318953e-05,
      "loss": 0.0021,
      "step": 1080
    },
    {
      "epoch": 2.2244897959183674,
      "grad_norm": 0.007490945048630238,
      "learning_rate": 1.910477885328399e-05,
      "loss": 0.0016,
      "step": 1090
    },
    {
      "epoch": 2.2448979591836733,
      "grad_norm": 0.0007616786169819534,
      "learning_rate": 1.8180059125981823e-05,
      "loss": 0.0021,
      "step": 1100
    },
    {
      "epoch": 2.2653061224489797,
      "grad_norm": 0.011547713540494442,
      "learning_rate": 1.727328090977702e-05,
      "loss": 0.0067,
      "step": 1110
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.002859343308955431,
      "learning_rate": 1.6384955486934156e-05,
      "loss": 0.0011,
      "step": 1120
    },
    {
      "epoch": 2.306122448979592,
      "grad_norm": 0.19982703030109406,
      "learning_rate": 1.551558373520455e-05,
      "loss": 0.0005,
      "step": 1130
    },
    {
      "epoch": 2.326530612244898,
      "grad_norm": 0.033438604325056076,
      "learning_rate": 1.4665655845408871e-05,
      "loss": 0.0003,
      "step": 1140
    },
    {
      "epoch": 2.3469387755102042,
      "grad_norm": 0.5412230491638184,
      "learning_rate": 1.38356510450456e-05,
      "loss": 0.0047,
      "step": 1150
    },
    {
      "epoch": 2.36734693877551,
      "grad_norm": 0.02409766986966133,
      "learning_rate": 1.3026037328081043e-05,
      "loss": 0.0014,
      "step": 1160
    },
    {
      "epoch": 2.387755102040816,
      "grad_norm": 0.026604412123560905,
      "learning_rate": 1.2237271191073268e-05,
      "loss": 0.0004,
      "step": 1170
    },
    {
      "epoch": 2.4081632653061225,
      "grad_norm": 0.002546228002756834,
      "learning_rate": 1.1469797375778901e-05,
      "loss": 0.0005,
      "step": 1180
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.012271756306290627,
      "learning_rate": 1.0724048618387788e-05,
      "loss": 0.0023,
      "step": 1190
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 0.0026880260556936264,
      "learning_rate": 1.000044540552681e-05,
      "loss": 0.0003,
      "step": 1200
    },
    {
      "epoch": 2.4693877551020407,
      "grad_norm": 0.0003071462269872427,
      "learning_rate": 9.299395737170757e-06,
      "loss": 0.0002,
      "step": 1210
    },
    {
      "epoch": 2.489795918367347,
      "grad_norm": 0.0024168698582798243,
      "learning_rate": 8.621294896593535e-06,
      "loss": 0.0005,
      "step": 1220
    },
    {
      "epoch": 2.510204081632653,
      "grad_norm": 0.0008788177510723472,
      "learning_rate": 7.966525227489769e-06,
      "loss": 0.0002,
      "step": 1230
    },
    {
      "epoch": 2.5306122448979593,
      "grad_norm": 0.013314674608409405,
      "learning_rate": 7.33545591839222e-06,
      "loss": 0.0003,
      "step": 1240
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 0.00303016509860754,
      "learning_rate": 6.728442794506773e-06,
      "loss": 0.0002,
      "step": 1250
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.0006959500606171787,
      "learning_rate": 6.145828117082187e-06,
      "loss": 0.001,
      "step": 1260
    },
    {
      "epoch": 2.5918367346938775,
      "grad_norm": 0.00043282771366648376,
      "learning_rate": 5.587940390427804e-06,
      "loss": 0.0019,
      "step": 1270
    },
    {
      "epoch": 2.612244897959184,
      "grad_norm": 0.0013360020238906145,
      "learning_rate": 5.055094176688108e-06,
      "loss": 0.0035,
      "step": 1280
    },
    {
      "epoch": 2.63265306122449,
      "grad_norm": 0.3828214704990387,
      "learning_rate": 4.547589918478456e-06,
      "loss": 0.0008,
      "step": 1290
    },
    {
      "epoch": 2.6530612244897958,
      "grad_norm": 0.010694854892790318,
      "learning_rate": 4.065713769482082e-06,
      "loss": 0.0001,
      "step": 1300
    },
    {
      "epoch": 2.673469387755102,
      "grad_norm": 0.0028905747458338737,
      "learning_rate": 3.6097374331037324e-06,
      "loss": 0.0001,
      "step": 1310
    },
    {
      "epoch": 2.693877551020408,
      "grad_norm": 0.012663854286074638,
      "learning_rate": 3.1799180092711376e-06,
      "loss": 0.0005,
      "step": 1320
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.23777519166469574,
      "learning_rate": 2.776497849470544e-06,
      "loss": 0.0044,
      "step": 1330
    },
    {
      "epoch": 2.7346938775510203,
      "grad_norm": 0.0016951982397586107,
      "learning_rate": 2.399704420098009e-06,
      "loss": 0.0003,
      "step": 1340
    },
    {
      "epoch": 2.7551020408163263,
      "grad_norm": 0.004429919179528952,
      "learning_rate": 2.0497501742037073e-06,
      "loss": 0.0046,
      "step": 1350
    },
    {
      "epoch": 2.7755102040816326,
      "grad_norm": 0.5244802236557007,
      "learning_rate": 1.7268324317012975e-06,
      "loss": 0.0004,
      "step": 1360
    },
    {
      "epoch": 2.795918367346939,
      "grad_norm": 0.027252044528722763,
      "learning_rate": 1.4311332681101464e-06,
      "loss": 0.0005,
      "step": 1370
    },
    {
      "epoch": 2.816326530612245,
      "grad_norm": 0.005387682002037764,
      "learning_rate": 1.1628194118929403e-06,
      "loss": 0.001,
      "step": 1380
    },
    {
      "epoch": 2.836734693877551,
      "grad_norm": 0.07596255838871002,
      "learning_rate": 9.220421504467281e-07,
      "loss": 0.001,
      "step": 1390
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.01582220010459423,
      "learning_rate": 7.08937244800284e-07,
      "loss": 0.0005,
      "step": 1400
    },
    {
      "epoch": 2.877551020408163,
      "grad_norm": 0.0006362875574268401,
      "learning_rate": 5.236248530659182e-07,
      "loss": 0.0001,
      "step": 1410
    },
    {
      "epoch": 2.8979591836734695,
      "grad_norm": 0.006212462205439806,
      "learning_rate": 3.662094626889656e-07,
      "loss": 0.0001,
      "step": 1420
    },
    {
      "epoch": 2.9183673469387754,
      "grad_norm": 0.008587191812694073,
      "learning_rate": 2.3677983153307937e-07,
      "loss": 0.0011,
      "step": 1430
    },
    {
      "epoch": 2.938775510204082,
      "grad_norm": 0.022679781541228294,
      "learning_rate": 1.354089378345469e-07,
      "loss": 0.0001,
      "step": 1440
    },
    {
      "epoch": 2.9591836734693877,
      "grad_norm": 0.02521207183599472,
      "learning_rate": 6.215393905388278e-08,
      "loss": 0.0004,
      "step": 1450
    },
    {
      "epoch": 2.979591836734694,
      "grad_norm": 0.005231223069131374,
      "learning_rate": 1.705613964789743e-08,
      "loss": 0.0001,
      "step": 1460
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.00031977047910913825,
      "learning_rate": 1.4096778039318636e-10,
      "loss": 0.0002,
      "step": 1470
    }
  ],
  "logging_steps": 10,
  "max_steps": 1470,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.199076039254344e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
