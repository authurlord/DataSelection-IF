{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_json('train/RE/RE/RE-train.json')\n",
    "select_file = pd.read_json('train/RE/RE/train-select.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'RE'\n",
    "dataset = 'RE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_3431715/459085310.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n"
     ]
    }
   ],
   "source": [
    "ppl_array = np.zeros(len(train_file))\n",
    "for process_num in range(1,9,1): ## maximum of k process\n",
    "    if os.path.exists('ppl/{}/{}/ppl-init-{}.csv'.format(task,dataset,process_num)): ## i-th gradient \n",
    "        ppl_df = pd.read_csv('ppl/{}/{}/ppl-init-{}.csv'.format(task,dataset,process_num),index_col=0)\n",
    "        for index,row in ppl_df.iterrows():\n",
    "            ppl_array[index] = row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ppl_array`: shape和文件全集保持相同，所有数据by case的perplexity number，一个array\n",
    "- `ppl_array`越大越困难，data selection baseline可以按照ppl_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `greedyList_All_norm_flatten`是一个dict，key是index，value是对应的Facility Location Score\n",
    "- 需要写一个函数，来检查哪些更大\n",
    "- `greedyList_All_norm_flatten`越大越好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedyList_All_norm_flatten = torch.load('selection/{}/{}/FL-Score.pkl'.format(task,dataset),weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler = torch.load('Influence/{}/{}/batch.pkl'.format(task,dataset),weights_only=False)\n",
    "sample_IF = torch.load('Influence/{}/{}/score.pkl'.format(task,dataset),weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(sample_IF):\n",
    "    \"\"\"\n",
    "    对sample_IF字典中各个'method'对应的值（键为index、值为float的字典）进行Z-score归一化。\n",
    "\n",
    "    参数:\n",
    "    sample_IF (dict): 包含多个'method'键的字典，每个'method'键对应的值为需要进行归一化处理的字典数据。\n",
    "\n",
    "    返回:\n",
    "    dict: 归一化后的字典，结构与输入的sample_IF一致，其中每个'method'键对应的值都已经完成Z-score归一化。\n",
    "    \"\"\"\n",
    "    for method in sample_IF.keys():\n",
    "        # 获取当前method对应需要归一化的值列表，保持原有顺序\n",
    "        values_list = list(sample_IF[method].values())\n",
    "        # 将列表转换为torch.Tensor\n",
    "        tensor_value = torch.tensor(values_list).unsqueeze(1)  # 添加维度，变为二维张量\n",
    "\n",
    "        # 计算均值和标准差\n",
    "        mean_value = tensor_value.mean()\n",
    "        std_value = tensor_value.std()\n",
    "\n",
    "        # 进行Z-score归一化\n",
    "        normalized_tensor = (tensor_value - mean_value) / std_value\n",
    "\n",
    "        # 将归一化后的结果再转换回列表\n",
    "        normalized_list = normalized_tensor.squeeze(1).tolist()\n",
    "\n",
    "        # 更新原字典中当前method对应的值\n",
    "        index_list = list(sample_IF[method].keys())\n",
    "        normalized_dict = {}\n",
    "        for index, normalized_value in zip(index_list, normalized_list):\n",
    "            normalized_dict[index] = normalized_value\n",
    "\n",
    "        sample_IF[method] = normalized_dict\n",
    "\n",
    "    return sample_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_IF = z_score_normalize(sample_IF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1667,  942, 1678, 5770, 1673, 1674, 1677, 1669, 5234, 6461])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(ppl_array)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.75"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_array[6461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "def get_top_k_indices(data_dict: dict, k: int, IF = False) -> list:\n",
    "    \"\"\"\n",
    "    从字典中获取前 K 个最大数值对应的索引。\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): 输入字典，key 为索引，value 为数值。\n",
    "                          例如：{0: 10, 1: 5, 2: 20, 3: 8}\n",
    "        k (int): 要获取的最大元素的数量。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含前 K 个最大数值对应索引的列表，按数值从大到小排序。\n",
    "              如果 k 大于字典的元素数量，将返回所有索引。\n",
    "    \"\"\"\n",
    "    if not isinstance(data_dict, dict):\n",
    "        raise TypeError(\"Input 'data_dict' must be a dictionary.\")\n",
    "    if not isinstance(k, int) or k < 0:\n",
    "        raise ValueError(\"Input 'k' must be a non-negative integer.\")\n",
    "\n",
    "    if k == 0:\n",
    "        return []\n",
    "    if not data_dict:\n",
    "        return []\n",
    "\n",
    "    # 使用 heapq.nlargest 获取前 K 个最大的 (value, key) 对\n",
    "    # nlargest 默认按第一个元素（value）排序\n",
    "    # 注意：nlargest 返回的顺序是数值从大到小\n",
    "    if not IF: ## 如果按照降序排列，默认为True\n",
    "        top_k_items = heapq.nlargest(k, data_dict.items(), key=lambda item: item[1])\n",
    "    else: ## 如果按照升序排列\n",
    "        top_k_items = heapq.nsmallest(k, data_dict.items(), key=lambda item: item[1])        \n",
    "\n",
    "    # 提取索引（key）并返回\n",
    "    # item[0] 是原始的 key\n",
    "    top_k_indices = [item[0] for item in top_k_items]\n",
    "\n",
    "    return top_k_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.491122722625732"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_IF['proposed'][3142]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IF=True: 倒序查找，IF\n",
    "- IF=False: 顺序查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_k_indices(sample_IF['proposed'],k=len(select_file),IF=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppl': {'micro_f1': 0.8912733446519525, 'macro_f1': 0.7014128856663336},\n",
       " 'FL': {'micro_f1': 0.9272665534804754, 'macro_f1': 0.7401582353894606},\n",
       " 'IF': {'micro_f1': 0.7860780984719864, 'macro_f1': 0.5283008735899821}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
