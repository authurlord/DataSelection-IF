{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2768f438",
   "metadata": {},
   "source": [
    "# Mislabeled data detection - RoBERTa-MRPC\n",
    "\n",
    "This notebook demonstrates how to efficiently compute the influence functions using DataInf, showing its application to **mislabeled data detection** tasks.\n",
    "\n",
    "- Model: Robert-large (https://arxiv.org/abs/1907.11692; pretrained with publicly available datasets including BOOKCORPUS, WIKIPEDIA, and CC-NEWS)\n",
    "- Fine-tuning dataset: GLUE-mrpc\n",
    "    - What is MRPC? The Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) is a corpus of sentence pairs automatically extracted from online news sources, with human annotations for whether the sentences in the pair are semantically equivalent.\n",
    "\n",
    "References\n",
    "- https://github.com/huggingface/peft/blob/main/examples/sequence_classification/LoRA.ipynb\n",
    "- DataInf is available at this [ArXiv link](https://arxiv.org/abs/2310.00902)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b8aee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='www.modelscope.cn', port=443): Max retries exceeded with url: /api/v1/datasets/qnli/glue (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7ff092ca1010>, 'Connection to www.modelscope.cn timed out. (connect timeout=60)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connection.py:615\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x7ff092ca1010>, 'Connection to www.modelscope.cn timed out. (connect timeout=60)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    872\u001b[0m     )\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    872\u001b[0m     )\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.modelscope.cn', port=443): Max retries exceeded with url: /api/v1/datasets/qnli/glue (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7ff092ca1010>, 'Connection to www.modelscope.cn timed out. (connect timeout=60)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MsDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# # Load the cola dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# train_datasets = MsDataset.load('glue', subset_name='cola', split='train')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# eval_datasets = MsDataset.load('glue', subset_name='cola', split='validation')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mMsDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqnli\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/modelscope/msdatasets/ms_dataset.py:290\u001b[0m, in \u001b[0;36mMsDataset.load\u001b[0;34m(dataset_name, namespace, target, version, hub, subset_name, split, data_dir, data_files, download_mode, cache_dir, use_streaming, stream_batch_size, custom_cfg, token, dataset_info_only, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HubApi\n\u001b[1;32m    289\u001b[0m _api \u001b[38;5;241m=\u001b[39m HubApi()\n\u001b[0;32m--> 290\u001b[0m dataset_id_on_hub, dataset_type \u001b[38;5;241m=\u001b[39m \u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset_id_and_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Load from the ModelScope Hub for type=4 (general)\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(dataset_type) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(DatasetFormations\u001b[38;5;241m.\u001b[39mgeneral\u001b[38;5;241m.\u001b[39mvalue):\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/modelscope/hub/api.py:790\u001b[0m, in \u001b[0;36mHubApi.get_dataset_id_and_type\u001b[0;34m(self, dataset_name, namespace)\u001b[0m\n\u001b[1;32m    788\u001b[0m datahub_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/v1/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnamespace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    789\u001b[0m cookies \u001b[38;5;241m=\u001b[39m ModelScopeConfig\u001b[38;5;241m.\u001b[39mget_cookies()\n\u001b[0;32m--> 790\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatahub_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m resp \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    792\u001b[0m datahub_raise_on_error(datahub_url, resp, r)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='www.modelscope.cn', port=443): Max retries exceeded with url: /api/v1/datasets/qnli/glue (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7ff092ca1010>, 'Connection to www.modelscope.cn timed out. (connect timeout=60)'))"
     ]
    }
   ],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "# # Load the cola dataset\n",
    "# train_datasets = MsDataset.load('glue', subset_name='cola', split='train')\n",
    "# eval_datasets = MsDataset.load('glue', subset_name='cola', split='validation')\n",
    "\n",
    "MsDataset.load(\n",
    "            \"glue\",\n",
    "            'qnli',\n",
    "            cache_dir=None,\n",
    "            use_auth_token=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625da945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "# from dataloader import create_dataloaders\n",
    "from dataloader_ER import create_dataloaders\n",
    "# from lora_model import LORAEngine,LORAEngineDeberta,LORAEngineDebertaMultiClass\n",
    "from lora_model_vmap import LORAEngineDebertaMultiClass\n",
    "\n",
    "# from influence import IFEngine\n",
    "from influence_hyperinf import IFEngine\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaeb117",
   "metadata": {},
   "source": [
    "## Set up hyperparameters and LoRA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025c666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_or_path=\"roberta-large\"\n",
    "# model_name_or_path=\"/home/yanmy/roberta-base\"\n",
    "model_name_or_path=\"../../model/deberta-v3-base\"\n",
    "# model_name_or_path=\"../../model/roberta-large\"\n",
    "# task=\"mrpc\"\n",
    "task = \"ER\"\n",
    "noise_ratio=0\n",
    "batch_size=32\n",
    "# target_modules=[\"query_proj\", \"key_proj\", \"value_proj\"] ## deberta, for roberta, use [\"value\"]\n",
    "# target_modules = ['value']\n",
    "target_modules=[\"value_proj\"] ## deberta, for roberta, use [\"value\"]\n",
    "\n",
    "device=\"cuda:3\"\n",
    "num_epochs=4\n",
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e778490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning models\n",
    "dataloader_outputs = create_dataloaders(model_name_or_path=model_name_or_path,\n",
    "                                           task=task,\n",
    "                                           noise_ratio=noise_ratio,\n",
    "                                           batch_size=batch_size)\n",
    "train_dataloader, eval_dataloader, noise_index, tokenized_datasets, collate_fn=dataloader_outputs\n",
    "\n",
    "# lora_engine = LORAEngine(model_name_or_path=model_name_or_path,\n",
    "#                             target_modules=target_modules,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             eval_dataloader=eval_dataloader,\n",
    "#                             device=device,\n",
    "#                             num_epochs=num_epochs,\n",
    "#                             lr=lr,\n",
    "#                             low_rank=8, \n",
    "#                             task=task)\n",
    "\n",
    "lora_engine = LORAEngineDeberta(model_name_or_path=model_name_or_path,\n",
    "                            target_modules=target_modules,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            eval_dataloader=eval_dataloader,\n",
    "                            device=device,\n",
    "                            num_epochs=num_epochs,\n",
    "                            lr=lr,\n",
    "                            low_rank=8, \n",
    "                            task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19785d2",
   "metadata": {},
   "source": [
    "## Fine-tune a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8736e452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fe06d4abd3456cb57d64125fd8a89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98889c2e44d4b8cacb50e19f631ecc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/737 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e5790583e14cd79d20fc7285ebbd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fine-tuning models\n",
    "# dataloader_outputs = create_dataloaders(model_name_or_path=model_name_or_path,\n",
    "#                                            task=task,\n",
    "#                                            noise_ratio=noise_ratio,\n",
    "#                                            batch_size=batch_size,\n",
    "#                                            train_file = '../ER/semi-text-c-FUSER/train.json',\n",
    "#                                            valid_file = '../ER/semi-text-c-FUSER/valid.json',\n",
    "#                                            test_file = '../ER/semi-text-c-FUSER/test.json')\n",
    "\n",
    "\n",
    "dataloader_outputs = create_dataloaders(model_name_or_path=model_name_or_path,\n",
    "                                           task=task,\n",
    "                                           noise_ratio=noise_ratio,\n",
    "                                           batch_size=batch_size,\n",
    "                                           train_file = '../ER/semi-text-c/train.json',\n",
    "                                           valid_file = '../ER/semi-text-c/valid.json',\n",
    "                                           test_file = '../ER/semi-text-c/test.json',\n",
    "                                           max_length=256)\n",
    "# train_dataloader, eval_dataloader, noise_index, tokenized_datasets, collate_fn=dataloader_outputs\n",
    "train_dataloader, eval_dataloader,test_dataloader, noise_index, tokenized_datasets, collate_fn=dataloader_outputs\n",
    "\n",
    "\n",
    "# lora_engine = LORAEngine(model_name_or_path=model_name_or_path,\n",
    "#                             target_modules=target_modules,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             eval_dataloader=eval_dataloader,\n",
    "#                             device=device,\n",
    "#                             num_epochs=num_epochs,\n",
    "#                             lr=lr,\n",
    "#                             low_rank=8, \n",
    "#                             task=task)\n",
    "\n",
    "lora_engine = LORAEngineDebertaMultiClass(model_name_or_path=model_name_or_path,\n",
    "                            target_modules=target_modules,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            # eval_dataloader=eval_dataloader,\n",
    "                            eval_dataloader=eval_dataloader,\n",
    "                            test_dataloader = test_dataloader,\n",
    "                            device=device,\n",
    "                            num_epochs=num_epochs,\n",
    "                            lr=lr,\n",
    "                            low_rank=16, \n",
    "                            task=task,\n",
    "                            save_path = '../models/ER',\n",
    "                            valid_each_epoch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acd02f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ../../model/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,450 || all params: 184,720,132 || trainable%: 0.1605\n",
      "Total Steps:564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 141/141 [00:16<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 0.505478358437829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:15<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 0.19228826483037878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:15<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 0.14015114000925782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:15<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 0.1141124431717586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:19<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Result on Test Data: {'f1': 0.8093841642228738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_engine.build_LORA_model()\n",
    "lora_engine.train_LORA_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06576452",
   "metadata": {},
   "source": [
    "## Compute the gradient\n",
    " - Influence function uses the first-order gradient of a loss function. Here we compute gradients using `compute_gradient`\n",
    " - `tr_grad_dict` has a nested structure of two Python dictionaries. The outer dictionary has `{an index of the training data: a dictionary of gradients}` and the inner dictionary has `{layer name: gradients}`. The `val_grad_dict` has the same structure but for the validationd data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acb4bd",
   "metadata": {},
   "source": [
    "## Compute the influence function\n",
    " - We compute the inverse Hessian vector product first using `compute_hvps()`. With the argument `compute_accurate=True`, the exact influence function value will be computed. (it may take an hour to compute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf312d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "vmap(single_sample_grad, in_dims=(None, None, None, 0, 0, 0), ...)(<inputs>): Got in_dim=0 for an input but the input is of type <class 'str'>. We cannot vmap over non-Tensor arguments, please use None as the respective in_dim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tr_grad_dict, val_grad_dict \u001b[38;5;241m=\u001b[39m \u001b[43mlora_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/home/wangys/DataSelection-IF/notebooks/../src/lora_model_vmap.py:174\u001b[0m, in \u001b[0;36mLORAEngineDebertaMultiClass.compute_gradient\u001b[0;34m(self, tokenized_datasets, collate_fn, batch_size)\u001b[0m\n\u001b[1;32m    167\u001b[0m sample_tensors \u001b[38;5;241m=\u001b[39m [input_ids, attention_mask]\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# 使用vmap对单个样本梯度计算函数在批次维度向量化\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# grads = torch.func.vmap(\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m#     single_sample_grad,\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m#     in_dims=(0, None, None, None),\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m#     randomness=\"different\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# )(sample_tensors, self.model, func_weights, func_buffers)\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_sample_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_buffers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# 处理梯度字典，筛选并转换梯度格式（和原代码类似的筛选逻辑，根据实际情况调整）\u001b[39;00m\n\u001b[1;32m    181\u001b[0m grad_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/torch/_functorch/apis.py:201\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/torch/_functorch/vmap.py:312\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m lazy_load_decompositions()\n\u001b[1;32m    311\u001b[0m _check_out_dims_is_int_or_int_pytree(out_dims, func)\n\u001b[0;32m--> 312\u001b[0m batch_size, flat_in_dims, flat_args, args_spec \u001b[38;5;241m=\u001b[39m \u001b[43m_process_batched_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     chunks_flat_args \u001b[38;5;241m=\u001b[39m _get_chunked_inputs(\n\u001b[1;32m    318\u001b[0m         flat_args, flat_in_dims, batch_size, chunk_size\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/deepspeed/lib/python3.12/site-packages/torch/_functorch/vmap.py:126\u001b[0m, in \u001b[0;36m_process_batched_inputs\u001b[0;34m(in_dims, args, func)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_name(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in_dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ...)(<inputs>): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot in_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for an input but in_dim must be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man integer dimension or None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(in_dim, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Tensor):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_name(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in_dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ...)(<inputs>): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot in_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for an input but the input is of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. We cannot vmap over non-Tensor arguments, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use None as the respective in_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (in_dim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39marg\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mor\u001b[39;00m in_dim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mdim()):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_name(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in_dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ...)(<inputs>): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot in_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for some input, but that input is a Tensor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof dimensionality \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m so expected in_dim to satisfy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <= in_dim < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: vmap(single_sample_grad, in_dims=(None, None, None, 0, 0, 0), ...)(<inputs>): Got in_dim=0 for an input but the input is of type <class 'str'>. We cannot vmap over non-Tensor arguments, please use None as the respective in_dim"
     ]
    }
   ],
   "source": [
    "tr_grad_dict, val_grad_dict = lora_engine.compute_gradient(tokenized_datasets, collate_fn, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f21c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import pickle, os\n",
    "import torch\n",
    "import numpy as np\n",
    "class IFEngine(object):\n",
    "        # 初始化存储时间、Hessian-Vector Product (HVP) 结果和影响函数（Influence Function）值的字典\n",
    "\n",
    "    def __init__(self):\n",
    "        self.time_dict=defaultdict(list)\n",
    "        self.hvp_dict=defaultdict(list)\n",
    "        self.IF_dict=defaultdict(list)\n",
    "\n",
    "    def preprocess_gradients(self, tr_grad_dict, val_grad_dict, noise_index=None): # 存储训练集和验证集的梯度字典，并计算验证集平均梯度\n",
    "        self.tr_grad_dict = tr_grad_dict # 训练集梯度字典\n",
    "        self.val_grad_dict = val_grad_dict # 验证集梯度字典\n",
    "        self.noise_index = noise_index # 可选的噪声索引（用于异常值处理）\n",
    "        # 存储训练集和验证集的样本数\n",
    "        self.n_train = len(self.tr_grad_dict.keys())\n",
    "        self.n_val = len(self.val_grad_dict.keys())\n",
    "        self.compute_val_grad_avg() # 计算验证集平均梯度\n",
    "\n",
    "    def compute_val_grad_avg(self):\n",
    "        # Compute the avg gradient on the validation dataset\n",
    "        self.val_grad_avg_dict={}\n",
    "        for weight_name in self.val_grad_dict[0]:\n",
    "            # 初始化为与梯度同设备的零向量\n",
    "            self.val_grad_avg_dict[weight_name]=torch.zeros(self.val_grad_dict[0][weight_name].shape).to(self.val_grad_dict[0][weight_name].device)\n",
    "            # 逐个样本累加梯度并取平均值\n",
    "            for val_id in self.val_grad_dict:\n",
    "                self.val_grad_avg_dict[weight_name] += self.val_grad_dict[val_id][weight_name] / self.n_val\n",
    "\n",
    "    def compute_hvps(self, lambda_const_param=10, compute_accurate=True, compute_LiSSA=True):\n",
    "        '''\n",
    "        Compute the influence function score under each method\n",
    "        '''\n",
    "        self.compute_hvp_iterative(lambda_const_param=lambda_const_param) ## HyperInf,使用 Schulz 迭代法计算 HVP 和近似 Hessian 逆矩阵\n",
    "        self.compute_hvp_identity() ## Baseline TracIn\n",
    "        self.compute_hvp_proposed(lambda_const_param=lambda_const_param) ## Datainf\n",
    "        if compute_LiSSA:\n",
    "            self.compute_hvp_LiSSA(lambda_const_param=lambda_const_param)\n",
    "        if compute_accurate:\n",
    "            self.compute_hvp_accurate(lambda_const_param=lambda_const_param)\n",
    "\n",
    "    def compute_hvp_identity(self):\n",
    "        '''\n",
    "        TracIN\n",
    "        '''\n",
    "        start_time = time()\n",
    "        self.hvp_dict['identity'] = self.val_grad_avg_dict.copy()\n",
    "        self.time_dict['identity'] = time()-start_time\n",
    "        print(\"Time taken for Hessian-free: \", self.time_dict['identity'])\n",
    "\n",
    "    def compute_hvp_iterative(self, lambda_const_param=10, n_iteration=30):\n",
    "        '''\n",
    "        Compute the influence funcion score by our method HyperINF\n",
    "        '''\n",
    "\n",
    "        def schulz_inverse_stable(A, damping_factor=0, max_iterations=20, tol=1e-6):\n",
    "            n = A.shape[0]\n",
    "            #I = np.eye(n)\n",
    "            I = torch.eye(n, device=A.device)\n",
    "            A_damped = A + damping_factor * I  # Apply damping for stable\n",
    "\n",
    "            #X = np.eye(n) * 0.00005  # Initial estimate of inverse matrix\n",
    "            X = torch.eye(n, device=A.device) * 0.00005  # Initial estimate of inverse matrix\n",
    "\n",
    "            for _ in range(max_iterations):\n",
    "                # 通过 Schulz 方法更新逆矩阵估计值\n",
    "                #X = X.dot(2 * I - A_damped.dot(X))\n",
    "                X = X @ (2 * I - A_damped @ X)\n",
    "\n",
    "                # # Check for convergence\n",
    "                # if np.linalg.norm(I - A.dot(X)) < tol:\n",
    "                #     break\n",
    "\n",
    "            return X\n",
    "\n",
    "        start_time = time()\n",
    "        hvp_iterative_dict={}\n",
    "\n",
    "        for _, weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
    "            # lambda_const computation = 0.1 x (n * d_l)^(-1) \\sum_{i=1}^{n} ||grad_i^l||_2^2, 计算 λ（正则化系数）：基于梯度的方差\n",
    "            S=torch.zeros(len(self.tr_grad_dict.keys())).to(self.val_grad_avg_dict[weight_name].device)\n",
    "            for tr_id in self.tr_grad_dict:\n",
    "                tmp_grad = self.tr_grad_dict[tr_id][weight_name]\n",
    "                S[tr_id]=torch.mean(tmp_grad**2)\n",
    "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
    "\n",
    "            # iterative hvp computation\n",
    "            # G_l: same shape of self.tr_grad_dict[0][weight_name].T @ self.tr_grad_dict[0][weight_name]\n",
    "            # 构造 Fisher 信息矩阵（近似 Hessian）\n",
    "            G_l = torch.zeros((self.tr_grad_dict[0][weight_name].T @ self.tr_grad_dict[0][weight_name]).shape).to(self.val_grad_avg_dict[weight_name].device)\n",
    "            for tr_id in self.tr_grad_dict:\n",
    "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device) # (grad_i^l)^T\n",
    "                G_l += tmp_grad.T @ tmp_grad / self.n_train\n",
    "                \n",
    "            # 加入正则化项以保证矩阵可逆\n",
    "            G_l = G_l + lambda_const * torch.eye(G_l.shape[0], device=G_l.device)\n",
    "           # G_l = G_l.cpu().detach().numpy()\n",
    "           # 使用 Schulz 方法近似计算逆矩阵\n",
    "            # G_l_inv = schulz_inverse_stable(G_l, damping_factor=0.001, max_iterations=n_iteration, tol=1e-6)\n",
    "            G_l_inv = torch.inverse(G_l)\n",
    "            print(G_l.shape,G_l_inv.shape)\n",
    "            # 计算 HVP: G_l_inv @ val_grad_avg\n",
    "            hvp_iterative_dict[weight_name] = torch.tensor(self.val_grad_avg_dict[weight_name] @ G_l_inv)\n",
    "            #print(hvp_iterative_dict[weight_name])\n",
    "        self.hvp_dict['iterative'] = hvp_iterative_dict\n",
    "        self.time_dict['iterative'] = time()-start_time\n",
    "        print(\"Time taken for HyperINF: \", self.time_dict['iterative'])\n",
    "\n",
    "\n",
    "\n",
    "    def compute_hvp_proposed(self, lambda_const_param=10):\n",
    "        '''\n",
    "        DataInf method\n",
    "        '''\n",
    "        start_time = time()\n",
    "        hvp_proposed_dict={}\n",
    "\n",
    "        for _ , weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
    "            # lambda_const computation = 0.1 x (n * d_l)^(-1) \\sum_{i=1}^{n} ||grad_i^l||_2^2\n",
    "            S=torch.zeros(len(self.tr_grad_dict.keys())).to(self.val_grad_avg_dict[weight_name].device)\n",
    "            for tr_id in self.tr_grad_dict:\n",
    "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device)\n",
    "                S[tr_id]=torch.mean(tmp_grad**2)\n",
    "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
    "\n",
    "            # hvp computation\n",
    "            hvp=torch.zeros(self.val_grad_avg_dict[weight_name].shape).to(self.val_grad_avg_dict[weight_name].device)\n",
    "            for tr_id in self.tr_grad_dict: # i\n",
    "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device) # grad_i^l\n",
    "                # L_(l,i) / (lambda + ||grad_i^l||_2^2) in Eqn. (5)\n",
    "                C_tmp = torch.sum(self.val_grad_avg_dict[weight_name] * tmp_grad) / (lambda_const + torch.sum(tmp_grad**2)).to(self.val_grad_avg_dict[weight_name].device)\n",
    "                # (v_l^T - C_tmp * (grad_i^l)^T ) / (n * lambda) in Eqn. (5)\n",
    "                hvp += (self.val_grad_avg_dict[weight_name] - C_tmp*tmp_grad) / (self.n_train*lambda_const)\n",
    "            hvp_proposed_dict[weight_name] = hvp\n",
    "        self.hvp_dict['proposed'] = hvp_proposed_dict\n",
    "        self.time_dict['proposed'] = time()-start_time\n",
    "        print(\"Time taken for Datainf: \", self.time_dict['proposed'])\n",
    "\n",
    "    def compute_hvp_accurate(self, lambda_const_param=10):\n",
    "        start_time = time()\n",
    "        hvp_accurate_dict={}\n",
    "        for _ , weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
    "\n",
    "            # lambda_const computation\n",
    "            S=torch.zeros(len(self.tr_grad_dict.keys()))\n",
    "            for tr_id in self.tr_grad_dict:\n",
    "                tmp_grad = self.tr_grad_dict[tr_id][weight_name]\n",
    "                S[tr_id]=torch.mean(tmp_grad**2)\n",
    "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
    "\n",
    "            # hvp computation (eigenvalue decomposition)\n",
    "            AAt_matrix = torch.zeros(torch.outer(self.tr_grad_dict[0][weight_name].reshape(-1),\n",
    "                                                 self.tr_grad_dict[0][weight_name].reshape(-1)).shape)\n",
    "            for tr_id in self.tr_grad_dict:\n",
    "\n",
    "                tmp_mat = torch.outer(self.tr_grad_dict[tr_id][weight_name].reshape(-1),\n",
    "                                      self.tr_grad_dict[tr_id][weight_name].reshape(-1))\n",
    "                AAt_matrix += tmp_mat\n",
    "\n",
    "\n",
    "            L, V = torch.linalg.eig(AAt_matrix)\n",
    "            L, V = L.float(), V.float()\n",
    "            hvp = self.val_grad_avg_dict[weight_name].reshape(-1) @ V\n",
    "            hvp = (hvp / (lambda_const + L/ self.n_train)) @ V.T\n",
    "\n",
    "            hvp_accurate_dict[weight_name] = hvp.reshape(len(self.tr_grad_dict[0][weight_name]), -1)\n",
    "            del tmp_mat, AAt_matrix, V # to save memory\n",
    "        self.hvp_dict['accurate'] = hvp_accurate_dict\n",
    "        self.time_dict['accurate'] = time()-start_time\n",
    "        print(\"Time taken for Accurate: \", self.time_dict['accurate'])\n",
    "\n",
    "    def compute_hvp_LiSSA(self, lambda_const_param=10, n_iteration=10, alpha_const=1.):\n",
    "        '''\n",
    "        LiSSA method\n",
    "        '''\n",
    "        start_time = time()\n",
    "        hvp_LiSSA_dict={}\n",
    "\n",
    "        for _, weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
    "            # lambda_const computation\n",
    "            S=torch.zeros(len(self.tr_grad_dict.keys())).to(self.val_grad_avg_dict[weight_name].device)\n",
    "            for tr_id in self.tr_grad_dict:\n",
    "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device)\n",
    "                S[tr_id]=torch.mean(tmp_grad**2)\n",
    "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
    "\n",
    "            # hvp computation\n",
    "            running_hvp=self.val_grad_avg_dict[weight_name]\n",
    "            for _ in range(n_iteration):\n",
    "                hvp_tmp=torch.zeros(self.val_grad_avg_dict[weight_name].shape).to(self.val_grad_avg_dict[weight_name].device)\n",
    "                for tr_id in self.tr_grad_dict:\n",
    "                    tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device)\n",
    "                    hvp_tmp += (torch.sum(tmp_grad*running_hvp)*tmp_grad - lambda_const*running_hvp) / self.n_train\n",
    "\n",
    "                running_hvp = self.val_grad_avg_dict[weight_name] + running_hvp - alpha_const*hvp_tmp\n",
    "            hvp_LiSSA_dict[weight_name] = running_hvp\n",
    "\n",
    "        self.hvp_dict['LiSSA'] = hvp_LiSSA_dict\n",
    "        self.time_dict['LiSSA'] = time()-start_time\n",
    "        print(\"Time taken for LiSSA: \", self.time_dict['LiSSA'])\n",
    "\n",
    "    def compute_IF(self):\n",
    "        for method_name in self.hvp_dict:\n",
    "            if_tmp_dict = {}\n",
    "            for tr_id in self.tr_grad_dict:\n",
    "                if_tmp_value = 0\n",
    "                for weight_name in self.val_grad_avg_dict:\n",
    "                    if_tmp_value += torch.sum(self.hvp_dict[method_name][weight_name]*self.tr_grad_dict[tr_id][weight_name])\n",
    "                if_tmp_dict[tr_id]= -if_tmp_value.cpu()\n",
    "               # print(-if_tmp_value)\n",
    "\n",
    "            self.IF_dict[method_name] = pd.Series(if_tmp_dict, dtype=float).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7d01d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b6ceab93ac45a08d49a6953b1e3672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "Time taken for HyperINF:  7.937711477279663\n",
      "Time taken for Hessian-free:  3.0994415283203125e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f816b217d184953af42657ef1b29940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Datainf:  15.164361238479614\n"
     ]
    }
   ],
   "source": [
    "influence_engine = IFEngine()\n",
    "influence_engine.preprocess_gradients(tr_grad_dict, val_grad_dict, noise_index)\n",
    "\n",
    "influence_engine.compute_hvps(compute_accurate=False,compute_LiSSA=False)\n",
    "influence_engine.compute_IF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85318fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 146.31735229, 1650.41796875,  180.49357605, ...,  285.13562012,\n",
       "          5.19919968,  148.25637817])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influence_engine.IF_dict['proposed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba4e6aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 146.31735229, 1650.41796875,  180.49357605, ...,  285.13562012,\n",
       "          5.19919968,  148.25637817])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = torch.load('/home/yanmy/HyperINF-main/output/output_fp16_deberta_ER_v_proj.pkl')\n",
    "result['proposed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11dd8ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df6281b31d545e9869ecfd30f0039e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8a8ec086f64f3f8630bf6e4d7ac7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766122d443a846f4be41a8ad0846eb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "Time taken for HyperINF:  7.681562423706055\n",
      "Time taken for Hessian-free:  6.4373016357421875e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2086f48c809d48948a09f90e7be56a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Datainf:  15.23117733001709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a077a79fba8a4d009bd44f26998c4e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for LiSSA:  75.86726307868958\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "IF_device = 'cuda:3' ## 避免爆显存\n",
    "for key in tqdm(tr_grad_dict): ## 尝试转为fp16计算\n",
    "    for kk in tr_grad_dict[key]:\n",
    "        tr_grad_dict[key][kk] = tr_grad_dict[key][kk].to(IF_device)\n",
    "for key in tqdm(val_grad_dict):\n",
    "    for kk in val_grad_dict[key]:\n",
    "        val_grad_dict[key][kk] = val_grad_dict[key][kk].to(IF_device)\n",
    "\n",
    "influence_engine = IFEngine()\n",
    "influence_engine.preprocess_gradients(tr_grad_dict, val_grad_dict, noise_index)\n",
    "\n",
    "influence_engine.compute_hvps(compute_accurate=False,compute_LiSSA=True)\n",
    "influence_engine.compute_IF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3d426fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(influence_engine.IF_dict,'../../HyperINF-main/output/output_fp16_deberta_ER_v_proj_inv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba66074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from influence_hyperinf import IFEngine\n",
    "from tqdm.notebook import tqdm\n",
    "IF_device = 'cuda:2' ## 避免爆显存\n",
    "# tr_grad_dict_IF = tr_grad_dict.copy()\n",
    "# val_grad_dict_IF = val_grad_dict.copy()\n",
    "# ## to cuda\n",
    "for key in tqdm(tr_grad_dict): ## 尝试转为fp16计算\n",
    "    for kk in tr_grad_dict[key]:\n",
    "        tr_grad_dict[key][kk] = tr_grad_dict[key][kk].to(IF_device)\n",
    "\n",
    "for key in tqdm(val_grad_dict):\n",
    "    for kk in val_grad_dict[key]:\n",
    "        val_grad_dict[key][kk] = val_grad_dict[key][kk].to(IF_device)\n",
    "\n",
    "\n",
    "## compute influence function\n",
    "influence_engine = IFEngine()\n",
    "influence_engine.preprocess_gradients(tr_grad_dict, val_grad_dict, noise_index)\n",
    "\n",
    "influence_engine.compute_hvps(compute_accurate=False,compute_LiSSA=True)\n",
    "influence_engine.compute_IF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cca0c",
   "metadata": {},
   "source": [
    "## Attributes of influence_engine\n",
    "There are a couple of useful attributes in `influence_engine`. For intance, to compare the runtime, one case use `time_dict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9f7b3",
   "metadata": {},
   "source": [
    "`IF_dict` includes all the computed influence function values. Here, `identity` indicates the `Hessian-free` influence computation method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1371a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n",
      "4.46.3\n"
     ]
    }
   ],
   "source": [
    "# -*- encoding:utf-8 -*-\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "print(torch.__version__)  # 1.7.1\n",
    "print(transformers.__version__) # 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa121b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanmy/anaconda3/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    "    DebertaV2ForSequenceClassification, DebertaV2Tokenizer, AdamW, get_linear_schedule_with_warmup,AutoTokenizer\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/yanmy/model/deberta-v3-base/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f71cec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'influence_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43minfluence_engine\u001b[49m\u001b[38;5;241m.\u001b[39mIF_dict,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../HyperINF-main/output/output_fp16_deberta_all.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'influence_engine' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.save(influence_engine.IF_dict,'../../HyperINF-main/output/output_fp16_deberta_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "758a8382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00820148,  0.00500778,  0.00903799, ..., -0.02732378,\n",
       "        0.06782677,  0.20921639])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influence_engine.IF_dict['identity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c866c",
   "metadata": {},
   "source": [
    "## retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d03a7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "result = torch.load('/home/yanmy/HyperINF-main/output/output_fp16_deberta.pkl')\n",
    "index = np.argsort(result['proposed'])[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c93a786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    261\n",
       "0    239\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_json('../ER/semi-text-c/train.json').iloc[index,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "713fd5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.argsort(result['proposed'])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e9e07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.load('/home/yanmy/HyperINF-main/output/output_deberta_fp16_ER.pkl')\n",
    "b = np.argsort(result['proposed'])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a4d3f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(a).intersection(set(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00d5ead1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1073\n",
       "0     427\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "result = torch.load('/home/yanmy/HyperINF-main/output/output_fp16_deberta_ER_v_proj_inv.pkl')\n",
    "index = np.argsort(result['iterative'])[:1500]\n",
    "import pandas as pd\n",
    "pd.read_json('../ER/semi-text-c/train.json').iloc[index,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f60952b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5846b1c47f441e8a78306b52e3c33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fffb3ca8d414b078607ad3d9c44cab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/737 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80163251615e49f1acf3db216f8838ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_or_path=\"/home/yanmy/model/deberta-v3-base\" \n",
    "# task=\"mrpc\"\n",
    "task = \"ER\"\n",
    "noise_ratio=0\n",
    "batch_size=32\n",
    "# target_modules=[\"query_proj\", \"key_proj\", \"value_proj\"] ## deberta, for roberta, use [\"value\"]\n",
    "target_modules=[\"value_proj\"] ## deberta, for roberta, use [\"value\"]\n",
    "\n",
    "device=\"cuda:3\"\n",
    "num_epochs=10\n",
    "lr=3e-4\n",
    "\n",
    "\n",
    "dataloader_outputs = create_dataloaders(model_name_or_path=model_name_or_path,\n",
    "                                           task=task,\n",
    "                                           noise_ratio=noise_ratio,\n",
    "                                           batch_size=batch_size,\n",
    "                                           train_file = '../ER/semi-text-c/train.json',\n",
    "                                           valid_file = '../ER/semi-text-c/valid.json',\n",
    "                                           test_file = '../ER/semi-text-c/test.json',\n",
    "                                           max_length=256,\n",
    "                                           select_index=index)\n",
    "# train_dataloader, eval_dataloader, noise_index, tokenized_datasets, collate_fn=dataloader_outputs\n",
    "train_dataloader, eval_dataloader,test_dataloader, noise_index, tokenized_datasets, collate_fn=dataloader_outputs\n",
    "\n",
    "\n",
    "# lora_engine = LORAEngine(model_name_or_path=model_name_or_path,\n",
    "#                             target_modules=target_modules,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             eval_dataloader=eval_dataloader,\n",
    "#                             device=device,\n",
    "#                             num_epochs=num_epochs,\n",
    "#                             lr=lr,\n",
    "#                             low_rank=8, \n",
    "#                             task=task)\n",
    "\n",
    "lora_engine = LORAEngineDebertaMultiClass(model_name_or_path=model_name_or_path,\n",
    "                            target_modules=target_modules,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            # eval_dataloader=eval_dataloader,\n",
    "                            eval_dataloader=eval_dataloader,\n",
    "                            test_dataloader = test_dataloader,\n",
    "                            device=device,\n",
    "                            num_epochs=num_epochs,\n",
    "                            lr=lr,\n",
    "                            low_rank=8, \n",
    "                            task=task,\n",
    "                            save_path = '../models/ER',\n",
    "                            valid_each_epoch = True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a18ce",
   "metadata": {},
   "source": [
    "`output/output_fp16_deberta.pkl`\n",
    "- 1000: {'f1': 0.7783063748810657}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66adb5a",
   "metadata": {},
   "source": [
    "## Application to mislabeled data detection task\n",
    "- We compare the mislabeled data detection ability of different influence computation methods. Given that large influence function values are likely to increase the validation loss, data points with large influence fucntion values are desired to be mislabeled. \n",
    "- We inspect data points from the largest to lowest influence function values and evaluate the detection rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2ab5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=influence_engine.n_train\n",
    "true_label=np.zeros(n_train)\n",
    "true_label[noise_index]=1\n",
    "\n",
    "method_dict={'identity': 'Hessian-free',\n",
    "            'proposed': 'DataInf',\n",
    "            'LiSSA': 'LiSSA'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0335e",
   "metadata": {},
   "source": [
    "Requirement already satisfied: torch in /home/yanmy/anaconda3/lib/python3.9/site-packages (1.13.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44833374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "for method in influence_engine.IF_dict:\n",
    "    detection_rate_list=[]\n",
    "    low_quality_to_high_quality=np.argsort(influence_engine.IF_dict[method])[::-1]\n",
    "    for ind in range(1, len(low_quality_to_high_quality)+1):\n",
    "        detected_samples = set(low_quality_to_high_quality[:ind]).intersection(noise_index)\n",
    "        detection_rate = 100*len(detected_samples)/len(noise_index)\n",
    "        detection_rate_list.append(detection_rate)\n",
    "    plt.plot(100*np.arange(len(low_quality_to_high_quality))/n_train, \n",
    "             detection_rate_list,\n",
    "             label=method_dict[method])\n",
    "plt.xlabel('Data inspected (%)', fontsize=18)\n",
    "plt.ylabel('Detection Rate (%)', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=15)\n",
    "plt.title('Mislabeled Data Detection', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e60ae-368c-4bc1-977f-5deeaf5fe862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3332f3a-f5e0-4ce4-9748-3d51f161bb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
