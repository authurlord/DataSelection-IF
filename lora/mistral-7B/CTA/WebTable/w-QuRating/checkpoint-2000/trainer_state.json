{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0828370330265296,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005414185165132647,
      "grad_norm": 125.84483337402344,
      "learning_rate": 2.432432432432433e-06,
      "loss": 4.7168,
      "step": 10
    },
    {
      "epoch": 0.010828370330265295,
      "grad_norm": 52.09004592895508,
      "learning_rate": 5.135135135135136e-06,
      "loss": 3.5279,
      "step": 20
    },
    {
      "epoch": 0.016242555495397944,
      "grad_norm": 26.09783172607422,
      "learning_rate": 7.837837837837838e-06,
      "loss": 2.6042,
      "step": 30
    },
    {
      "epoch": 0.02165674066053059,
      "grad_norm": 20.314117431640625,
      "learning_rate": 1.0540540540540541e-05,
      "loss": 0.9146,
      "step": 40
    },
    {
      "epoch": 0.02707092582566324,
      "grad_norm": 4.854868412017822,
      "learning_rate": 1.3243243243243244e-05,
      "loss": 0.3835,
      "step": 50
    },
    {
      "epoch": 0.03248511099079589,
      "grad_norm": 11.562946319580078,
      "learning_rate": 1.5945945945945947e-05,
      "loss": 0.4187,
      "step": 60
    },
    {
      "epoch": 0.03789929615592853,
      "grad_norm": 9.63088607788086,
      "learning_rate": 1.864864864864865e-05,
      "loss": 0.3676,
      "step": 70
    },
    {
      "epoch": 0.04331348132106118,
      "grad_norm": 4.453158378601074,
      "learning_rate": 2.1351351351351353e-05,
      "loss": 0.1218,
      "step": 80
    },
    {
      "epoch": 0.04872766648619383,
      "grad_norm": 7.841948986053467,
      "learning_rate": 2.4054054054054056e-05,
      "loss": 0.0658,
      "step": 90
    },
    {
      "epoch": 0.05414185165132648,
      "grad_norm": 1.6542608737945557,
      "learning_rate": 2.6756756756756756e-05,
      "loss": 0.119,
      "step": 100
    },
    {
      "epoch": 0.05955603681645912,
      "grad_norm": 1.1822863817214966,
      "learning_rate": 2.945945945945946e-05,
      "loss": 0.0788,
      "step": 110
    },
    {
      "epoch": 0.06497022198159177,
      "grad_norm": 1.4891260862350464,
      "learning_rate": 3.2162162162162165e-05,
      "loss": 0.0181,
      "step": 120
    },
    {
      "epoch": 0.07038440714672442,
      "grad_norm": 5.63910436630249,
      "learning_rate": 3.486486486486487e-05,
      "loss": 0.1264,
      "step": 130
    },
    {
      "epoch": 0.07579859231185707,
      "grad_norm": 10.248591423034668,
      "learning_rate": 3.756756756756757e-05,
      "loss": 0.0681,
      "step": 140
    },
    {
      "epoch": 0.08121277747698971,
      "grad_norm": 4.169712066650391,
      "learning_rate": 4.0270270270270274e-05,
      "loss": 0.0578,
      "step": 150
    },
    {
      "epoch": 0.08662696264212236,
      "grad_norm": 1.317439317703247,
      "learning_rate": 4.297297297297298e-05,
      "loss": 0.0296,
      "step": 160
    },
    {
      "epoch": 0.092041147807255,
      "grad_norm": 3.992046356201172,
      "learning_rate": 4.567567567567568e-05,
      "loss": 0.0898,
      "step": 170
    },
    {
      "epoch": 0.09745533297238766,
      "grad_norm": 0.3586070239543915,
      "learning_rate": 4.837837837837838e-05,
      "loss": 0.0408,
      "step": 180
    },
    {
      "epoch": 0.10286951813752031,
      "grad_norm": 4.471882343292236,
      "learning_rate": 5.1081081081081086e-05,
      "loss": 0.0397,
      "step": 190
    },
    {
      "epoch": 0.10828370330265295,
      "grad_norm": 0.764348030090332,
      "learning_rate": 5.378378378378378e-05,
      "loss": 0.0416,
      "step": 200
    },
    {
      "epoch": 0.1136978884677856,
      "grad_norm": 15.63594913482666,
      "learning_rate": 5.648648648648649e-05,
      "loss": 0.0698,
      "step": 210
    },
    {
      "epoch": 0.11911207363291824,
      "grad_norm": 0.08774740248918533,
      "learning_rate": 5.918918918918919e-05,
      "loss": 0.0291,
      "step": 220
    },
    {
      "epoch": 0.12452625879805089,
      "grad_norm": 5.901494979858398,
      "learning_rate": 6.189189189189189e-05,
      "loss": 0.0705,
      "step": 230
    },
    {
      "epoch": 0.12994044396318355,
      "grad_norm": 2.41074538230896,
      "learning_rate": 6.459459459459459e-05,
      "loss": 0.0835,
      "step": 240
    },
    {
      "epoch": 0.1353546291283162,
      "grad_norm": 3.990743637084961,
      "learning_rate": 6.72972972972973e-05,
      "loss": 0.0557,
      "step": 250
    },
    {
      "epoch": 0.14076881429344884,
      "grad_norm": 0.5979434847831726,
      "learning_rate": 7e-05,
      "loss": 0.0515,
      "step": 260
    },
    {
      "epoch": 0.1461829994585815,
      "grad_norm": 0.28575748205184937,
      "learning_rate": 7.27027027027027e-05,
      "loss": 0.061,
      "step": 270
    },
    {
      "epoch": 0.15159718462371413,
      "grad_norm": 1.7549219131469727,
      "learning_rate": 7.54054054054054e-05,
      "loss": 0.049,
      "step": 280
    },
    {
      "epoch": 0.15701136978884678,
      "grad_norm": 1.6557278633117676,
      "learning_rate": 7.810810810810811e-05,
      "loss": 0.0653,
      "step": 290
    },
    {
      "epoch": 0.16242555495397942,
      "grad_norm": 3.4390883445739746,
      "learning_rate": 8.08108108108108e-05,
      "loss": 0.0402,
      "step": 300
    },
    {
      "epoch": 0.16783974011911207,
      "grad_norm": 0.09036239236593246,
      "learning_rate": 8.351351351351352e-05,
      "loss": 0.0402,
      "step": 310
    },
    {
      "epoch": 0.17325392528424471,
      "grad_norm": 3.6212005615234375,
      "learning_rate": 8.621621621621621e-05,
      "loss": 0.0494,
      "step": 320
    },
    {
      "epoch": 0.17866811044937736,
      "grad_norm": 0.1447906792163849,
      "learning_rate": 8.891891891891892e-05,
      "loss": 0.0162,
      "step": 330
    },
    {
      "epoch": 0.18408229561451,
      "grad_norm": 0.673901379108429,
      "learning_rate": 9.162162162162162e-05,
      "loss": 0.0578,
      "step": 340
    },
    {
      "epoch": 0.18949648077964265,
      "grad_norm": 0.8859617114067078,
      "learning_rate": 9.432432432432433e-05,
      "loss": 0.0433,
      "step": 350
    },
    {
      "epoch": 0.19491066594477532,
      "grad_norm": 0.2760806083679199,
      "learning_rate": 9.702702702702702e-05,
      "loss": 0.051,
      "step": 360
    },
    {
      "epoch": 0.20032485110990797,
      "grad_norm": 1.4033362865447998,
      "learning_rate": 9.972972972972973e-05,
      "loss": 0.0404,
      "step": 370
    },
    {
      "epoch": 0.20573903627504062,
      "grad_norm": 2.7674193382263184,
      "learning_rate": 9.999819116012134e-05,
      "loss": 0.0378,
      "step": 380
    },
    {
      "epoch": 0.21115322144017326,
      "grad_norm": 0.04012174904346466,
      "learning_rate": 9.99919385483188e-05,
      "loss": 0.0203,
      "step": 390
    },
    {
      "epoch": 0.2165674066053059,
      "grad_norm": 0.021367007866501808,
      "learning_rate": 9.998122039161928e-05,
      "loss": 0.0209,
      "step": 400
    },
    {
      "epoch": 0.22198159177043855,
      "grad_norm": 3.3930253982543945,
      "learning_rate": 9.996603764742536e-05,
      "loss": 0.0659,
      "step": 410
    },
    {
      "epoch": 0.2273957769355712,
      "grad_norm": 3.0523598194122314,
      "learning_rate": 9.99463916719402e-05,
      "loss": 0.0337,
      "step": 420
    },
    {
      "epoch": 0.23280996210070384,
      "grad_norm": 6.736275672912598,
      "learning_rate": 9.992228422004645e-05,
      "loss": 0.0191,
      "step": 430
    },
    {
      "epoch": 0.2382241472658365,
      "grad_norm": 3.5886807441711426,
      "learning_rate": 9.989371744514949e-05,
      "loss": 0.0344,
      "step": 440
    },
    {
      "epoch": 0.24363833243096913,
      "grad_norm": 2.753753662109375,
      "learning_rate": 9.986069389898502e-05,
      "loss": 0.0487,
      "step": 450
    },
    {
      "epoch": 0.24905251759610178,
      "grad_norm": 5.27712869644165,
      "learning_rate": 9.982321653139126e-05,
      "loss": 0.0542,
      "step": 460
    },
    {
      "epoch": 0.25446670276123445,
      "grad_norm": 1.3543390035629272,
      "learning_rate": 9.978128869004524e-05,
      "loss": 0.0364,
      "step": 470
    },
    {
      "epoch": 0.2598808879263671,
      "grad_norm": 1.6606029272079468,
      "learning_rate": 9.973491412016401e-05,
      "loss": 0.0585,
      "step": 480
    },
    {
      "epoch": 0.26529507309149974,
      "grad_norm": 6.667534828186035,
      "learning_rate": 9.968409696416986e-05,
      "loss": 0.0441,
      "step": 490
    },
    {
      "epoch": 0.2707092582566324,
      "grad_norm": 1.2167683839797974,
      "learning_rate": 9.962884176132057e-05,
      "loss": 0.0467,
      "step": 500
    },
    {
      "epoch": 0.27612344342176504,
      "grad_norm": 2.236240863800049,
      "learning_rate": 9.956915344730363e-05,
      "loss": 0.0389,
      "step": 510
    },
    {
      "epoch": 0.2815376285868977,
      "grad_norm": 0.11750505119562149,
      "learning_rate": 9.950503735379561e-05,
      "loss": 0.0683,
      "step": 520
    },
    {
      "epoch": 0.2869518137520303,
      "grad_norm": 1.8754128217697144,
      "learning_rate": 9.943649920798578e-05,
      "loss": 0.0188,
      "step": 530
    },
    {
      "epoch": 0.292365998917163,
      "grad_norm": 0.08526628464460373,
      "learning_rate": 9.936354513206456e-05,
      "loss": 0.032,
      "step": 540
    },
    {
      "epoch": 0.2977801840822956,
      "grad_norm": 3.003363847732544,
      "learning_rate": 9.928618164267665e-05,
      "loss": 0.0384,
      "step": 550
    },
    {
      "epoch": 0.30319436924742826,
      "grad_norm": 0.3713514804840088,
      "learning_rate": 9.920441565033892e-05,
      "loss": 0.0442,
      "step": 560
    },
    {
      "epoch": 0.3086085544125609,
      "grad_norm": 7.691275119781494,
      "learning_rate": 9.911825445882316e-05,
      "loss": 0.0885,
      "step": 570
    },
    {
      "epoch": 0.31402273957769355,
      "grad_norm": 0.5232574939727783,
      "learning_rate": 9.902770576450364e-05,
      "loss": 0.0412,
      "step": 580
    },
    {
      "epoch": 0.3194369247428262,
      "grad_norm": 0.0693608894944191,
      "learning_rate": 9.893277765566959e-05,
      "loss": 0.0214,
      "step": 590
    },
    {
      "epoch": 0.32485110990795885,
      "grad_norm": 1.7488300800323486,
      "learning_rate": 9.883347861180283e-05,
      "loss": 0.0387,
      "step": 600
    },
    {
      "epoch": 0.3302652950730915,
      "grad_norm": 0.9067704081535339,
      "learning_rate": 9.87298175028202e-05,
      "loss": 0.0322,
      "step": 610
    },
    {
      "epoch": 0.33567948023822414,
      "grad_norm": 0.6581000685691833,
      "learning_rate": 9.862180358828133e-05,
      "loss": 0.0335,
      "step": 620
    },
    {
      "epoch": 0.3410936654033568,
      "grad_norm": 1.8716267347335815,
      "learning_rate": 9.850944651656152e-05,
      "loss": 0.0363,
      "step": 630
    },
    {
      "epoch": 0.34650785056848943,
      "grad_norm": 0.24174907803535461,
      "learning_rate": 9.839275632398989e-05,
      "loss": 0.0308,
      "step": 640
    },
    {
      "epoch": 0.3519220357336221,
      "grad_norm": 0.11814843863248825,
      "learning_rate": 9.827174343395286e-05,
      "loss": 0.0535,
      "step": 650
    },
    {
      "epoch": 0.3573362208987547,
      "grad_norm": 1.492432951927185,
      "learning_rate": 9.814641865596312e-05,
      "loss": 0.04,
      "step": 660
    },
    {
      "epoch": 0.36275040606388737,
      "grad_norm": 1.641128659248352,
      "learning_rate": 9.801679318469401e-05,
      "loss": 0.0296,
      "step": 670
    },
    {
      "epoch": 0.36816459122902,
      "grad_norm": 0.19025912880897522,
      "learning_rate": 9.788287859897964e-05,
      "loss": 0.033,
      "step": 680
    },
    {
      "epoch": 0.37357877639415266,
      "grad_norm": 0.017675884068012238,
      "learning_rate": 9.774468686078051e-05,
      "loss": 0.024,
      "step": 690
    },
    {
      "epoch": 0.3789929615592853,
      "grad_norm": 1.970911979675293,
      "learning_rate": 9.760223031411505e-05,
      "loss": 0.0291,
      "step": 700
    },
    {
      "epoch": 0.38440714672441795,
      "grad_norm": 2.3891661167144775,
      "learning_rate": 9.745552168395701e-05,
      "loss": 0.0482,
      "step": 710
    },
    {
      "epoch": 0.38982133188955065,
      "grad_norm": 0.34417304396629333,
      "learning_rate": 9.730457407509875e-05,
      "loss": 0.0351,
      "step": 720
    },
    {
      "epoch": 0.3952355170546833,
      "grad_norm": 2.2434170246124268,
      "learning_rate": 9.714940097098069e-05,
      "loss": 0.0183,
      "step": 730
    },
    {
      "epoch": 0.40064970221981594,
      "grad_norm": 1.1336456537246704,
      "learning_rate": 9.699001623248686e-05,
      "loss": 0.0168,
      "step": 740
    },
    {
      "epoch": 0.4060638873849486,
      "grad_norm": 0.26655063033103943,
      "learning_rate": 9.682643409670681e-05,
      "loss": 0.0142,
      "step": 750
    },
    {
      "epoch": 0.41147807255008123,
      "grad_norm": 0.018038704991340637,
      "learning_rate": 9.665866917566385e-05,
      "loss": 0.026,
      "step": 760
    },
    {
      "epoch": 0.4168922577152139,
      "grad_norm": 0.2737966775894165,
      "learning_rate": 9.648673645500985e-05,
      "loss": 0.0065,
      "step": 770
    },
    {
      "epoch": 0.4223064428803465,
      "grad_norm": 2.12507963180542,
      "learning_rate": 9.631065129268664e-05,
      "loss": 0.0419,
      "step": 780
    },
    {
      "epoch": 0.42772062804547917,
      "grad_norm": 0.1116512268781662,
      "learning_rate": 9.613042941755409e-05,
      "loss": 0.0547,
      "step": 790
    },
    {
      "epoch": 0.4331348132106118,
      "grad_norm": 0.9920666217803955,
      "learning_rate": 9.594608692798526e-05,
      "loss": 0.0379,
      "step": 800
    },
    {
      "epoch": 0.43854899837574446,
      "grad_norm": 0.0758490338921547,
      "learning_rate": 9.575764029042826e-05,
      "loss": 0.0378,
      "step": 810
    },
    {
      "epoch": 0.4439631835408771,
      "grad_norm": 0.005599972791969776,
      "learning_rate": 9.55651063379355e-05,
      "loss": 0.011,
      "step": 820
    },
    {
      "epoch": 0.44937736870600975,
      "grad_norm": 1.5851383209228516,
      "learning_rate": 9.536850226866e-05,
      "loss": 0.0244,
      "step": 830
    },
    {
      "epoch": 0.4547915538711424,
      "grad_norm": 0.09629037231206894,
      "learning_rate": 9.516784564431917e-05,
      "loss": 0.0299,
      "step": 840
    },
    {
      "epoch": 0.46020573903627504,
      "grad_norm": 0.47334450483322144,
      "learning_rate": 9.496315438862616e-05,
      "loss": 0.0288,
      "step": 850
    },
    {
      "epoch": 0.4656199242014077,
      "grad_norm": 0.5971724390983582,
      "learning_rate": 9.475444678568872e-05,
      "loss": 0.0236,
      "step": 860
    },
    {
      "epoch": 0.47103410936654033,
      "grad_norm": 0.01746099442243576,
      "learning_rate": 9.454174147837607e-05,
      "loss": 0.0623,
      "step": 870
    },
    {
      "epoch": 0.476448294531673,
      "grad_norm": 0.17525719106197357,
      "learning_rate": 9.432505746665351e-05,
      "loss": 0.0139,
      "step": 880
    },
    {
      "epoch": 0.4818624796968056,
      "grad_norm": 0.14830513298511505,
      "learning_rate": 9.410441410588537e-05,
      "loss": 0.0601,
      "step": 890
    },
    {
      "epoch": 0.48727666486193827,
      "grad_norm": 3.1174051761627197,
      "learning_rate": 9.3879831105106e-05,
      "loss": 0.0557,
      "step": 900
    },
    {
      "epoch": 0.4926908500270709,
      "grad_norm": 0.22923779487609863,
      "learning_rate": 9.365132852525924e-05,
      "loss": 0.0047,
      "step": 910
    },
    {
      "epoch": 0.49810503519220356,
      "grad_norm": 0.0387270525097847,
      "learning_rate": 9.341892677740657e-05,
      "loss": 0.0199,
      "step": 920
    },
    {
      "epoch": 0.5035192203573362,
      "grad_norm": 0.03415464237332344,
      "learning_rate": 9.318264662090376e-05,
      "loss": 0.036,
      "step": 930
    },
    {
      "epoch": 0.5089334055224689,
      "grad_norm": 3.0797295570373535,
      "learning_rate": 9.29425091615466e-05,
      "loss": 0.0243,
      "step": 940
    },
    {
      "epoch": 0.5143475906876015,
      "grad_norm": 0.14299878478050232,
      "learning_rate": 9.269853584968568e-05,
      "loss": 0.0362,
      "step": 950
    },
    {
      "epoch": 0.5197617758527342,
      "grad_norm": 0.035804953426122665,
      "learning_rate": 9.245074847831021e-05,
      "loss": 0.0147,
      "step": 960
    },
    {
      "epoch": 0.5251759610178668,
      "grad_norm": 0.9607359170913696,
      "learning_rate": 9.219916918110138e-05,
      "loss": 0.0094,
      "step": 970
    },
    {
      "epoch": 0.5305901461829995,
      "grad_norm": 0.14787735044956207,
      "learning_rate": 9.194382043045537e-05,
      "loss": 0.0294,
      "step": 980
    },
    {
      "epoch": 0.5360043313481321,
      "grad_norm": 1.3866773843765259,
      "learning_rate": 9.168472503547586e-05,
      "loss": 0.0193,
      "step": 990
    },
    {
      "epoch": 0.5414185165132648,
      "grad_norm": 0.9536610245704651,
      "learning_rate": 9.142190613993666e-05,
      "loss": 0.0224,
      "step": 1000
    },
    {
      "epoch": 0.5468327016783974,
      "grad_norm": 0.094327911734581,
      "learning_rate": 9.115538722021442e-05,
      "loss": 0.0238,
      "step": 1010
    },
    {
      "epoch": 0.5522468868435301,
      "grad_norm": 0.06930060684680939,
      "learning_rate": 9.088519208319154e-05,
      "loss": 0.0193,
      "step": 1020
    },
    {
      "epoch": 0.5576610720086627,
      "grad_norm": 0.27972403168678284,
      "learning_rate": 9.061134486412962e-05,
      "loss": 0.0104,
      "step": 1030
    },
    {
      "epoch": 0.5630752571737954,
      "grad_norm": 0.028068341314792633,
      "learning_rate": 9.03338700245136e-05,
      "loss": 0.0158,
      "step": 1040
    },
    {
      "epoch": 0.568489442338928,
      "grad_norm": 0.011992385610938072,
      "learning_rate": 9.005279234986672e-05,
      "loss": 0.0368,
      "step": 1050
    },
    {
      "epoch": 0.5739036275040607,
      "grad_norm": 1.7494678497314453,
      "learning_rate": 8.976813694753651e-05,
      "loss": 0.0202,
      "step": 1060
    },
    {
      "epoch": 0.5793178126691932,
      "grad_norm": 0.15968522429466248,
      "learning_rate": 8.947992924445213e-05,
      "loss": 0.0202,
      "step": 1070
    },
    {
      "epoch": 0.584731997834326,
      "grad_norm": 0.019011400640010834,
      "learning_rate": 8.918819498485303e-05,
      "loss": 0.0578,
      "step": 1080
    },
    {
      "epoch": 0.5901461829994585,
      "grad_norm": 1.394095778465271,
      "learning_rate": 8.889296022798941e-05,
      "loss": 0.0776,
      "step": 1090
    },
    {
      "epoch": 0.5955603681645912,
      "grad_norm": 1.5680569410324097,
      "learning_rate": 8.859425134579444e-05,
      "loss": 0.0592,
      "step": 1100
    },
    {
      "epoch": 0.6009745533297238,
      "grad_norm": 1.3112528324127197,
      "learning_rate": 8.829209502052857e-05,
      "loss": 0.0258,
      "step": 1110
    },
    {
      "epoch": 0.6063887384948565,
      "grad_norm": 2.210642099380493,
      "learning_rate": 8.798651824239612e-05,
      "loss": 0.0561,
      "step": 1120
    },
    {
      "epoch": 0.6118029236599891,
      "grad_norm": 1.292048692703247,
      "learning_rate": 8.767754830713439e-05,
      "loss": 0.0252,
      "step": 1130
    },
    {
      "epoch": 0.6172171088251218,
      "grad_norm": 0.140386700630188,
      "learning_rate": 8.73652128135755e-05,
      "loss": 0.037,
      "step": 1140
    },
    {
      "epoch": 0.6226312939902545,
      "grad_norm": 1.0726150274276733,
      "learning_rate": 8.704953966118103e-05,
      "loss": 0.0135,
      "step": 1150
    },
    {
      "epoch": 0.6280454791553871,
      "grad_norm": 0.24958038330078125,
      "learning_rate": 8.673055704754994e-05,
      "loss": 0.0066,
      "step": 1160
    },
    {
      "epoch": 0.6334596643205198,
      "grad_norm": 0.1304091513156891,
      "learning_rate": 8.640829346589979e-05,
      "loss": 0.0314,
      "step": 1170
    },
    {
      "epoch": 0.6388738494856524,
      "grad_norm": 0.013022479601204395,
      "learning_rate": 8.608277770252165e-05,
      "loss": 0.0253,
      "step": 1180
    },
    {
      "epoch": 0.6442880346507851,
      "grad_norm": 2.787271499633789,
      "learning_rate": 8.575403883420867e-05,
      "loss": 0.0144,
      "step": 1190
    },
    {
      "epoch": 0.6497022198159177,
      "grad_norm": 0.09507196396589279,
      "learning_rate": 8.542210622565879e-05,
      "loss": 0.0036,
      "step": 1200
    },
    {
      "epoch": 0.6551164049810504,
      "grad_norm": 0.00226972927339375,
      "learning_rate": 8.508700952685175e-05,
      "loss": 0.0227,
      "step": 1210
    },
    {
      "epoch": 0.660530590146183,
      "grad_norm": 1.0151863098144531,
      "learning_rate": 8.474877867040067e-05,
      "loss": 0.0178,
      "step": 1220
    },
    {
      "epoch": 0.6659447753113157,
      "grad_norm": 22.912487030029297,
      "learning_rate": 8.440744386887818e-05,
      "loss": 0.0485,
      "step": 1230
    },
    {
      "epoch": 0.6713589604764483,
      "grad_norm": 0.984298050403595,
      "learning_rate": 8.406303561211774e-05,
      "loss": 0.0161,
      "step": 1240
    },
    {
      "epoch": 0.676773145641581,
      "grad_norm": 0.3730125427246094,
      "learning_rate": 8.371558466449011e-05,
      "loss": 0.0174,
      "step": 1250
    },
    {
      "epoch": 0.6821873308067136,
      "grad_norm": 0.004657266195863485,
      "learning_rate": 8.336512206215539e-05,
      "loss": 0.0141,
      "step": 1260
    },
    {
      "epoch": 0.6876015159718463,
      "grad_norm": 0.0064207641407847404,
      "learning_rate": 8.301167911029055e-05,
      "loss": 0.0137,
      "step": 1270
    },
    {
      "epoch": 0.6930157011369789,
      "grad_norm": 0.05174608901143074,
      "learning_rate": 8.265528738029324e-05,
      "loss": 0.0223,
      "step": 1280
    },
    {
      "epoch": 0.6984298863021116,
      "grad_norm": 1.818171501159668,
      "learning_rate": 8.229597870696157e-05,
      "loss": 0.0323,
      "step": 1290
    },
    {
      "epoch": 0.7038440714672441,
      "grad_norm": 0.9815323352813721,
      "learning_rate": 8.19337851856505e-05,
      "loss": 0.012,
      "step": 1300
    },
    {
      "epoch": 0.7092582566323768,
      "grad_norm": 2.1632232666015625,
      "learning_rate": 8.156873916940489e-05,
      "loss": 0.0267,
      "step": 1310
    },
    {
      "epoch": 0.7146724417975094,
      "grad_norm": 0.007005088496953249,
      "learning_rate": 8.120087326606957e-05,
      "loss": 0.0126,
      "step": 1320
    },
    {
      "epoch": 0.7200866269626421,
      "grad_norm": 1.1907438039779663,
      "learning_rate": 8.083022033537664e-05,
      "loss": 0.0185,
      "step": 1330
    },
    {
      "epoch": 0.7255008121277747,
      "grad_norm": 1.1393976211547852,
      "learning_rate": 8.045681348601025e-05,
      "loss": 0.0195,
      "step": 1340
    },
    {
      "epoch": 0.7309149972929074,
      "grad_norm": 4.078137397766113,
      "learning_rate": 8.008068607264912e-05,
      "loss": 0.0185,
      "step": 1350
    },
    {
      "epoch": 0.73632918245804,
      "grad_norm": 1.4351844787597656,
      "learning_rate": 7.970187169298724e-05,
      "loss": 0.0047,
      "step": 1360
    },
    {
      "epoch": 0.7417433676231727,
      "grad_norm": 0.6353096961975098,
      "learning_rate": 7.932040418473263e-05,
      "loss": 0.0363,
      "step": 1370
    },
    {
      "epoch": 0.7471575527883053,
      "grad_norm": 0.21844147145748138,
      "learning_rate": 7.89363176225848e-05,
      "loss": 0.046,
      "step": 1380
    },
    {
      "epoch": 0.752571737953438,
      "grad_norm": 0.07143494486808777,
      "learning_rate": 7.854964631519105e-05,
      "loss": 0.0087,
      "step": 1390
    },
    {
      "epoch": 0.7579859231185706,
      "grad_norm": 0.5895802974700928,
      "learning_rate": 7.816042480208183e-05,
      "loss": 0.0115,
      "step": 1400
    },
    {
      "epoch": 0.7634001082837033,
      "grad_norm": 2.6574838161468506,
      "learning_rate": 7.77686878505855e-05,
      "loss": 0.0187,
      "step": 1410
    },
    {
      "epoch": 0.7688142934488359,
      "grad_norm": 0.012055299244821072,
      "learning_rate": 7.737447045272266e-05,
      "loss": 0.0158,
      "step": 1420
    },
    {
      "epoch": 0.7742284786139686,
      "grad_norm": 2.04085373878479,
      "learning_rate": 7.697780782208056e-05,
      "loss": 0.0212,
      "step": 1430
    },
    {
      "epoch": 0.7796426637791013,
      "grad_norm": 0.3383457064628601,
      "learning_rate": 7.657873539066756e-05,
      "loss": 0.0073,
      "step": 1440
    },
    {
      "epoch": 0.7850568489442339,
      "grad_norm": 3.335899829864502,
      "learning_rate": 7.617728880574826e-05,
      "loss": 0.031,
      "step": 1450
    },
    {
      "epoch": 0.7904710341093666,
      "grad_norm": 0.19468721747398376,
      "learning_rate": 7.577350392665918e-05,
      "loss": 0.0076,
      "step": 1460
    },
    {
      "epoch": 0.7958852192744992,
      "grad_norm": 0.0053457473404705524,
      "learning_rate": 7.536741682160571e-05,
      "loss": 0.0054,
      "step": 1470
    },
    {
      "epoch": 0.8012994044396319,
      "grad_norm": 0.6662625074386597,
      "learning_rate": 7.495906376444022e-05,
      "loss": 0.018,
      "step": 1480
    },
    {
      "epoch": 0.8067135896047645,
      "grad_norm": 0.7977598905563354,
      "learning_rate": 7.454848123142197e-05,
      "loss": 0.0079,
      "step": 1490
    },
    {
      "epoch": 0.8121277747698972,
      "grad_norm": 1.777335286140442,
      "learning_rate": 7.41357058979588e-05,
      "loss": 0.0271,
      "step": 1500
    },
    {
      "epoch": 0.8175419599350298,
      "grad_norm": 0.9003738164901733,
      "learning_rate": 7.372077463533109e-05,
      "loss": 0.0113,
      "step": 1510
    },
    {
      "epoch": 0.8229561451001625,
      "grad_norm": 0.0036126982886344194,
      "learning_rate": 7.330372450739829e-05,
      "loss": 0.0183,
      "step": 1520
    },
    {
      "epoch": 0.828370330265295,
      "grad_norm": 1.8423842191696167,
      "learning_rate": 7.288459276728807e-05,
      "loss": 0.0535,
      "step": 1530
    },
    {
      "epoch": 0.8337845154304278,
      "grad_norm": 4.116658687591553,
      "learning_rate": 7.246341685406879e-05,
      "loss": 0.0428,
      "step": 1540
    },
    {
      "epoch": 0.8391987005955603,
      "grad_norm": 0.08053385466337204,
      "learning_rate": 7.204023438940511e-05,
      "loss": 0.0089,
      "step": 1550
    },
    {
      "epoch": 0.844612885760693,
      "grad_norm": 0.004629564005881548,
      "learning_rate": 7.161508317419759e-05,
      "loss": 0.0049,
      "step": 1560
    },
    {
      "epoch": 0.8500270709258256,
      "grad_norm": 0.005140126682817936,
      "learning_rate": 7.118800118520593e-05,
      "loss": 0.0065,
      "step": 1570
    },
    {
      "epoch": 0.8554412560909583,
      "grad_norm": 0.35412144660949707,
      "learning_rate": 7.075902657165687e-05,
      "loss": 0.018,
      "step": 1580
    },
    {
      "epoch": 0.8608554412560909,
      "grad_norm": 0.043654851615428925,
      "learning_rate": 7.032819765183634e-05,
      "loss": 0.0089,
      "step": 1590
    },
    {
      "epoch": 0.8662696264212236,
      "grad_norm": 0.04077580198645592,
      "learning_rate": 6.989555290966673e-05,
      "loss": 0.0049,
      "step": 1600
    },
    {
      "epoch": 0.8716838115863562,
      "grad_norm": 0.008583649061620235,
      "learning_rate": 6.946113099126938e-05,
      "loss": 0.0129,
      "step": 1610
    },
    {
      "epoch": 0.8770979967514889,
      "grad_norm": 0.07225753366947174,
      "learning_rate": 6.902497070151234e-05,
      "loss": 0.0031,
      "step": 1620
    },
    {
      "epoch": 0.8825121819166215,
      "grad_norm": 0.0026265212800353765,
      "learning_rate": 6.858711100054425e-05,
      "loss": 0.0232,
      "step": 1630
    },
    {
      "epoch": 0.8879263670817542,
      "grad_norm": 0.004113343078643084,
      "learning_rate": 6.814759100031414e-05,
      "loss": 0.0006,
      "step": 1640
    },
    {
      "epoch": 0.8933405522468868,
      "grad_norm": 0.006093104835599661,
      "learning_rate": 6.770644996107782e-05,
      "loss": 0.0166,
      "step": 1650
    },
    {
      "epoch": 0.8987547374120195,
      "grad_norm": 0.14034339785575867,
      "learning_rate": 6.726372728789082e-05,
      "loss": 0.0211,
      "step": 1660
    },
    {
      "epoch": 0.9041689225771521,
      "grad_norm": 0.014673382975161076,
      "learning_rate": 6.681946252708869e-05,
      "loss": 0.0127,
      "step": 1670
    },
    {
      "epoch": 0.9095831077422848,
      "grad_norm": 1.5227645635604858,
      "learning_rate": 6.637369536275431e-05,
      "loss": 0.0144,
      "step": 1680
    },
    {
      "epoch": 0.9149972929074174,
      "grad_norm": 0.2898022532463074,
      "learning_rate": 6.592646561317331e-05,
      "loss": 0.0144,
      "step": 1690
    },
    {
      "epoch": 0.9204114780725501,
      "grad_norm": 0.16000008583068848,
      "learning_rate": 6.54778132272771e-05,
      "loss": 0.0217,
      "step": 1700
    },
    {
      "epoch": 0.9258256632376828,
      "grad_norm": 0.07952141016721725,
      "learning_rate": 6.502777828107457e-05,
      "loss": 0.0078,
      "step": 1710
    },
    {
      "epoch": 0.9312398484028154,
      "grad_norm": 0.9451358318328857,
      "learning_rate": 6.45764009740722e-05,
      "loss": 0.0187,
      "step": 1720
    },
    {
      "epoch": 0.9366540335679481,
      "grad_norm": 0.2728198766708374,
      "learning_rate": 6.412372162568322e-05,
      "loss": 0.0144,
      "step": 1730
    },
    {
      "epoch": 0.9420682187330807,
      "grad_norm": 1.0453542470932007,
      "learning_rate": 6.366978067162614e-05,
      "loss": 0.0067,
      "step": 1740
    },
    {
      "epoch": 0.9474824038982134,
      "grad_norm": 0.2527516186237335,
      "learning_rate": 6.321461866031278e-05,
      "loss": 0.0139,
      "step": 1750
    },
    {
      "epoch": 0.952896589063346,
      "grad_norm": 0.56496661901474,
      "learning_rate": 6.275827624922621e-05,
      "loss": 0.0193,
      "step": 1760
    },
    {
      "epoch": 0.9583107742284787,
      "grad_norm": 0.005957538727670908,
      "learning_rate": 6.230079420128911e-05,
      "loss": 0.017,
      "step": 1770
    },
    {
      "epoch": 0.9637249593936112,
      "grad_norm": 0.5009787082672119,
      "learning_rate": 6.184221338122257e-05,
      "loss": 0.0345,
      "step": 1780
    },
    {
      "epoch": 0.969139144558744,
      "grad_norm": 0.3646543622016907,
      "learning_rate": 6.138257475189578e-05,
      "loss": 0.0162,
      "step": 1790
    },
    {
      "epoch": 0.9745533297238765,
      "grad_norm": 1.1433452367782593,
      "learning_rate": 6.092191937066712e-05,
      "loss": 0.0249,
      "step": 1800
    },
    {
      "epoch": 0.9799675148890092,
      "grad_norm": 0.005269546061754227,
      "learning_rate": 6.04602883857166e-05,
      "loss": 0.016,
      "step": 1810
    },
    {
      "epoch": 0.9853817000541418,
      "grad_norm": 0.027783077210187912,
      "learning_rate": 5.9997723032370346e-05,
      "loss": 0.018,
      "step": 1820
    },
    {
      "epoch": 0.9907958852192745,
      "grad_norm": 0.015877699479460716,
      "learning_rate": 5.953426462941718e-05,
      "loss": 0.0064,
      "step": 1830
    },
    {
      "epoch": 0.9962100703844071,
      "grad_norm": 0.7508984208106995,
      "learning_rate": 5.906995457541788e-05,
      "loss": 0.0288,
      "step": 1840
    },
    {
      "epoch": 1.0016242555495398,
      "grad_norm": 0.26469868421554565,
      "learning_rate": 5.8604834345007244e-05,
      "loss": 0.0105,
      "step": 1850
    },
    {
      "epoch": 1.0070384407146724,
      "grad_norm": 0.0750700905919075,
      "learning_rate": 5.8138945485189244e-05,
      "loss": 0.0046,
      "step": 1860
    },
    {
      "epoch": 1.012452625879805,
      "grad_norm": 1.693765640258789,
      "learning_rate": 5.767232961162596e-05,
      "loss": 0.0277,
      "step": 1870
    },
    {
      "epoch": 1.0178668110449378,
      "grad_norm": 0.018022233620285988,
      "learning_rate": 5.720502840492018e-05,
      "loss": 0.0121,
      "step": 1880
    },
    {
      "epoch": 1.0232809962100704,
      "grad_norm": 0.025364132598042488,
      "learning_rate": 5.673708360689226e-05,
      "loss": 0.0026,
      "step": 1890
    },
    {
      "epoch": 1.028695181375203,
      "grad_norm": 0.0128355473279953,
      "learning_rate": 5.6268537016851585e-05,
      "loss": 0.0073,
      "step": 1900
    },
    {
      "epoch": 1.0341093665403356,
      "grad_norm": 1.0056512355804443,
      "learning_rate": 5.579943048786275e-05,
      "loss": 0.0115,
      "step": 1910
    },
    {
      "epoch": 1.0395235517054684,
      "grad_norm": 0.02687026560306549,
      "learning_rate": 5.5329805923007094e-05,
      "loss": 0.0013,
      "step": 1920
    },
    {
      "epoch": 1.044937736870601,
      "grad_norm": 0.8745640516281128,
      "learning_rate": 5.485970527163963e-05,
      "loss": 0.0037,
      "step": 1930
    },
    {
      "epoch": 1.0503519220357336,
      "grad_norm": 0.13542549312114716,
      "learning_rate": 5.438917052564198e-05,
      "loss": 0.0029,
      "step": 1940
    },
    {
      "epoch": 1.0557661072008662,
      "grad_norm": 0.010415283963084221,
      "learning_rate": 5.391824371567137e-05,
      "loss": 0.0106,
      "step": 1950
    },
    {
      "epoch": 1.061180292365999,
      "grad_norm": 0.007145554292947054,
      "learning_rate": 5.344696690740628e-05,
      "loss": 0.0021,
      "step": 1960
    },
    {
      "epoch": 1.0665944775311316,
      "grad_norm": 0.3527683913707733,
      "learning_rate": 5.297538219778889e-05,
      "loss": 0.0022,
      "step": 1970
    },
    {
      "epoch": 1.0720086626962642,
      "grad_norm": 0.0030679586343467236,
      "learning_rate": 5.2503531711264755e-05,
      "loss": 0.0124,
      "step": 1980
    },
    {
      "epoch": 1.077422847861397,
      "grad_norm": 0.07452504336833954,
      "learning_rate": 5.203145759602002e-05,
      "loss": 0.001,
      "step": 1990
    },
    {
      "epoch": 1.0828370330265296,
      "grad_norm": 1.045310378074646,
      "learning_rate": 5.155920202021655e-05,
      "loss": 0.0053,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 3694,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.085783924248412e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
