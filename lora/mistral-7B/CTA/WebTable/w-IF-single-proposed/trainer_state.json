{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 735,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04081632653061224,
      "grad_norm": 44.02785873413086,
      "learning_rate": 1.3513513513513515e-05,
      "loss": 5.1333,
      "step": 10
    },
    {
      "epoch": 0.08163265306122448,
      "grad_norm": 9.310185432434082,
      "learning_rate": 2.702702702702703e-05,
      "loss": 1.5549,
      "step": 20
    },
    {
      "epoch": 0.12244897959183673,
      "grad_norm": 3.9996955394744873,
      "learning_rate": 4.0540540540540545e-05,
      "loss": 0.5463,
      "step": 30
    },
    {
      "epoch": 0.16326530612244897,
      "grad_norm": 2.7044897079467773,
      "learning_rate": 5.405405405405406e-05,
      "loss": 0.0634,
      "step": 40
    },
    {
      "epoch": 0.20408163265306123,
      "grad_norm": 8.412781715393066,
      "learning_rate": 6.756756756756757e-05,
      "loss": 0.0509,
      "step": 50
    },
    {
      "epoch": 0.24489795918367346,
      "grad_norm": 2.1106789112091064,
      "learning_rate": 8.108108108108109e-05,
      "loss": 0.0391,
      "step": 60
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 3.938859224319458,
      "learning_rate": 9.45945945945946e-05,
      "loss": 0.0401,
      "step": 70
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 0.759385347366333,
      "learning_rate": 9.997967128605077e-05,
      "loss": 0.043,
      "step": 80
    },
    {
      "epoch": 0.3673469387755102,
      "grad_norm": 1.3088032007217407,
      "learning_rate": 9.985550011399889e-05,
      "loss": 0.0381,
      "step": 90
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 0.6681814789772034,
      "learning_rate": 9.961873159705425e-05,
      "loss": 0.041,
      "step": 100
    },
    {
      "epoch": 0.4489795918367347,
      "grad_norm": 0.809893012046814,
      "learning_rate": 9.92699004707285e-05,
      "loss": 0.0217,
      "step": 110
    },
    {
      "epoch": 0.4897959183673469,
      "grad_norm": 0.4039226472377777,
      "learning_rate": 9.880979456100974e-05,
      "loss": 0.0188,
      "step": 120
    },
    {
      "epoch": 0.5306122448979592,
      "grad_norm": 1.099865436553955,
      "learning_rate": 9.823945300507816e-05,
      "loss": 0.0221,
      "step": 130
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.2452104538679123,
      "learning_rate": 9.756016390444173e-05,
      "loss": 0.0166,
      "step": 140
    },
    {
      "epoch": 0.6122448979591837,
      "grad_norm": 0.3389217257499695,
      "learning_rate": 9.677346141579277e-05,
      "loss": 0.011,
      "step": 150
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 0.6964383721351624,
      "learning_rate": 9.588112228615496e-05,
      "loss": 0.0229,
      "step": 160
    },
    {
      "epoch": 0.6938775510204082,
      "grad_norm": 0.15247783064842224,
      "learning_rate": 9.488516184014667e-05,
      "loss": 0.0181,
      "step": 170
    },
    {
      "epoch": 0.7346938775510204,
      "grad_norm": 0.608238697052002,
      "learning_rate": 9.378782942842292e-05,
      "loss": 0.0164,
      "step": 180
    },
    {
      "epoch": 0.7755102040816326,
      "grad_norm": 0.27250370383262634,
      "learning_rate": 9.259160334757574e-05,
      "loss": 0.0105,
      "step": 190
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 1.0124620199203491,
      "learning_rate": 9.129918524296594e-05,
      "loss": 0.0312,
      "step": 200
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 6.514912128448486,
      "learning_rate": 8.99134940071277e-05,
      "loss": 0.0189,
      "step": 210
    },
    {
      "epoch": 0.8979591836734694,
      "grad_norm": 0.40862327814102173,
      "learning_rate": 8.8437659187526e-05,
      "loss": 0.0203,
      "step": 220
    },
    {
      "epoch": 0.9387755102040817,
      "grad_norm": 1.0851341485977173,
      "learning_rate": 8.687501391855539e-05,
      "loss": 0.0183,
      "step": 230
    },
    {
      "epoch": 0.9795918367346939,
      "grad_norm": 0.09923844039440155,
      "learning_rate": 8.5229087393743e-05,
      "loss": 0.0116,
      "step": 240
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 1.1604199409484863,
      "learning_rate": 8.35035968951572e-05,
      "loss": 0.0199,
      "step": 250
    },
    {
      "epoch": 1.0612244897959184,
      "grad_norm": 0.04119187965989113,
      "learning_rate": 8.170243939802309e-05,
      "loss": 0.0026,
      "step": 260
    },
    {
      "epoch": 1.1020408163265305,
      "grad_norm": 0.06797995418310165,
      "learning_rate": 7.982968276950568e-05,
      "loss": 0.009,
      "step": 270
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 1.6776013374328613,
      "learning_rate": 7.788955658153829e-05,
      "loss": 0.0116,
      "step": 280
    },
    {
      "epoch": 1.183673469387755,
      "grad_norm": 0.08513222634792328,
      "learning_rate": 7.588644255844464e-05,
      "loss": 0.0159,
      "step": 290
    },
    {
      "epoch": 1.2244897959183674,
      "grad_norm": 0.06748264282941818,
      "learning_rate": 7.382486468092898e-05,
      "loss": 0.0125,
      "step": 300
    },
    {
      "epoch": 1.2653061224489797,
      "grad_norm": 0.7949643135070801,
      "learning_rate": 7.170947896878392e-05,
      "loss": 0.0064,
      "step": 310
    },
    {
      "epoch": 1.306122448979592,
      "grad_norm": 0.23286306858062744,
      "learning_rate": 6.954506296539112e-05,
      "loss": 0.0061,
      "step": 320
    },
    {
      "epoch": 1.346938775510204,
      "grad_norm": 0.015628360211849213,
      "learning_rate": 6.73365049477645e-05,
      "loss": 0.0174,
      "step": 330
    },
    {
      "epoch": 1.3877551020408163,
      "grad_norm": 0.7178647518157959,
      "learning_rate": 6.508879288650431e-05,
      "loss": 0.0072,
      "step": 340
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.8737956285476685,
      "learning_rate": 6.280700318059562e-05,
      "loss": 0.0018,
      "step": 350
    },
    {
      "epoch": 1.469387755102041,
      "grad_norm": 0.004116684664040804,
      "learning_rate": 6.049628919249399e-05,
      "loss": 0.0041,
      "step": 360
    },
    {
      "epoch": 1.510204081632653,
      "grad_norm": 0.7270804047584534,
      "learning_rate": 5.816186960939084e-05,
      "loss": 0.0117,
      "step": 370
    },
    {
      "epoch": 1.5510204081632653,
      "grad_norm": 0.009976300410926342,
      "learning_rate": 5.580901665694471e-05,
      "loss": 0.0052,
      "step": 380
    },
    {
      "epoch": 1.5918367346938775,
      "grad_norm": 0.5751399397850037,
      "learning_rate": 5.344304419209748e-05,
      "loss": 0.0238,
      "step": 390
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 0.02020726352930069,
      "learning_rate": 5.106929570186706e-05,
      "loss": 0.0092,
      "step": 400
    },
    {
      "epoch": 1.6734693877551021,
      "grad_norm": 0.20800678431987762,
      "learning_rate": 4.869313223522158e-05,
      "loss": 0.0097,
      "step": 410
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.0469423308968544,
      "learning_rate": 4.631992029529037e-05,
      "loss": 0.0025,
      "step": 420
    },
    {
      "epoch": 1.7551020408163265,
      "grad_norm": 0.7831787467002869,
      "learning_rate": 4.395501971925676e-05,
      "loss": 0.0091,
      "step": 430
    },
    {
      "epoch": 1.7959183673469388,
      "grad_norm": 0.3495224118232727,
      "learning_rate": 4.16037715733058e-05,
      "loss": 0.0163,
      "step": 440
    },
    {
      "epoch": 1.836734693877551,
      "grad_norm": 0.04339225962758064,
      "learning_rate": 3.9271486089965694e-05,
      "loss": 0.0052,
      "step": 450
    },
    {
      "epoch": 1.8775510204081631,
      "grad_norm": 0.07693063467741013,
      "learning_rate": 3.696343067508651e-05,
      "loss": 0.0022,
      "step": 460
    },
    {
      "epoch": 1.9183673469387754,
      "grad_norm": 0.06144203618168831,
      "learning_rate": 3.468481801154148e-05,
      "loss": 0.0045,
      "step": 470
    },
    {
      "epoch": 1.9591836734693877,
      "grad_norm": 0.04109908267855644,
      "learning_rate": 3.2440794286518896e-05,
      "loss": 0.0019,
      "step": 480
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.020661626011133194,
      "learning_rate": 3.0236427568992842e-05,
      "loss": 0.0081,
      "step": 490
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.01968221366405487,
      "learning_rate": 2.807669636362169e-05,
      "loss": 0.0005,
      "step": 500
    },
    {
      "epoch": 2.0816326530612246,
      "grad_norm": 0.14119543135166168,
      "learning_rate": 2.5966478366925406e-05,
      "loss": 0.0005,
      "step": 510
    },
    {
      "epoch": 2.122448979591837,
      "grad_norm": 0.019805369898676872,
      "learning_rate": 2.391053945113533e-05,
      "loss": 0.0032,
      "step": 520
    },
    {
      "epoch": 2.163265306122449,
      "grad_norm": 0.04890020191669464,
      "learning_rate": 2.191352290059621e-05,
      "loss": 0.001,
      "step": 530
    },
    {
      "epoch": 2.204081632653061,
      "grad_norm": 0.2724575996398926,
      "learning_rate": 1.9979938925029827e-05,
      "loss": 0.0007,
      "step": 540
    },
    {
      "epoch": 2.2448979591836733,
      "grad_norm": 0.13101248443126678,
      "learning_rate": 1.811415447334408e-05,
      "loss": 0.0003,
      "step": 550
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.0029788590036332607,
      "learning_rate": 1.632038337099297e-05,
      "loss": 0.0015,
      "step": 560
    },
    {
      "epoch": 2.326530612244898,
      "grad_norm": 0.030549928545951843,
      "learning_rate": 1.460267680316184e-05,
      "loss": 0.0077,
      "step": 570
    },
    {
      "epoch": 2.36734693877551,
      "grad_norm": 0.0707252025604248,
      "learning_rate": 1.296491416527147e-05,
      "loss": 0.0004,
      "step": 580
    },
    {
      "epoch": 2.4081632653061225,
      "grad_norm": 0.001838712370954454,
      "learning_rate": 1.1410794301464817e-05,
      "loss": 0.0003,
      "step": 590
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 0.006915987469255924,
      "learning_rate": 9.943827150864144e-06,
      "loss": 0.0003,
      "step": 600
    },
    {
      "epoch": 2.489795918367347,
      "grad_norm": 0.01157085970044136,
      "learning_rate": 8.567325820465156e-06,
      "loss": 0.0001,
      "step": 610
    },
    {
      "epoch": 2.5306122448979593,
      "grad_norm": 0.004167746752500534,
      "learning_rate": 7.28439910257141e-06,
      "loss": 0.0023,
      "step": 620
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.011171423830091953,
      "learning_rate": 6.097944453668081e-06,
      "loss": 0.0008,
      "step": 630
    },
    {
      "epoch": 2.612244897959184,
      "grad_norm": 0.015315547585487366,
      "learning_rate": 5.0106414505921575e-06,
      "loss": 0.0003,
      "step": 640
    },
    {
      "epoch": 2.6530612244897958,
      "grad_norm": 0.0040106214582920074,
      "learning_rate": 4.024945738778163e-06,
      "loss": 0.0012,
      "step": 650
    },
    {
      "epoch": 2.693877551020408,
      "grad_norm": 0.01318233460187912,
      "learning_rate": 3.1430834862470393e-06,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 2.7346938775510203,
      "grad_norm": 0.0016710498603060842,
      "learning_rate": 2.3670463558638555e-06,
      "loss": 0.0001,
      "step": 670
    },
    {
      "epoch": 2.7755102040816326,
      "grad_norm": 0.0016280915588140488,
      "learning_rate": 1.6985870072192156e-06,
      "loss": 0.0001,
      "step": 680
    },
    {
      "epoch": 2.816326530612245,
      "grad_norm": 0.005317701492458582,
      "learning_rate": 1.1392151382933647e-06,
      "loss": 0.0002,
      "step": 690
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.37126225233078003,
      "learning_rate": 6.901940758427206e-07,
      "loss": 0.0009,
      "step": 700
    },
    {
      "epoch": 2.8979591836734695,
      "grad_norm": 1.330736756324768,
      "learning_rate": 3.5253792220940606e-07,
      "loss": 0.0013,
      "step": 710
    },
    {
      "epoch": 2.938775510204082,
      "grad_norm": 0.0027163871563971043,
      "learning_rate": 1.2700926499756293e-07,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 2.979591836734694,
      "grad_norm": 0.0028811718802899122,
      "learning_rate": 1.4117454789208672e-08,
      "loss": 0.0009,
      "step": 730
    },
    {
      "epoch": 3.0,
      "step": 735,
      "total_flos": 5.20837670771884e+17,
      "train_loss": 0.10961826110328389,
      "train_runtime": 1624.5517,
      "train_samples_per_second": 7.217,
      "train_steps_per_second": 0.452
    }
  ],
  "logging_steps": 10,
  "max_steps": 735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.20837670771884e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
