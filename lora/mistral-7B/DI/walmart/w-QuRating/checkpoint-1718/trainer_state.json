{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1718,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011641443538998836,
      "grad_norm": 80.63081359863281,
      "learning_rate": 5.232558139534884e-06,
      "loss": 5.4856,
      "step": 10
    },
    {
      "epoch": 0.023282887077997673,
      "grad_norm": 25.55644989013672,
      "learning_rate": 1.1046511627906977e-05,
      "loss": 2.5168,
      "step": 20
    },
    {
      "epoch": 0.034924330616996506,
      "grad_norm": 1.1852247714996338,
      "learning_rate": 1.686046511627907e-05,
      "loss": 0.333,
      "step": 30
    },
    {
      "epoch": 0.046565774155995346,
      "grad_norm": 11.452202796936035,
      "learning_rate": 2.2674418604651163e-05,
      "loss": 0.1052,
      "step": 40
    },
    {
      "epoch": 0.05820721769499418,
      "grad_norm": 13.272262573242188,
      "learning_rate": 2.848837209302326e-05,
      "loss": 0.0947,
      "step": 50
    },
    {
      "epoch": 0.06984866123399301,
      "grad_norm": 5.838610649108887,
      "learning_rate": 3.430232558139535e-05,
      "loss": 0.0612,
      "step": 60
    },
    {
      "epoch": 0.08149010477299184,
      "grad_norm": 2.695420503616333,
      "learning_rate": 4.0116279069767444e-05,
      "loss": 0.075,
      "step": 70
    },
    {
      "epoch": 0.09313154831199069,
      "grad_norm": 1.0843267440795898,
      "learning_rate": 4.593023255813954e-05,
      "loss": 0.0427,
      "step": 80
    },
    {
      "epoch": 0.10477299185098952,
      "grad_norm": 1.209168791770935,
      "learning_rate": 5.1744186046511636e-05,
      "loss": 0.0751,
      "step": 90
    },
    {
      "epoch": 0.11641443538998836,
      "grad_norm": 0.5474321246147156,
      "learning_rate": 5.755813953488373e-05,
      "loss": 0.0479,
      "step": 100
    },
    {
      "epoch": 0.1280558789289872,
      "grad_norm": 4.031466007232666,
      "learning_rate": 6.337209302325582e-05,
      "loss": 0.0477,
      "step": 110
    },
    {
      "epoch": 0.13969732246798602,
      "grad_norm": 4.7198262214660645,
      "learning_rate": 6.918604651162791e-05,
      "loss": 0.038,
      "step": 120
    },
    {
      "epoch": 0.15133876600698487,
      "grad_norm": 3.044062376022339,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.0852,
      "step": 130
    },
    {
      "epoch": 0.1629802095459837,
      "grad_norm": 1.3760777711868286,
      "learning_rate": 8.081395348837209e-05,
      "loss": 0.056,
      "step": 140
    },
    {
      "epoch": 0.17462165308498254,
      "grad_norm": 0.9745791554450989,
      "learning_rate": 8.662790697674419e-05,
      "loss": 0.0611,
      "step": 150
    },
    {
      "epoch": 0.18626309662398138,
      "grad_norm": 0.818501889705658,
      "learning_rate": 9.244186046511628e-05,
      "loss": 0.0309,
      "step": 160
    },
    {
      "epoch": 0.1979045401629802,
      "grad_norm": 0.9978060722351074,
      "learning_rate": 9.825581395348838e-05,
      "loss": 0.0938,
      "step": 170
    },
    {
      "epoch": 0.20954598370197905,
      "grad_norm": 4.813770294189453,
      "learning_rate": 9.999494164235837e-05,
      "loss": 0.0717,
      "step": 180
    },
    {
      "epoch": 0.22118742724097787,
      "grad_norm": 1.4338412284851074,
      "learning_rate": 9.997016847691437e-05,
      "loss": 0.0457,
      "step": 190
    },
    {
      "epoch": 0.23282887077997672,
      "grad_norm": 0.9828733801841736,
      "learning_rate": 9.992476163411523e-05,
      "loss": 0.0273,
      "step": 200
    },
    {
      "epoch": 0.24447031431897556,
      "grad_norm": 1.6946580410003662,
      "learning_rate": 9.985873986335033e-05,
      "loss": 0.0527,
      "step": 210
    },
    {
      "epoch": 0.2561117578579744,
      "grad_norm": 1.7354215383529663,
      "learning_rate": 9.977213042632312e-05,
      "loss": 0.0453,
      "step": 220
    },
    {
      "epoch": 0.26775320139697323,
      "grad_norm": 1.3678512573242188,
      "learning_rate": 9.966496908579437e-05,
      "loss": 0.0887,
      "step": 230
    },
    {
      "epoch": 0.27939464493597205,
      "grad_norm": 1.2493021488189697,
      "learning_rate": 9.95373000908149e-05,
      "loss": 0.0455,
      "step": 240
    },
    {
      "epoch": 0.2910360884749709,
      "grad_norm": 0.866474986076355,
      "learning_rate": 9.938917615845434e-05,
      "loss": 0.0476,
      "step": 250
    },
    {
      "epoch": 0.30267753201396974,
      "grad_norm": 0.2826874554157257,
      "learning_rate": 9.922065845203316e-05,
      "loss": 0.0852,
      "step": 260
    },
    {
      "epoch": 0.31431897555296856,
      "grad_norm": 0.0928569808602333,
      "learning_rate": 9.903181655586717e-05,
      "loss": 0.0376,
      "step": 270
    },
    {
      "epoch": 0.3259604190919674,
      "grad_norm": 0.49904853105545044,
      "learning_rate": 9.882272844653468e-05,
      "loss": 0.0283,
      "step": 280
    },
    {
      "epoch": 0.33760186263096625,
      "grad_norm": 1.9504700899124146,
      "learning_rate": 9.859348046067851e-05,
      "loss": 0.0638,
      "step": 290
    },
    {
      "epoch": 0.3492433061699651,
      "grad_norm": 1.212996482849121,
      "learning_rate": 9.83441672593558e-05,
      "loss": 0.0591,
      "step": 300
    },
    {
      "epoch": 0.3608847497089639,
      "grad_norm": 0.39755338430404663,
      "learning_rate": 9.807489178895064e-05,
      "loss": 0.0404,
      "step": 310
    },
    {
      "epoch": 0.37252619324796277,
      "grad_norm": 1.1401013135910034,
      "learning_rate": 9.778576523866542e-05,
      "loss": 0.0695,
      "step": 320
    },
    {
      "epoch": 0.3841676367869616,
      "grad_norm": 0.09216223657131195,
      "learning_rate": 9.747690699460858e-05,
      "loss": 0.0322,
      "step": 330
    },
    {
      "epoch": 0.3958090803259604,
      "grad_norm": 0.02409212850034237,
      "learning_rate": 9.714844459049777e-05,
      "loss": 0.0363,
      "step": 340
    },
    {
      "epoch": 0.4074505238649593,
      "grad_norm": 0.3683124780654907,
      "learning_rate": 9.680051365499856e-05,
      "loss": 0.0345,
      "step": 350
    },
    {
      "epoch": 0.4190919674039581,
      "grad_norm": 0.568727433681488,
      "learning_rate": 9.643325785572073e-05,
      "loss": 0.0476,
      "step": 360
    },
    {
      "epoch": 0.4307334109429569,
      "grad_norm": 0.39043912291526794,
      "learning_rate": 9.604682883989501e-05,
      "loss": 0.0292,
      "step": 370
    },
    {
      "epoch": 0.44237485448195574,
      "grad_norm": 3.873581886291504,
      "learning_rate": 9.564138617175495e-05,
      "loss": 0.0547,
      "step": 380
    },
    {
      "epoch": 0.4540162980209546,
      "grad_norm": 1.5251116752624512,
      "learning_rate": 9.521709726664967e-05,
      "loss": 0.0806,
      "step": 390
    },
    {
      "epoch": 0.46565774155995343,
      "grad_norm": 1.3904556035995483,
      "learning_rate": 9.477413732191467e-05,
      "loss": 0.0531,
      "step": 400
    },
    {
      "epoch": 0.47729918509895225,
      "grad_norm": 2.964005470275879,
      "learning_rate": 9.43126892445295e-05,
      "loss": 0.0628,
      "step": 410
    },
    {
      "epoch": 0.4889406286379511,
      "grad_norm": 0.18436652421951294,
      "learning_rate": 9.383294357559162e-05,
      "loss": 0.0383,
      "step": 420
    },
    {
      "epoch": 0.5005820721769499,
      "grad_norm": 1.7244259119033813,
      "learning_rate": 9.33350984116384e-05,
      "loss": 0.0335,
      "step": 430
    },
    {
      "epoch": 0.5122235157159488,
      "grad_norm": 0.011705826036632061,
      "learning_rate": 9.281935932284898e-05,
      "loss": 0.0232,
      "step": 440
    },
    {
      "epoch": 0.5238649592549476,
      "grad_norm": 0.007300643716007471,
      "learning_rate": 9.22859392681603e-05,
      "loss": 0.0195,
      "step": 450
    },
    {
      "epoch": 0.5355064027939465,
      "grad_norm": 0.03753940761089325,
      "learning_rate": 9.173505850733208e-05,
      "loss": 0.0249,
      "step": 460
    },
    {
      "epoch": 0.5471478463329453,
      "grad_norm": 0.5762289762496948,
      "learning_rate": 9.116694450999729e-05,
      "loss": 0.0385,
      "step": 470
    },
    {
      "epoch": 0.5587892898719441,
      "grad_norm": 1.8507986068725586,
      "learning_rate": 9.058183186173522e-05,
      "loss": 0.0492,
      "step": 480
    },
    {
      "epoch": 0.570430733410943,
      "grad_norm": 0.3273333013057709,
      "learning_rate": 8.997996216720661e-05,
      "loss": 0.0537,
      "step": 490
    },
    {
      "epoch": 0.5820721769499418,
      "grad_norm": 0.7019246220588684,
      "learning_rate": 8.936158395039017e-05,
      "loss": 0.0716,
      "step": 500
    },
    {
      "epoch": 0.5937136204889406,
      "grad_norm": 1.0783511400222778,
      "learning_rate": 8.872695255196209e-05,
      "loss": 0.026,
      "step": 510
    },
    {
      "epoch": 0.6053550640279395,
      "grad_norm": 2.3840553760528564,
      "learning_rate": 8.807633002386086e-05,
      "loss": 0.0272,
      "step": 520
    },
    {
      "epoch": 0.6169965075669382,
      "grad_norm": 0.7279425859451294,
      "learning_rate": 8.740998502108071e-05,
      "loss": 0.0396,
      "step": 530
    },
    {
      "epoch": 0.6286379511059371,
      "grad_norm": 1.9127202033996582,
      "learning_rate": 8.672819269073866e-05,
      "loss": 0.0397,
      "step": 540
    },
    {
      "epoch": 0.640279394644936,
      "grad_norm": 3.5827760696411133,
      "learning_rate": 8.603123455846089e-05,
      "loss": 0.0472,
      "step": 550
    },
    {
      "epoch": 0.6519208381839348,
      "grad_norm": 0.34991928935050964,
      "learning_rate": 8.531939841213499e-05,
      "loss": 0.0186,
      "step": 560
    },
    {
      "epoch": 0.6635622817229336,
      "grad_norm": 1.888492465019226,
      "learning_rate": 8.459297818307681e-05,
      "loss": 0.0572,
      "step": 570
    },
    {
      "epoch": 0.6752037252619325,
      "grad_norm": 1.0297880172729492,
      "learning_rate": 8.385227382466029e-05,
      "loss": 0.0648,
      "step": 580
    },
    {
      "epoch": 0.6868451688009313,
      "grad_norm": 1.0209201574325562,
      "learning_rate": 8.309759118846074e-05,
      "loss": 0.0413,
      "step": 590
    },
    {
      "epoch": 0.6984866123399301,
      "grad_norm": 0.6794229745864868,
      "learning_rate": 8.232924189796264e-05,
      "loss": 0.0408,
      "step": 600
    },
    {
      "epoch": 0.710128055878929,
      "grad_norm": 1.7567877769470215,
      "learning_rate": 8.15475432198841e-05,
      "loss": 0.028,
      "step": 610
    },
    {
      "epoch": 0.7217694994179278,
      "grad_norm": 0.028361083939671516,
      "learning_rate": 8.07528179331711e-05,
      "loss": 0.0404,
      "step": 620
    },
    {
      "epoch": 0.7334109429569267,
      "grad_norm": 0.3290628492832184,
      "learning_rate": 7.994539419571572e-05,
      "loss": 0.0215,
      "step": 630
    },
    {
      "epoch": 0.7450523864959255,
      "grad_norm": 1.1642632484436035,
      "learning_rate": 7.912560540885308e-05,
      "loss": 0.0161,
      "step": 640
    },
    {
      "epoch": 0.7566938300349243,
      "grad_norm": 0.778558075428009,
      "learning_rate": 7.829379007969336e-05,
      "loss": 0.033,
      "step": 650
    },
    {
      "epoch": 0.7683352735739232,
      "grad_norm": 0.6316184997558594,
      "learning_rate": 7.745029168134554e-05,
      "loss": 0.0426,
      "step": 660
    },
    {
      "epoch": 0.779976717112922,
      "grad_norm": 1.7147645950317383,
      "learning_rate": 7.659545851109035e-05,
      "loss": 0.0363,
      "step": 670
    },
    {
      "epoch": 0.7916181606519208,
      "grad_norm": 0.2154669165611267,
      "learning_rate": 7.572964354656161e-05,
      "loss": 0.0185,
      "step": 680
    },
    {
      "epoch": 0.8032596041909197,
      "grad_norm": 0.01699378713965416,
      "learning_rate": 7.485320429999453e-05,
      "loss": 0.0543,
      "step": 690
    },
    {
      "epoch": 0.8149010477299186,
      "grad_norm": 0.8464850187301636,
      "learning_rate": 7.39665026706019e-05,
      "loss": 0.0324,
      "step": 700
    },
    {
      "epoch": 0.8265424912689173,
      "grad_norm": 0.09484400600194931,
      "learning_rate": 7.30699047951387e-05,
      "loss": 0.026,
      "step": 710
    },
    {
      "epoch": 0.8381839348079162,
      "grad_norm": 0.033315837383270264,
      "learning_rate": 7.21637808967169e-05,
      "loss": 0.0244,
      "step": 720
    },
    {
      "epoch": 0.8498253783469151,
      "grad_norm": 0.03870254009962082,
      "learning_rate": 7.124850513193298e-05,
      "loss": 0.0322,
      "step": 730
    },
    {
      "epoch": 0.8614668218859138,
      "grad_norm": 1.900525450706482,
      "learning_rate": 7.032445543637127e-05,
      "loss": 0.0183,
      "step": 740
    },
    {
      "epoch": 0.8731082654249127,
      "grad_norm": 0.15910714864730835,
      "learning_rate": 6.939201336854679e-05,
      "loss": 0.0233,
      "step": 750
    },
    {
      "epoch": 0.8847497089639115,
      "grad_norm": 0.8625436425209045,
      "learning_rate": 6.845156395235209e-05,
      "loss": 0.0541,
      "step": 760
    },
    {
      "epoch": 0.8963911525029103,
      "grad_norm": 1.0398715734481812,
      "learning_rate": 6.750349551807332e-05,
      "loss": 0.02,
      "step": 770
    },
    {
      "epoch": 0.9080325960419092,
      "grad_norm": 0.7509053349494934,
      "learning_rate": 6.654819954204081e-05,
      "loss": 0.0185,
      "step": 780
    },
    {
      "epoch": 0.919674039580908,
      "grad_norm": 1.9233368635177612,
      "learning_rate": 6.558607048498085e-05,
      "loss": 0.0288,
      "step": 790
    },
    {
      "epoch": 0.9313154831199069,
      "grad_norm": 0.27315205335617065,
      "learning_rate": 6.461750562913488e-05,
      "loss": 0.0139,
      "step": 800
    },
    {
      "epoch": 0.9429569266589057,
      "grad_norm": 0.025472773239016533,
      "learning_rate": 6.364290491421375e-05,
      "loss": 0.0272,
      "step": 810
    },
    {
      "epoch": 0.9545983701979045,
      "grad_norm": 0.7400341033935547,
      "learning_rate": 6.266267077225471e-05,
      "loss": 0.0518,
      "step": 820
    },
    {
      "epoch": 0.9662398137369034,
      "grad_norm": 0.6447116732597351,
      "learning_rate": 6.16772079614492e-05,
      "loss": 0.0227,
      "step": 830
    },
    {
      "epoch": 0.9778812572759022,
      "grad_norm": 0.1354592889547348,
      "learning_rate": 6.068692339901006e-05,
      "loss": 0.0181,
      "step": 840
    },
    {
      "epoch": 0.989522700814901,
      "grad_norm": 0.09338360279798508,
      "learning_rate": 5.9692225993147444e-05,
      "loss": 0.0333,
      "step": 850
    },
    {
      "epoch": 1.0011641443538999,
      "grad_norm": 0.005089069716632366,
      "learning_rate": 5.869352647422235e-05,
      "loss": 0.0158,
      "step": 860
    },
    {
      "epoch": 1.0128055878928988,
      "grad_norm": 0.5453640222549438,
      "learning_rate": 5.769123722514795e-05,
      "loss": 0.019,
      "step": 870
    },
    {
      "epoch": 1.0244470314318976,
      "grad_norm": 0.19937574863433838,
      "learning_rate": 5.668577211110848e-05,
      "loss": 0.0073,
      "step": 880
    },
    {
      "epoch": 1.0360884749708963,
      "grad_norm": 1.0532867908477783,
      "learning_rate": 5.5677546308665985e-05,
      "loss": 0.007,
      "step": 890
    },
    {
      "epoch": 1.0477299185098952,
      "grad_norm": 0.05295218899846077,
      "learning_rate": 5.4666976134325776e-05,
      "loss": 0.0137,
      "step": 900
    },
    {
      "epoch": 1.059371362048894,
      "grad_norm": 0.13614201545715332,
      "learning_rate": 5.365447887263093e-05,
      "loss": 0.0029,
      "step": 910
    },
    {
      "epoch": 1.071012805587893,
      "grad_norm": 0.597905158996582,
      "learning_rate": 5.264047260385734e-05,
      "loss": 0.0064,
      "step": 920
    },
    {
      "epoch": 1.0826542491268918,
      "grad_norm": 0.5613531470298767,
      "learning_rate": 5.162537603137989e-05,
      "loss": 0.04,
      "step": 930
    },
    {
      "epoch": 1.0942956926658907,
      "grad_norm": 0.025521976873278618,
      "learning_rate": 5.060960830878158e-05,
      "loss": 0.0027,
      "step": 940
    },
    {
      "epoch": 1.1059371362048893,
      "grad_norm": 0.13637548685073853,
      "learning_rate": 4.959358886677667e-05,
      "loss": 0.0233,
      "step": 950
    },
    {
      "epoch": 1.1175785797438882,
      "grad_norm": 1.0531283617019653,
      "learning_rate": 4.857773724001939e-05,
      "loss": 0.0153,
      "step": 960
    },
    {
      "epoch": 1.129220023282887,
      "grad_norm": 0.12516933679580688,
      "learning_rate": 4.756247289386967e-05,
      "loss": 0.0059,
      "step": 970
    },
    {
      "epoch": 1.140861466821886,
      "grad_norm": 0.5930761098861694,
      "learning_rate": 4.654821505118764e-05,
      "loss": 0.0099,
      "step": 980
    },
    {
      "epoch": 1.1525029103608848,
      "grad_norm": 0.6762140393257141,
      "learning_rate": 4.5535382519228034e-05,
      "loss": 0.0149,
      "step": 990
    },
    {
      "epoch": 1.1641443538998835,
      "grad_norm": 1.1446669101715088,
      "learning_rate": 4.452439351670653e-05,
      "loss": 0.0062,
      "step": 1000
    },
    {
      "epoch": 1.1757857974388823,
      "grad_norm": 0.5518869757652283,
      "learning_rate": 4.351566550110868e-05,
      "loss": 0.0151,
      "step": 1010
    },
    {
      "epoch": 1.1874272409778812,
      "grad_norm": 0.02259141020476818,
      "learning_rate": 4.2509614996313595e-05,
      "loss": 0.0116,
      "step": 1020
    },
    {
      "epoch": 1.19906868451688,
      "grad_norm": 0.008717171847820282,
      "learning_rate": 4.150665742060286e-05,
      "loss": 0.019,
      "step": 1030
    },
    {
      "epoch": 1.210710128055879,
      "grad_norm": 0.8335132598876953,
      "learning_rate": 4.050720691512603e-05,
      "loss": 0.0189,
      "step": 1040
    },
    {
      "epoch": 1.2223515715948778,
      "grad_norm": 0.9712436199188232,
      "learning_rate": 3.951167617289361e-05,
      "loss": 0.0211,
      "step": 1050
    },
    {
      "epoch": 1.2339930151338767,
      "grad_norm": 0.055094096809625626,
      "learning_rate": 3.85204762683678e-05,
      "loss": 0.0092,
      "step": 1060
    },
    {
      "epoch": 1.2456344586728754,
      "grad_norm": 0.20145510137081146,
      "learning_rate": 3.753401648772166e-05,
      "loss": 0.0101,
      "step": 1070
    },
    {
      "epoch": 1.2572759022118742,
      "grad_norm": 1.3698475360870361,
      "learning_rate": 3.655270415983675e-05,
      "loss": 0.0069,
      "step": 1080
    },
    {
      "epoch": 1.2689173457508731,
      "grad_norm": 1.7429356575012207,
      "learning_rate": 3.5576944488108945e-05,
      "loss": 0.0403,
      "step": 1090
    },
    {
      "epoch": 1.280558789289872,
      "grad_norm": 0.05096098408102989,
      "learning_rate": 3.460714038313184e-05,
      "loss": 0.0071,
      "step": 1100
    },
    {
      "epoch": 1.2922002328288706,
      "grad_norm": 0.13572855293750763,
      "learning_rate": 3.3643692296326944e-05,
      "loss": 0.0149,
      "step": 1110
    },
    {
      "epoch": 1.3038416763678695,
      "grad_norm": 0.12968969345092773,
      "learning_rate": 3.268699805458932e-05,
      "loss": 0.0204,
      "step": 1120
    },
    {
      "epoch": 1.3154831199068684,
      "grad_norm": 0.092732734978199,
      "learning_rate": 3.1737452696016935e-05,
      "loss": 0.0064,
      "step": 1130
    },
    {
      "epoch": 1.3271245634458673,
      "grad_norm": 0.11918128281831741,
      "learning_rate": 3.0795448306791665e-05,
      "loss": 0.0044,
      "step": 1140
    },
    {
      "epoch": 1.3387660069848661,
      "grad_norm": 0.7768703699111938,
      "learning_rate": 2.9861373859278907e-05,
      "loss": 0.0062,
      "step": 1150
    },
    {
      "epoch": 1.350407450523865,
      "grad_norm": 0.03201400116086006,
      "learning_rate": 2.893561505141335e-05,
      "loss": 0.0087,
      "step": 1160
    },
    {
      "epoch": 1.362048894062864,
      "grad_norm": 0.14187747240066528,
      "learning_rate": 2.801855414743646e-05,
      "loss": 0.0037,
      "step": 1170
    },
    {
      "epoch": 1.3736903376018628,
      "grad_norm": 0.10285942256450653,
      "learning_rate": 2.7110569820052067e-05,
      "loss": 0.0149,
      "step": 1180
    },
    {
      "epoch": 1.3853317811408614,
      "grad_norm": 1.5381436347961426,
      "learning_rate": 2.6212036994064837e-05,
      "loss": 0.0144,
      "step": 1190
    },
    {
      "epoch": 1.3969732246798603,
      "grad_norm": 1.1929600238800049,
      "learning_rate": 2.532332669156634e-05,
      "loss": 0.0211,
      "step": 1200
    },
    {
      "epoch": 1.4086146682188592,
      "grad_norm": 0.3858569264411926,
      "learning_rate": 2.4444805878732614e-05,
      "loss": 0.0061,
      "step": 1210
    },
    {
      "epoch": 1.420256111757858,
      "grad_norm": 0.036048781126737595,
      "learning_rate": 2.3576837314296673e-05,
      "loss": 0.0134,
      "step": 1220
    },
    {
      "epoch": 1.4318975552968567,
      "grad_norm": 1.5576518774032593,
      "learning_rate": 2.2719779399757973e-05,
      "loss": 0.0129,
      "step": 1230
    },
    {
      "epoch": 1.4435389988358556,
      "grad_norm": 0.006263007875531912,
      "learning_rate": 2.1873986031391498e-05,
      "loss": 0.0087,
      "step": 1240
    },
    {
      "epoch": 1.4551804423748544,
      "grad_norm": 0.029816865921020508,
      "learning_rate": 2.1039806454116855e-05,
      "loss": 0.0063,
      "step": 1250
    },
    {
      "epoch": 1.4668218859138533,
      "grad_norm": 0.8483845591545105,
      "learning_rate": 2.0217585117288053e-05,
      "loss": 0.0083,
      "step": 1260
    },
    {
      "epoch": 1.4784633294528522,
      "grad_norm": 0.046862997114658356,
      "learning_rate": 1.940766153246366e-05,
      "loss": 0.0076,
      "step": 1270
    },
    {
      "epoch": 1.490104772991851,
      "grad_norm": 0.017893768846988678,
      "learning_rate": 1.8610370133215526e-05,
      "loss": 0.0032,
      "step": 1280
    },
    {
      "epoch": 1.50174621653085,
      "grad_norm": 0.7399126887321472,
      "learning_rate": 1.7826040137034645e-05,
      "loss": 0.01,
      "step": 1290
    },
    {
      "epoch": 1.5133876600698488,
      "grad_norm": 0.0038857453037053347,
      "learning_rate": 1.7054995409390646e-05,
      "loss": 0.0041,
      "step": 1300
    },
    {
      "epoch": 1.5250291036088475,
      "grad_norm": 1.023985505104065,
      "learning_rate": 1.6297554330001297e-05,
      "loss": 0.0132,
      "step": 1310
    },
    {
      "epoch": 1.5366705471478463,
      "grad_norm": 0.007064896170049906,
      "learning_rate": 1.5554029661367208e-05,
      "loss": 0.0068,
      "step": 1320
    },
    {
      "epoch": 1.5483119906868452,
      "grad_norm": 0.014088965952396393,
      "learning_rate": 1.4824728419625882e-05,
      "loss": 0.0086,
      "step": 1330
    },
    {
      "epoch": 1.5599534342258439,
      "grad_norm": 0.05195337533950806,
      "learning_rate": 1.4109951747778766e-05,
      "loss": 0.0139,
      "step": 1340
    },
    {
      "epoch": 1.5715948777648427,
      "grad_norm": 0.14869637787342072,
      "learning_rate": 1.3409994791343217e-05,
      "loss": 0.0059,
      "step": 1350
    },
    {
      "epoch": 1.5832363213038416,
      "grad_norm": 0.03284448757767677,
      "learning_rate": 1.2725146576481083e-05,
      "loss": 0.0032,
      "step": 1360
    },
    {
      "epoch": 1.5948777648428405,
      "grad_norm": 0.029336705803871155,
      "learning_rate": 1.2055689890654043e-05,
      "loss": 0.0104,
      "step": 1370
    },
    {
      "epoch": 1.6065192083818394,
      "grad_norm": 0.09889902174472809,
      "learning_rate": 1.1401901165854988e-05,
      "loss": 0.0045,
      "step": 1380
    },
    {
      "epoch": 1.6181606519208382,
      "grad_norm": 0.24068127572536469,
      "learning_rate": 1.076405036446384e-05,
      "loss": 0.0052,
      "step": 1390
    },
    {
      "epoch": 1.6298020954598371,
      "grad_norm": 0.4020506739616394,
      "learning_rate": 1.0142400867774615e-05,
      "loss": 0.0063,
      "step": 1400
    },
    {
      "epoch": 1.641443538998836,
      "grad_norm": 1.0736106634140015,
      "learning_rate": 9.537209367240123e-06,
      "loss": 0.0093,
      "step": 1410
    },
    {
      "epoch": 1.6530849825378346,
      "grad_norm": 0.0041382876224815845,
      "learning_rate": 8.94872575847891e-06,
      "loss": 0.0025,
      "step": 1420
    },
    {
      "epoch": 1.6647264260768335,
      "grad_norm": 0.011660872027277946,
      "learning_rate": 8.377193038088365e-06,
      "loss": 0.0049,
      "step": 1430
    },
    {
      "epoch": 1.6763678696158324,
      "grad_norm": 0.052247270941734314,
      "learning_rate": 7.822847203306643e-06,
      "loss": 0.0015,
      "step": 1440
    },
    {
      "epoch": 1.688009313154831,
      "grad_norm": 0.008161068893969059,
      "learning_rate": 7.285917154564681e-06,
      "loss": 0.0033,
      "step": 1450
    },
    {
      "epoch": 1.69965075669383,
      "grad_norm": 0.06334782391786575,
      "learning_rate": 6.766624600968658e-06,
      "loss": 0.0093,
      "step": 1460
    },
    {
      "epoch": 1.7112922002328288,
      "grad_norm": 0.4013904929161072,
      "learning_rate": 6.265183968751848e-06,
      "loss": 0.0074,
      "step": 1470
    },
    {
      "epoch": 1.7229336437718277,
      "grad_norm": 0.005526825785636902,
      "learning_rate": 5.7818023127338196e-06,
      "loss": 0.0033,
      "step": 1480
    },
    {
      "epoch": 1.7345750873108265,
      "grad_norm": 0.012108388356864452,
      "learning_rate": 5.316679230823396e-06,
      "loss": 0.0005,
      "step": 1490
    },
    {
      "epoch": 1.7462165308498254,
      "grad_norm": 0.023240400478243828,
      "learning_rate": 4.870006781600589e-06,
      "loss": 0.005,
      "step": 1500
    },
    {
      "epoch": 1.7578579743888243,
      "grad_norm": 0.01378738135099411,
      "learning_rate": 4.441969405011931e-06,
      "loss": 0.0008,
      "step": 1510
    },
    {
      "epoch": 1.7694994179278232,
      "grad_norm": 0.31699246168136597,
      "learning_rate": 4.032743846211428e-06,
      "loss": 0.0102,
      "step": 1520
    },
    {
      "epoch": 1.781140861466822,
      "grad_norm": 0.010582235641777515,
      "learning_rate": 3.6424990825790594e-06,
      "loss": 0.0016,
      "step": 1530
    },
    {
      "epoch": 1.7927823050058207,
      "grad_norm": 0.018806617707014084,
      "learning_rate": 3.271396253946607e-06,
      "loss": 0.0034,
      "step": 1540
    },
    {
      "epoch": 1.8044237485448196,
      "grad_norm": 0.1408696472644806,
      "learning_rate": 2.9195885960598133e-06,
      "loss": 0.0094,
      "step": 1550
    },
    {
      "epoch": 1.8160651920838184,
      "grad_norm": 0.005669817328453064,
      "learning_rate": 2.5872213773043054e-06,
      "loss": 0.003,
      "step": 1560
    },
    {
      "epoch": 1.827706635622817,
      "grad_norm": 0.07752303034067154,
      "learning_rate": 2.274431838721358e-06,
      "loss": 0.0022,
      "step": 1570
    },
    {
      "epoch": 1.839348079161816,
      "grad_norm": 0.06756936013698578,
      "learning_rate": 1.9813491373383895e-06,
      "loss": 0.0025,
      "step": 1580
    },
    {
      "epoch": 1.8509895227008148,
      "grad_norm": 0.10754489153623581,
      "learning_rate": 1.7080942928373923e-06,
      "loss": 0.0033,
      "step": 1590
    },
    {
      "epoch": 1.8626309662398137,
      "grad_norm": 0.08750997483730316,
      "learning_rate": 1.454780137583539e-06,
      "loss": 0.0039,
      "step": 1600
    },
    {
      "epoch": 1.8742724097788126,
      "grad_norm": 0.5935863852500916,
      "learning_rate": 1.2215112700344421e-06,
      "loss": 0.0044,
      "step": 1610
    },
    {
      "epoch": 1.8859138533178115,
      "grad_norm": 0.0370556116104126,
      "learning_rate": 1.0083840115493348e-06,
      "loss": 0.0044,
      "step": 1620
    },
    {
      "epoch": 1.8975552968568103,
      "grad_norm": 0.09195943176746368,
      "learning_rate": 8.154863666161528e-07,
      "loss": 0.0101,
      "step": 1630
    },
    {
      "epoch": 1.9091967403958092,
      "grad_norm": 0.15898220241069794,
      "learning_rate": 6.428979865126084e-07,
      "loss": 0.0026,
      "step": 1640
    },
    {
      "epoch": 1.9208381839348079,
      "grad_norm": 0.009945046156644821,
      "learning_rate": 4.906901364166994e-07,
      "loss": 0.0043,
      "step": 1650
    },
    {
      "epoch": 1.9324796274738067,
      "grad_norm": 0.010744723491370678,
      "learning_rate": 3.5892566597983125e-07,
      "loss": 0.0014,
      "step": 1660
    },
    {
      "epoch": 1.9441210710128056,
      "grad_norm": 0.08141691237688065,
      "learning_rate": 2.476589833749765e-07,
      "loss": 0.017,
      "step": 1670
    },
    {
      "epoch": 1.9557625145518043,
      "grad_norm": 0.012069404125213623,
      "learning_rate": 1.5693603283045144e-07,
      "loss": 0.008,
      "step": 1680
    },
    {
      "epoch": 1.9674039580908032,
      "grad_norm": 2.08064866065979,
      "learning_rate": 8.67942756586082e-08,
      "loss": 0.0049,
      "step": 1690
    },
    {
      "epoch": 1.979045401629802,
      "grad_norm": 0.07203181833028793,
      "learning_rate": 3.726267478735834e-08,
      "loss": 0.0077,
      "step": 1700
    },
    {
      "epoch": 1.990686845168801,
      "grad_norm": 0.23229143023490906,
      "learning_rate": 8.361682800755999e-09,
      "loss": 0.004,
      "step": 1710
    }
  ],
  "logging_steps": 10,
  "max_steps": 1718,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.086183055146353e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
