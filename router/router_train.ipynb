{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "# from dataloader import create_dataloaders\n",
    "from dataloader_ER import create_dataloaders,create_dataloaders_multi_label\n",
    "# from lora_model import LORAEngine,LORAEngineDeberta,LORAEngineDebertaMultiClass\n",
    "from lora_model_vmap import LORAEngineDebertaMultiClass,LORAEngineDebertaMultiLabel\n",
    "\n",
    "# from influence import IFEngine\n",
    "# from influence_hyperinf import IFEngine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_or_path=\"roberta-large\"\n",
    "# model_name_or_path=\"/home/yanmy/roberta-base\"\n",
    "# model_name_or_path=\"../../model/deberta-v3-base\"\n",
    "model_name_or_path=\"../../model/ModernBERT-base/\"\n",
    "# model_name_or_path=\"../../model/Qwen2.5-0.5B-Instruct/\"\n",
    "# model_name_or_path=\"../../model/roberta-large\"\n",
    "# task=\"mrpc\"\n",
    "task = \"Router\"\n",
    "noise_ratio=0\n",
    "batch_size=16\n",
    "# target_modules=[\"query_proj\", \"key_proj\", \"value_proj\"] ## deberta, for roberta, use [\"value\"]\n",
    "# target_modules = \n",
    "target_modules = ['Wqkv', 'Wo', 'Wi']\n",
    "# target_modules=[\"value_proj\"] ## deberta, for roberta, use [\"value\"]\n",
    "# target_modules=[\"q_proj\"] ## deberta, for roberta, use [\"value\"]\n",
    "\n",
    "device=\"cuda:7\"\n",
    "num_epochs=3\n",
    "lr=3e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 3300\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2a9480a79c40439f93270f04702135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834d5e3106d740f6821118484cc15b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef037d70c044a80a15fd79ade605f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68097 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataloader_outputs = create_dataloaders_multi_label(model_name_or_path=model_name_or_path,\n",
    "                                        #    task=task,\n",
    "                                        #    noise_ratio=noise_ratio,\n",
    "                                           batch_size=batch_size,\n",
    "                                           train_file = '../train/router/train_guided.csv',\n",
    "                                           valid_file = '../train/router/valid_guided.csv',\n",
    "                                           test_file = '../train/router/test_guided.csv',\n",
    "                                           max_length=2048)\n",
    "# train_dataloader, eval_dataloader, noise_index, tokenized_datasets, collate_fn=dataloader_outputs\n",
    "train_dataloader, eval_dataloader,test_dataloader, tokenized_datasets, collate_fn, label2id, id2label =dataloader_outputs\n",
    "\n",
    "num_labels = len(label2id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lora_engine = LORAEngineDebertaMultiLabel(model_name_or_path=model_name_or_path,\n",
    "                            target_modules=target_modules,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            # eval_dataloader=eval_dataloader,\n",
    "                            eval_dataloader=eval_dataloader,\n",
    "                            test_dataloader = test_dataloader,\n",
    "                            device=device,\n",
    "                            num_epochs=num_epochs,\n",
    "                            lr=lr,\n",
    "                            low_rank=16, \n",
    "                            task=task,\n",
    "                            save_path = '../models/router',\n",
    "                            valid_each_epoch=True,\n",
    "                            cal_grad_per_sample = False,\n",
    "                            num_labels=num_labels,\n",
    "                            label2id=label2id,\n",
    "                            id2label=id2label,\n",
    "                            use_lora = True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at ../../model/ModernBERT-base/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,393,042 || all params: 153,011,748 || trainable%: 2.2175\n",
      "Total Steps:621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [01:15<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 0.46381768778614374\n",
      "Epoch 1:Precision: 0.9189, Recall: 0.8293, F1-score: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:46<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 0.3417798299432377\n",
      "Epoch 2:Precision: 1.0000, Recall: 0.6897, F1-score: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:46<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 0.3256052052197249\n",
      "Epoch 3:Precision: 0.9231, Recall: 0.9000, F1-score: 0.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4257/4257 [06:12<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0668, Recall: 0.8664, F1-score: 0.1241\n"
     ]
    }
   ],
   "source": [
    "lora_engine.build_LORA_model()\n",
    "all_logits = lora_engine.train_LORA_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(all_logits,'../train/router/logits.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(id2label,'../train/router/id2label.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
