sample_per_cluster: 10
cluster_num: 200
train_init_model: true
task: ER
dataset: amazon-google
embedding_model_path: /data/home/wangys/sentence_transformer_model/bge-large-en-1.5
train_file_path: train/ER/amazon-google/amazon-google-train.json
eval_file_path: train/ER/amazon-google/train-init.json
test_file_path: train/ER/amazon-google/amazon-google-test.json
devices: 0,1,2,3,4,5,6,7
batch_size: 8
## LLM config
model_name_or_path: /home/wys/model/Qwen2.5-0.5B-Instruct
stage: sft
template: qwen
adapter_name_or_path: lora/qwen-0.5B/ER/amazon-google/init
require_grad: true
require_ppl: true
require_inference: true
cutoff_len: 1024