{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import ast\n",
    "import torch\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util_func import load_yaml,z_score_normalize,get_top_k_indices,run_command,round_down_to_power_of_two,load_yaml_args,normalize_to_neg1_pos1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util_func import load_yaml,z_score_normalize,get_top_k_indices,run_command,round_down_to_power_of_two,load_yaml_args,normalize_to_neg1_pos1\n",
    "from src.evaluation import evaluation\n",
    "evaluator = evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Score: 0.938132427843803\n",
      "\n",
      "Macro Score: 0.7767259106717945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.938132427843803, 'macro_f1': 0.7767259106717945}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_name = 'output/Ablation/CTA/WebTable/mistral-7B-w-main-batch-size-4.csv'\n",
    "output_file = pd.read_csv(output_file_name,index_col=0)\n",
    "metrics = evaluator.process('CTA','WebTable',output_file)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_select': 27.753063917160034,\n",
       " 'init-train': 28.262178421020508,\n",
       " 'batch-division': 50.33584022521973,\n",
       " 'gradient-calculation': 430.92104387283325,\n",
       " 'IF-Score': 516.7821741104126,\n",
       " 'Final Selection': 517.067054271698}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('eval_result/time_dict_CTA_WebTable_0,1,2,3_batch-size-4.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'init_select': 26.36381244659424,\n",
    " 'init-train': 26.608953952789307,\n",
    " 'batch-division': 45.89527630805969,\n",
    " 'gradient-calculation': 488.21150374412537,\n",
    " 'IF-Score': 528.6868059635162,\n",
    " 'Final Selection': 528.9380893707275} 12\n",
    " {'init_select': 27.753063917160034,\n",
    " 'init-train': 28.262178421020508,\n",
    " 'batch-division': 50.33584022521973,\n",
    " 'gradient-calculation': 430.92104387283325,\n",
    " 'IF-Score': 516.7821741104126,\n",
    " 'Final Selection': 517.067054271698} 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime for batch=1 IF calculation\n",
    "CUDA_VISIBLE_DEVICES=3 python cal_IF_single.py --yaml_path script/config_CTA_WebTable.yaml --process_num 1 --total_process_num 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'CTA'\n",
    "dataset = 'WebTable'\n",
    "count_val = 0\n",
    "val_grad_dict = {}\n",
    "for i in range(1,5,1):\n",
    "    val_grad_dict_part = torch.load('grad/{}/{}/val_grad_{}.pkl'.format(task,dataset,i))\n",
    "    for key in val_grad_dict_part.keys():\n",
    "        val_grad_dict[key+count_val] = val_grad_dict_part[key]\n",
    "    count_val += len(val_grad_dict_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import  KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# from FlagEmbedding import FlagModel\n",
    "import time\n",
    "# import submodlib\n",
    "# from submodlib.functions.facilityLocation import FacilityLocationFunction\n",
    "from datasets import Dataset\n",
    "from src.load_dataset import ReTaskEvaluator\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import yaml\n",
    "import argparse\n",
    "from src.evaluation import evaluation\n",
    "evaluator = evaluation()\n",
    "import torch.multiprocessing as mp\n",
    "import subprocess\n",
    "from src.util_func import load_yaml,z_score_normalize,get_top_k_indices,run_command,round_down_to_power_of_two,load_yaml_args,normalize_to_neg1_pos1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_json('/home/wys/DataSelection-IF/train/RE/RE/train-select-w-main-batch-size-4.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary Selection Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Method MELD-DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(sample_IF):\n",
    "    \"\"\"\n",
    "    对sample_IF字典中各个'method'对应的值（键为index、值为float的字典）进行Z-score归一化。\n",
    "\n",
    "    参数:\n",
    "    sample_IF (dict): 包含多个'method'键的字典，每个'method'键对应的值为需要进行归一化处理的字典数据。\n",
    "\n",
    "    返回:\n",
    "    dict: 归一化后的字典，结构与输入的sample_IF一致，其中每个'method'键对应的值都已经完成Z-score归一化。\n",
    "    \"\"\"\n",
    "    for method in sample_IF.keys():\n",
    "        # 获取当前method对应需要归一化的值列表，保持原有顺序\n",
    "        values_list = list(sample_IF[method].values())\n",
    "        # 将列表转换为torch.Tensor\n",
    "        tensor_value = torch.tensor(values_list).unsqueeze(1)  # 添加维度，变为二维张量\n",
    "\n",
    "        # 计算均值和标准差\n",
    "        mean_value = tensor_value.mean()\n",
    "        std_value = tensor_value.std()\n",
    "\n",
    "        # 进行Z-score归一化\n",
    "        normalized_tensor = (tensor_value - mean_value) / std_value\n",
    "\n",
    "        # 将归一化后的结果再转换回列表\n",
    "        normalized_list = normalized_tensor.squeeze(1).tolist()\n",
    "\n",
    "        # 更新原字典中当前method对应的值\n",
    "        index_list = list(sample_IF[method].keys())\n",
    "        normalized_dict = {}\n",
    "        for index, normalized_value in zip(index_list, normalized_list):\n",
    "            normalized_dict[index] = normalized_value\n",
    "\n",
    "        sample_IF[method] = normalized_dict\n",
    "\n",
    "    return sample_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n",
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2166745171926519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100015/834544746.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ppl_array[index] = row[0]\n"
     ]
    }
   ],
   "source": [
    "## reverse total score\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from src.util_func import load_yaml\n",
    "task_list = [\n",
    "    # ['RE','RE'],\n",
    "    # ['ER','abt-buy'],\n",
    "    # ['ER','semi-text-w'],\n",
    "    # ['DC','hospital'],\n",
    "    # ['DC','beer'],\n",
    "    # ['DC','rayyan'],\n",
    "    # ['DI','amazon'],\n",
    "    # ['DI','walmart'],\n",
    "    # ['AVE','oa_mine'],\n",
    "    ['CTA','SimTab'],\n",
    "    # ['CTA','WebTable'],\n",
    "    # ['ER','walmart-amazon'],\n",
    "    # ['ER','semi-text-c'],\n",
    "    # ['ER','amazon-google'],\n",
    "    # ['ER','wdc'],\n",
    "    # ['SM','CMS']\n",
    "]\n",
    "for task,dataset in task_list:\n",
    "    yaml_path = f'script/config_{task}_{dataset}.yaml'\n",
    "    config = load_yaml(yaml_path)\n",
    "    cluster_num = config['cluster_num']\n",
    "    cluster_per_budget = config['sample_per_cluster']\n",
    "    cluster_per_budget = 14\n",
    "    train_file_path = config['train_file_path']\n",
    "    train_file = pd.read_json(train_file_path)\n",
    "\n",
    "    cluster_rank = torch.load(f'../DataSelection-IF/selection/{task}/{dataset}/Cluster-Rank.pkl',weights_only=False)\n",
    "    total_score = torch.load(f'../DataSelection-IF/selection/{task}/{dataset}/Total-Score.pkl',weights_only=False)\n",
    "    sample_IF = torch.load(f'Influence/{task}/{dataset}/score.pkl',weights_only=False)\n",
    "    sample_IF = z_score_normalize(sample_IF)\n",
    "\n",
    "    ppl_array = np.zeros(len(total_score))\n",
    "    for process_num in range(1,9,1): ## maximum of k process\n",
    "        if os.path.exists('ppl/{}/{}/ppl-init-{}.csv'.format(task,dataset,process_num)): ## i-th gradient \n",
    "            ppl_df = pd.read_csv('ppl/{}/{}/ppl-init-{}.csv'.format(task,dataset,process_num),index_col=0)\n",
    "            for index,row in ppl_df.iterrows():\n",
    "                ppl_array[index] = row[0]\n",
    "\n",
    "    # QuRating_Score = np.load(f'QuRating/data/select_index_main_writing/{task}-{dataset}-QuRating-score.npy',allow_pickle=True).item()\n",
    "    # for key in range(len(total_score)):\n",
    "    #     # total_score[i] = total_score[i] - ppl_array[i]\n",
    "    #     if sample_IF['iterative'].__contains__(key):\n",
    "    #         total_score[key] += sample_IF['iterative'][key]\n",
    "    #     # total_score[i] = total_score[i] + 6 * QuRating_Score[i]\n",
    "    for key in sample_IF['iterative'].keys():\n",
    "        total_score[key] += sample_IF['iterative'][key]\n",
    "\n",
    "\n",
    "    p2_choose_index = []\n",
    "    count = 0\n",
    "    for i in cluster_rank.keys():\n",
    "        index_all = cluster_rank[i]\n",
    "        sorted_score_all = total_score[index_all]\n",
    "        sorted_index_all = index_all[np.argsort(-sorted_score_all)]\n",
    "        # print(index_all,sorted_index_all)\n",
    "        # break\n",
    "        change = cluster_per_budget - len(set(index_all[:cluster_per_budget]).intersection(set(sorted_index_all[:cluster_per_budget])))\n",
    "        count += change\n",
    "        p2_choose_index.extend(sorted_index_all[:cluster_per_budget])\n",
    "    select_IF_df = train_file.iloc[p2_choose_index]\n",
    "    print(len(select_IF_df) / len(train_file))\n",
    "    json.dump(select_IF_df.to_dict(orient='records'), open('train/{}/{}/train-select-w-main-size-20.json'.format(task,dataset), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2066997145861499"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python Ablation_Study.py --yaml_path script/config_RE_RE.yaml --device 0,1 --model mistral-7B --DO_TRAIN_MAIN_VAR --DO_EVAL_MAIN_VAR --main_var IF-single-size-10 IF-single-size-20 DSIR-size-10 DSIR-size-20 SuperFiltering-size-10 SuperFiltering-size-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Ablation_Study.py --yaml_path script/config_RE_RE.yaml --device 0,1 --model mistral-7B --DO_TRAIN_MAIN_VAR --DO_EVAL_MAIN_VAR --main_var QuRating-size-10 QuRating-size-20 LESS-size-10 LESS-size-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Ablation_Study.py --yaml_path script/config_ER_amazon-google.yaml --device 2,3 --model mistral-7B --DO_TRAIN_MAIN_VAR --DO_EVAL_MAIN_VAR --main_var IF-single-size-10 IF-single-size-20 DSIR-size-10 DSIR-size-20 SuperFiltering-size-10 SuperFiltering-size-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Ablation_Study.py --yaml_path script/config_CTA_SimTab.yaml --device 0,1 --model mistral-7B --DO_TRAIN_MAIN_VAR --DO_EVAL_MAIN_VAR --main_var IF-single-size-10 IF-single-size-20 DSIR-size-10 DSIR-size-20 SuperFiltering-size-10 SuperFiltering-size-20 QuRating-size-10 QuRating-size-20 LESS-size-10 LESS-size-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Ablation_Study.py --yaml_path script/config_ER_amazon-google.yaml --device 2,3 --model mistral-7B --DO_TRAIN_MAIN_VAR --DO_EVAL_MAIN_VAR --main_var QuRating-size-10 QuRating-size-20 LESS-size-10 LESS-size-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Ablation_Study.py --yaml_path script/config_CTA_SimTab.yaml --device 2,3 --model mistral-7B --DO_TRAIN_MAIN_VAR --DO_EVAL_MAIN_VAR --main_var main-size-20 main-size-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataInf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "IF-single-size-10 IF-single-size-20 DSIR-size-10 DSIR-size-20 SuperFiltering-size-10 SuperFiltering-size-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "QuRating-size-10 QuRating-size-20 LESS-size-10 LESS-size-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n",
      "1380\n",
      "1380\n"
     ]
    }
   ],
   "source": [
    "task = 'CTA'\n",
    "dataset = 'SimTab'\n",
    "percentage = 20\n",
    "select_num_df = pd.read_json(f'train/{task}/{dataset}/train-select-w-main-size-{percentage}.json')\n",
    "select_num = len(select_num_df)\n",
    "yaml_path = f'script/config_{task}_{dataset}.yaml'\n",
    "config = load_yaml(yaml_path)\n",
    "train_file_path = config['train_file_path']\n",
    "train_file = pd.read_json(train_file_path)\n",
    "if os.path.exists('Influence_single/{}/{}'.format(task,dataset)):\n",
    "    sample_IF_single = torch.load('Influence_single/{}/{}/score.pkl'.format(task,dataset),weights_only=False)\n",
    "    for IF_method in sample_IF_single.keys():\n",
    "        select_IF_single = get_top_k_indices(sample_IF_single[IF_method],k=select_num,IF=True)\n",
    "        select_IF_single_df = train_file.iloc[select_IF_single]\n",
    "        json.dump(select_IF_single_df.to_dict(orient='records'), open(f'train/{task}/{dataset}/train-select-w-IF-single-size-{percentage}.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=4)\n",
    "        print(len(select_IF_single_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SuperFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CUDA_VISIBLE_DEVICES=3 python code_ifd/select_data.py --json_data_path output/CTA-SimTab-gpt2.jsonl --json_save_path ../DataSelection-IF/train/CTA/SimTab/train-select-w-SuperFiltering-size-20.json --sample_num 1380 '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = 'CTA'\n",
    "dataset = 'SimTab'\n",
    "percentage = 20\n",
    "select_num_df = pd.read_json(f'train/{task}/{dataset}/train-select-w-main-size-{percentage}.json')\n",
    "select_size = len(select_num_df)\n",
    "step_3_command = f'CUDA_VISIBLE_DEVICES=3 python code_ifd/select_data.py \\\n",
    "--json_data_path output/{task}-{dataset}-gpt2.jsonl \\\n",
    "--json_save_path ../DataSelection-IF/train/{task}/{dataset}/train-select-w-SuperFiltering-size-{percentage}.json \\\n",
    "--sample_num {select_size} '\n",
    "step_3_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1708660588.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_100015/1708660588.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python QuRating_Selection.py --task ER --dataset amazon-google --device 0 --model_path ../../model/QuRating-1.3B --select_size 1394\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python QuRating_Selection.py --task CTA --dataset SimTab --device 0 --model_path ../../model/QuRating-1.3B --select_size 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'CTA'\n",
    "dataset = 'SimTab'\n",
    "select_file_size = 1300\n",
    "select_QuRating = np.load('QuRating/data/select_index_main_expert/{}-{}-QuRating-size-{}.npy'.format(task,dataset,select_file_size))\n",
    "yaml_path = f'script/config_{task}_{dataset}.yaml'\n",
    "config = load_yaml(yaml_path)\n",
    "train_file_path = config['train_file_path']\n",
    "train_file = pd.read_json(train_file_path)\n",
    "select_QuRating_df = train_file.iloc[select_QuRating]\n",
    "json.dump(select_QuRating_df.to_dict(orient='records'), open(f'train/{task}/{dataset}/train-select-w-QuRating-size-20.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37821/345711980.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  instruction = row[-1][0]['content']\n",
      "/tmp/ipykernel_37821/345711980.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  output = row[-1][1]['content']\n"
     ]
    }
   ],
   "source": [
    "task = 'CTA'\n",
    "dataset = 'SimTab'\n",
    "file = pd.read_json(f'../LESS/LESS_output/{task}_{dataset}/LESS_subset.jsonl',lines=True)\n",
    "def content_extraction(row):\n",
    "    instruction = row[-1][0]['content']\n",
    "    input = ''\n",
    "    output = row[-1][1]['content']\n",
    "    return instruction,input,output\n",
    "content_subset = file.apply(content_extraction,axis=1,result_type='expand')\n",
    "content_subset.columns = ['instruction','input','output']\n",
    "json.dump(content_subset.iloc[:,:1300].to_dict(orient='records'), open(f'../DataSelection-IF/train/{task}/{dataset}/train-select-w-LESS-size-20.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'RE'\n",
    "dataset = 'RE'\n",
    "batch_size = 4\n",
    "sample_IF = torch.load('Influence/{}/{}/batch-size-{}/score.pkl'.format(task,dataset,batch_size),weights_only=False)\n",
    "sample_IF = z_score_normalize(sample_IF)\n",
    "\n",
    "\n",
    "\n",
    "## FL Score\n",
    "greedyList_All_norm = z_score_normalize(greedyList_All)\n",
    "## Flatten\n",
    "greedyList_All_norm_flatten = {}\n",
    "for key in greedyList_All_norm.keys():\n",
    "    for index in greedyList_All_norm[key]:\n",
    "        greedyList_All_norm_flatten[index] = greedyList_All_norm[key][index]\n",
    "\n",
    "total_score = np.zeros(len(train_file))\n",
    "## calculate ppl\n",
    "# for index,row in ppl.iterrows():\n",
    "#     total_score[index] += row[0]\n",
    "\n",
    "for index in range(len(total_score)):\n",
    "    total_score[index] = ppl_array[index]\n",
    "## add FL\n",
    "for key in greedyList_All_norm_flatten.keys():\n",
    "    total_score[key] += greedyList_All_norm_flatten[key]\n",
    "## add global_IF\n",
    "for key in sample_IF['iterative']:\n",
    "    total_score[key] -= sample_IF['iterative'][key] ## Influence Score与performance成反比，所以是-=\n",
    "    \n",
    "## 遍历cluster,排序\n",
    "cluster_rank = {}\n",
    "for i in range(cluster_num): ## 100 is the cluster number, hyper-parameter\n",
    "    cluster_rank[i] = {}\n",
    "    cluster_index = cluster_indices[i]\n",
    "    sorted_index = cluster_index[np.argsort(-total_score[cluster_index])] ## return to global index\n",
    "    cluster_rank[i] = sorted_index\n",
    "\n",
    "p2_choose_index = []\n",
    "cluster_per_budget = sample_per_cluster\n",
    "for i in range(cluster_num):\n",
    "    p2_choose_index.extend(cluster_rank[i][:cluster_per_budget])\n",
    "\n",
    "## save FL Score for ablation\n",
    "create_folder_for_file('selection/{}/{}/batch-size-{}/FL-Score.pkl'.format(args.task,args.dataset))\n",
    "torch.save(greedyList_All_norm_flatten,'selection/{}/{}/batch-size-{}/FL-Score.pkl'.format(args.task,args.dataset))\n",
    "## save total score for ablation\n",
    "torch.save(total_score,'selection/{}/{}/batch-size-{}/Total-Score.pkl'.format(args.task,args.dataset))\n",
    "## save cluster division for ablation and furthur experiment\n",
    "torch.save(cluster_rank,'selection/{}/{}/batch-size-{}/Cluster-Rank.pkl'.format(args.task,args.dataset))\n",
    "\n",
    "## output\n",
    "\n",
    "selected_df = train_file.iloc[p2_choose_index]\n",
    "\n",
    "if(task=='SM'):\n",
    "    train_file_pos = train_file[train_file['output']==\"{'Output': 'match'}\"]\n",
    "    selected_df = pd.concat([selected_df,train_file_pos])\n",
    "    print('add positive samples')\n",
    "\n",
    "json.dump(selected_df.to_dict(orient='records'), open('train/{}/{}/train-select-w-main-batch-size-{}.json'.format(args.task,args.dataset,batch_size), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
