{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 735,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04081632653061224,
      "grad_norm": 52.57537841796875,
      "learning_rate": 1.2162162162162164e-05,
      "loss": 5.2157,
      "step": 10
    },
    {
      "epoch": 0.08163265306122448,
      "grad_norm": 20.002735137939453,
      "learning_rate": 2.5675675675675675e-05,
      "loss": 1.8028,
      "step": 20
    },
    {
      "epoch": 0.12244897959183673,
      "grad_norm": 10.45484447479248,
      "learning_rate": 3.918918918918919e-05,
      "loss": 0.4877,
      "step": 30
    },
    {
      "epoch": 0.16326530612244897,
      "grad_norm": 5.527371406555176,
      "learning_rate": 5.27027027027027e-05,
      "loss": 0.0987,
      "step": 40
    },
    {
      "epoch": 0.20408163265306123,
      "grad_norm": 2.074709415435791,
      "learning_rate": 6.621621621621621e-05,
      "loss": 0.0581,
      "step": 50
    },
    {
      "epoch": 0.24489795918367346,
      "grad_norm": 2.7354788780212402,
      "learning_rate": 7.972972972972974e-05,
      "loss": 0.0253,
      "step": 60
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.39722079038619995,
      "learning_rate": 9.324324324324324e-05,
      "loss": 0.0451,
      "step": 70
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 4.086644649505615,
      "learning_rate": 9.99858825452108e-05,
      "loss": 0.0535,
      "step": 80
    },
    {
      "epoch": 0.3673469387755102,
      "grad_norm": 2.145519256591797,
      "learning_rate": 9.987299073500244e-05,
      "loss": 0.0225,
      "step": 90
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 0.9334913492202759,
      "learning_rate": 9.96474620777906e-05,
      "loss": 0.0465,
      "step": 100
    },
    {
      "epoch": 0.4489795918367347,
      "grad_norm": 1.391143798828125,
      "learning_rate": 9.930980592415728e-05,
      "loss": 0.0273,
      "step": 110
    },
    {
      "epoch": 0.4897959183673469,
      "grad_norm": 1.8633078336715698,
      "learning_rate": 9.886078486170664e-05,
      "loss": 0.0354,
      "step": 120
    },
    {
      "epoch": 0.5306122448979592,
      "grad_norm": 0.1851649433374405,
      "learning_rate": 9.83014129927808e-05,
      "loss": 0.025,
      "step": 130
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 1.550029993057251,
      "learning_rate": 9.763295364413616e-05,
      "loss": 0.0462,
      "step": 140
    },
    {
      "epoch": 0.6122448979591837,
      "grad_norm": 2.995344638824463,
      "learning_rate": 9.685691651375298e-05,
      "loss": 0.0217,
      "step": 150
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 0.6577078700065613,
      "learning_rate": 9.597505426122185e-05,
      "loss": 0.029,
      "step": 160
    },
    {
      "epoch": 0.6938775510204082,
      "grad_norm": 1.6481977701187134,
      "learning_rate": 9.498935854940785e-05,
      "loss": 0.0183,
      "step": 170
    },
    {
      "epoch": 0.7346938775510204,
      "grad_norm": 0.666795015335083,
      "learning_rate": 9.390205554633193e-05,
      "loss": 0.0357,
      "step": 180
    },
    {
      "epoch": 0.7755102040816326,
      "grad_norm": 0.3980979919433594,
      "learning_rate": 9.27156008974286e-05,
      "loss": 0.0273,
      "step": 190
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 1.8961412906646729,
      "learning_rate": 9.143267417953485e-05,
      "loss": 0.0199,
      "step": 200
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.5811142921447754,
      "learning_rate": 9.005617284913586e-05,
      "loss": 0.0377,
      "step": 210
    },
    {
      "epoch": 0.8979591836734694,
      "grad_norm": 0.24823632836341858,
      "learning_rate": 8.858920569853519e-05,
      "loss": 0.0183,
      "step": 220
    },
    {
      "epoch": 0.9387755102040817,
      "grad_norm": 0.7925058603286743,
      "learning_rate": 8.703508583472854e-05,
      "loss": 0.01,
      "step": 230
    },
    {
      "epoch": 0.9795918367346939,
      "grad_norm": 16.64838409423828,
      "learning_rate": 8.539732319683817e-05,
      "loss": 0.0265,
      "step": 240
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.17221876978874207,
      "learning_rate": 8.367961662900703e-05,
      "loss": 0.0326,
      "step": 250
    },
    {
      "epoch": 1.0612244897959184,
      "grad_norm": 0.5920687317848206,
      "learning_rate": 8.188584552665593e-05,
      "loss": 0.0083,
      "step": 260
    },
    {
      "epoch": 1.1020408163265305,
      "grad_norm": 1.6200406551361084,
      "learning_rate": 8.002006107497018e-05,
      "loss": 0.0101,
      "step": 270
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.21155470609664917,
      "learning_rate": 7.80864770994038e-05,
      "loss": 0.0108,
      "step": 280
    },
    {
      "epoch": 1.183673469387755,
      "grad_norm": 0.4633030295372009,
      "learning_rate": 7.608946054886468e-05,
      "loss": 0.0114,
      "step": 290
    },
    {
      "epoch": 1.2244897959183674,
      "grad_norm": 1.2028626203536987,
      "learning_rate": 7.40335216330746e-05,
      "loss": 0.0152,
      "step": 300
    },
    {
      "epoch": 1.2653061224489797,
      "grad_norm": 1.7192742824554443,
      "learning_rate": 7.192330363637831e-05,
      "loss": 0.0063,
      "step": 310
    },
    {
      "epoch": 1.306122448979592,
      "grad_norm": 1.1760274171829224,
      "learning_rate": 6.976357243100718e-05,
      "loss": 0.03,
      "step": 320
    },
    {
      "epoch": 1.346938775510204,
      "grad_norm": 0.1746915727853775,
      "learning_rate": 6.755920571348112e-05,
      "loss": 0.0054,
      "step": 330
    },
    {
      "epoch": 1.3877551020408163,
      "grad_norm": 0.03628187254071236,
      "learning_rate": 6.531518198845854e-05,
      "loss": 0.0046,
      "step": 340
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 1.7601348161697388,
      "learning_rate": 6.303656932491349e-05,
      "loss": 0.0047,
      "step": 350
    },
    {
      "epoch": 1.469387755102041,
      "grad_norm": 1.1711201667785645,
      "learning_rate": 6.072851391003431e-05,
      "loss": 0.0109,
      "step": 360
    },
    {
      "epoch": 1.510204081632653,
      "grad_norm": 0.038115471601486206,
      "learning_rate": 5.8396228426694235e-05,
      "loss": 0.037,
      "step": 370
    },
    {
      "epoch": 1.5510204081632653,
      "grad_norm": 0.5561872720718384,
      "learning_rate": 5.604498028074323e-05,
      "loss": 0.0119,
      "step": 380
    },
    {
      "epoch": 1.5918367346938775,
      "grad_norm": 0.2665376365184784,
      "learning_rate": 5.368007970470964e-05,
      "loss": 0.0072,
      "step": 390
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 0.08071781694889069,
      "learning_rate": 5.130686776477844e-05,
      "loss": 0.0094,
      "step": 400
    },
    {
      "epoch": 1.6734693877551021,
      "grad_norm": 0.10757016390562057,
      "learning_rate": 4.8930704298132965e-05,
      "loss": 0.0094,
      "step": 410
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.6304304003715515,
      "learning_rate": 4.655695580790253e-05,
      "loss": 0.0092,
      "step": 420
    },
    {
      "epoch": 1.7551020408163265,
      "grad_norm": 0.7960205674171448,
      "learning_rate": 4.419098334305529e-05,
      "loss": 0.0074,
      "step": 430
    },
    {
      "epoch": 1.7959183673469388,
      "grad_norm": 0.036024585366249084,
      "learning_rate": 4.1838130390609187e-05,
      "loss": 0.0122,
      "step": 440
    },
    {
      "epoch": 1.836734693877551,
      "grad_norm": 0.02358056791126728,
      "learning_rate": 3.950371080750602e-05,
      "loss": 0.0024,
      "step": 450
    },
    {
      "epoch": 1.8775510204081631,
      "grad_norm": 0.23788516223430634,
      "learning_rate": 3.719299681940437e-05,
      "loss": 0.0043,
      "step": 460
    },
    {
      "epoch": 1.9183673469387754,
      "grad_norm": 0.17697153985500336,
      "learning_rate": 3.4911207113495704e-05,
      "loss": 0.0063,
      "step": 470
    },
    {
      "epoch": 1.9591836734693877,
      "grad_norm": 0.03969677910208702,
      "learning_rate": 3.26634950522355e-05,
      "loss": 0.0018,
      "step": 480
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.01731889694929123,
      "learning_rate": 3.04549370346089e-05,
      "loss": 0.0011,
      "step": 490
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.004837874788790941,
      "learning_rate": 2.8290521031216105e-05,
      "loss": 0.0062,
      "step": 500
    },
    {
      "epoch": 2.0816326530612246,
      "grad_norm": 0.006652116309851408,
      "learning_rate": 2.6175135319071025e-05,
      "loss": 0.0003,
      "step": 510
    },
    {
      "epoch": 2.122448979591837,
      "grad_norm": 0.002502916380763054,
      "learning_rate": 2.4113557441555383e-05,
      "loss": 0.0007,
      "step": 520
    },
    {
      "epoch": 2.163265306122449,
      "grad_norm": 0.004942276049405336,
      "learning_rate": 2.2110443418461725e-05,
      "loss": 0.0005,
      "step": 530
    },
    {
      "epoch": 2.204081632653061,
      "grad_norm": 0.02253705821931362,
      "learning_rate": 2.0170317230494316e-05,
      "loss": 0.0004,
      "step": 540
    },
    {
      "epoch": 2.2448979591836733,
      "grad_norm": 0.010797546245157719,
      "learning_rate": 1.829756060197692e-05,
      "loss": 0.0003,
      "step": 550
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.06983908265829086,
      "learning_rate": 1.64964031048428e-05,
      "loss": 0.0002,
      "step": 560
    },
    {
      "epoch": 2.326530612244898,
      "grad_norm": 0.0016158388461917639,
      "learning_rate": 1.4770912606257004e-05,
      "loss": 0.0002,
      "step": 570
    },
    {
      "epoch": 2.36734693877551,
      "grad_norm": 0.010689135640859604,
      "learning_rate": 1.3124986081444624e-05,
      "loss": 0.0021,
      "step": 580
    },
    {
      "epoch": 2.4081632653061225,
      "grad_norm": 0.012020448222756386,
      "learning_rate": 1.1562340812474004e-05,
      "loss": 0.0009,
      "step": 590
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 0.0064337411895394325,
      "learning_rate": 1.0086505992872303e-05,
      "loss": 0.0021,
      "step": 600
    },
    {
      "epoch": 2.489795918367347,
      "grad_norm": 0.002497553825378418,
      "learning_rate": 8.70081475703406e-06,
      "loss": 0.0006,
      "step": 610
    },
    {
      "epoch": 2.5306122448979593,
      "grad_norm": 0.027704039588570595,
      "learning_rate": 7.4083966524242706e-06,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 1.1759870052337646,
      "learning_rate": 6.212170571577086e-06,
      "loss": 0.0019,
      "step": 630
    },
    {
      "epoch": 2.612244897959184,
      "grad_norm": 0.4982583522796631,
      "learning_rate": 5.1148381598533355e-06,
      "loss": 0.0009,
      "step": 640
    },
    {
      "epoch": 2.6530612244897958,
      "grad_norm": 0.0011425400152802467,
      "learning_rate": 4.118877713845049e-06,
      "loss": 0.0014,
      "step": 650
    },
    {
      "epoch": 2.693877551020408,
      "grad_norm": 0.013743064366281033,
      "learning_rate": 3.226538584207228e-06,
      "loss": 0.0002,
      "step": 660
    },
    {
      "epoch": 2.7346938775510203,
      "grad_norm": 0.002053749980404973,
      "learning_rate": 2.439836095558262e-06,
      "loss": 0.0002,
      "step": 670
    },
    {
      "epoch": 2.7755102040816326,
      "grad_norm": 0.003665923373773694,
      "learning_rate": 1.7605469949218579e-06,
      "loss": 0.0001,
      "step": 680
    },
    {
      "epoch": 2.816326530612245,
      "grad_norm": 0.0017688337247818708,
      "learning_rate": 1.190205438990266e-06,
      "loss": 0.0011,
      "step": 690
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.009077670983970165,
      "learning_rate": 7.300995292715107e-07,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 2.8979591836734695,
      "grad_norm": 0.0007069744169712067,
      "learning_rate": 3.8126840294576136e-07,
      "loss": 0.0072,
      "step": 710
    },
    {
      "epoch": 2.938775510204082,
      "grad_norm": 0.0016435185680165887,
      "learning_rate": 1.4449988600111487e-07,
      "loss": 0.0016,
      "step": 720
    },
    {
      "epoch": 2.979591836734694,
      "grad_norm": 0.008451125584542751,
      "learning_rate": 2.0328713949230305e-08,
      "loss": 0.0034,
      "step": 730
    },
    {
      "epoch": 3.0,
      "step": 735,
      "total_flos": 5.20837670771884e+17,
      "train_loss": 0.11614717448694112,
      "train_runtime": 1631.8412,
      "train_samples_per_second": 7.188,
      "train_steps_per_second": 0.45
    }
  ],
  "logging_steps": 10,
  "max_steps": 735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.20837670771884e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
